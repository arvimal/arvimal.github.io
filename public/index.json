[{"body":"","link":"https://arvimal.github.io/","section":"","tags":null,"title":""},{"body":"","link":"https://arvimal.github.io/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://arvimal.github.io/categories/personal/","section":"categories","tags":null,"title":"personal"},{"body":"","link":"https://arvimal.github.io/posts/","section":"posts","tags":null,"title":"Posts"},{"body":"","link":"https://arvimal.github.io/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://arvimal.github.io/tags/testing/","section":"tags","tags":null,"title":"testing"},{"body":"Testing LoveIt Hugo theme Trying to revamp the blog with a beautiful theme - LoveIt.\n","link":"https://arvimal.github.io/posts/2022/08/testing-loveit/","section":"posts","tags":["testing"],"title":"Testing LoveIt"},{"body":"","link":"https://arvimal.github.io/archives/","section":"","tags":null,"title":""},{"body":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n","link":"https://arvimal.github.io/about/","section":"","tags":null,"title":"About"},{"body":"","link":"https://arvimal.github.io/tags/callable/","section":"tags","tags":null,"title":"callable"},{"body":"Introduction A callable is an object in Python that can be called / executed when called with parantheses ( ). Classes and functions are callable.\nCallables can be a class, a function, or an instance of a class. In simple terms, a class/function/instance/builtin is callable if it gets executed when called with parantheses ().\nExample 1: 1In [1]: help() 2Welcome to Python 3.6\u0026#39;s help utility! 3-- content omitted -- -------- 4 5In [2]: int() 6Out[2]: 0 7 8In [3]: 9callable(int) 10Out [3]: True 11 12In [4]: callable(help) 13Out [4]: True 14 15In [5]: def hello(): 16 print(\u0026#34;Howdy!!\u0026#34;) 17 18In [6]: hello() 19Out [6]: Howdy!! 20 21In [7]: callable(hello) 22Out [7]: True In Example 1, we can see that builtins like help(), a pre-defined type such as int(), and a custom function hello() are all callable. These can be executed while being called with parantheses.\nThe call() method The callable() builtin helps to determine if an object is callable or not. Internally, it translates to the magic method __call__().\nIn short:\nmy_object(*args) translates to my_object.__call__(*args)\nAll classes and functions are callable, as well as instances of classes with the __call__ magic method. An instance of a class/function is usually not callable (even though the class/function itself is), unless the class carries a __call__ magic method.\nie. An instance is callable only if the class it is instantiated from contains the __call__ magic method.\nThe inbuilt documentation on callable states: 1In [1]: print(callable.__doc__) 2Return whether the object is callable (i.e., some kind of function). Note that classes are callable, as are instances of classes with a call() method. [/code]\nExample 2: 1In [5]: def hello(): 2 ...: print(\u0026#34;Howdy!!\u0026#34;) 3 4In [6]: hello() 5Out [6]: Howdy!! 6 7In [7]: hello.__call__() 8Out [7]: Howdy!! 9 10In [8]: callable(hello) 11Out [8]: True Example 2 shows that a function when called with the parantheses (including any required arguments) is equivalent to calling the __call__() magic method. ie.. calling a function/class with parantheses translates to calling the __call__() magic method.\nNOTE: Read more on Magic methods in Python\nExample 3: Non-callable Instances [code language=\u0026quot;bash\u0026quot;]\nIn [1]: type(1) Out[1]: int\nIn [2]: callable(1) Out[2]: False\nIn [3]: x = 1\nIn [4]: type(x) Out[4]: int\nIn [5]: callable(int) Out[5]: True\nIn [6]: callable(x) Out[6]: False [/code] Example 3 above shows that even though the int class is callable, the instances created from the int class are not.\nRemember that instances will only be callable if the class from which it was instantiated contains a __call__ method. Inspecting the methods of class int reveals that it does not have a __call__ method.\nNOTE: You can view the methods of the int class using help(int) or dir(int).\nExample 4: Another example with Classes\n[code language=\u0026quot;bash\u0026quot;]\nIn [52]: class tell: ...: def call(self): ...: pass\nIn [53]: telling = tell()\nIn [54]: callable(tell) Out[54]: True\nIn [55]: callable(telling) Out[55]: True\nIn [56]: class test: ...: pass\nIn [57]: testing = test()\nIn [58]: callable(test) Out[58]: True\nIn [59]: callable(testing) Out[59]: False [/code] Since all classes are by default callable, both the classes tell and test in Example 4 are callable. But the instances of these classes necessarily need not be so. Since the class tell has the magic method __call__, the instance telling is callable. But the instance testing instantiated from the class test is not since the class does not have the magic method. Another set of examples.\nExample 5: Non-callable instance of a class [code language=\u0026quot;bash\u0026quot;]\nIn [1]: class new: ...: def foo(self): ...: print(\u0026quot;Hello\u0026quot;)\nIn [2]: n = new()\nIn [3]: n() ------------------ TypeError Traceback (most recent call last) in module() ----\u0026gt; 1 n()\nTypeError: 'new' object is not callable [/code]\nExample 6: Callable instance of the same class [code language=\u0026quot;bash\u0026quot;] In [4]: class new: ...: def call(self): ...: print(\u0026quot;I'm callable!\u0026quot;)\nIn [5]: n = new()\nIn [6]: n Out[6]: main.new at 0x7f7a614b1f98\nIn [7]: n() I'm callable! [/code] Example 5 and Example 6 shows how a class is itself callable, but unless it carries a __call__() method, the instances spawned out of it are not so.\nReferences: http://docs.python.org/3/library/functions.html#callable http://eli.thegreenplace.net/2012/03/23/python-internals-how-callables-work/ https://docs.python.org/3/reference/datamodel.html#object.__call__ ","link":"https://arvimal.github.io/posts/2017/08/callables-in-python/","section":"posts","tags":["callable","python","python-objects"],"title":"Callables in Python"},{"body":"","link":"https://arvimal.github.io/categories/programming/","section":"categories","tags":null,"title":"programming"},{"body":"","link":"https://arvimal.github.io/tags/python/","section":"tags","tags":null,"title":"python"},{"body":"","link":"https://arvimal.github.io/categories/python/","section":"categories","tags":null,"title":"python"},{"body":"","link":"https://arvimal.github.io/tags/python-objects/","section":"tags","tags":null,"title":"python-objects"},{"body":"","link":"https://arvimal.github.io/tags/kernel/","section":"tags","tags":null,"title":"kernel"},{"body":"","link":"https://arvimal.github.io/categories/linux/","section":"categories","tags":null,"title":"linux"},{"body":"","link":"https://arvimal.github.io/tags/module/","section":"tags","tags":null,"title":"module"},{"body":"Introduction _L_oadable Kernel Modules (LKM) are object code that can be loaded into memory, often used for supporting hardware or enable specific features.\nKernel modules enable the core kernel to be minimal and have features to be loaded as required.\nA kernel module is a normal file usually suffixed with .ko denoting it's a kernel object file. It contains compiled code from one or more source files, gets linked to the kernel when loaded, and runs in kernel space. It can dynamically adds functionality to a running kernel, without requiring a reboot.\nLinux kernel modules are written in C, and is compiled for a specific kernel version. This is the ideal practice since kernel data structures may change across versions, and using a module compiled for a specific version may break for another.\nSince kernel modules can be loaded and unloaded at will, it is pretty easy to unload an older version and load a newer one. This helps immensely in testing out new features since it is easy to change the source code, re-compile, unload the older version, load the newer version, and test the functionality.\nStructure Modules are expected to be under /lib/modules/$(uname -r)/ within directories specified according to use case.\n1[root@centos7 3.10.0-514.26.2.el7.x86_64] # ls -l 2total 2940 3lrwxrwxrwx. 1 root root 43 Jul 8 05:10 build -\u0026gt; /usr/src/kernels/3.10.0-514.26.2.el7.x86_64 4drwxr-xr-x. 2 root root 6 Jul 4 11:17 extra 5drwxr-xr-x. 12 root root 128 Jul 8 05:10 kernel 6-rw-r--r--. 1 root root 762886 Jul 8 05:11 modules.alias 7-rw-r--r--. 1 root root 735054 Jul 8 05:11 modules.alias.bin 8-rw-r--r--. 1 root root 1326 Jul 4 11:17 modules.block 9-rw-r--r--. 1 root root 6227 Jul 4 11:15 modules.builtin 10-rw-r--r--. 1 root root 8035 Jul 8 05:11 modules.builtin.bin 11-rw-r--r--. 1 root root 240071 Jul 8 05:11 modules.dep 12-rw-r--r--. 1 root root 343333 Jul 8 05:11 modules.dep.bin 13-rw-r--r--. 1 root root 361 Jul 8 05:11 modules.devname 14-rw-r--r--. 1 root root 132 Jul 4 11:17 modules.drm 15-rw-r--r--. 1 root root 110 Jul 4 11:17 modules.modesetting 16-rw-r--r--. 1 root root 1580 Jul 4 11:17 modules.networking 17-rw-r--r--. 1 root root 90643 Jul 4 11:15 modules.order 18-rw-r--r--. 1 root root 89 Jul 8 05:11 modules.softdep 19-rw-r--r--. 1 root root 350918 Jul 8 05:11 modules.symbols 20-rw-r--r--. 1 root root 432831 Jul 8 05:11 modules.symbols.bin 21lrwxrwxrwx. 1 root root 5 Jul 8 05:10 source -\u0026gt; build 22drwxr-xr-x. 2 root root 6 Jul 4 11:17 updates 23drwxr-xr-x. 2 root root 95 Jul 8 05:10 vdso 24drwxr-xr-x. 2 root root 6 Jul 4 11:17 weak-updates As we can see, there are several files that deals with the inter-dependencies of modules, which is used by modprobe to understand which modules to load before the one being actually requested to load.\nFor example:\nmodules.block lists the modules for block devices modules.networking lists the ones for network devices. modules.builtin lists the path of modules included in the kernel. modules.devname lists the ones that would be loaded automatically if a particular device is created. The kernel folder contains modules divided according to their use cases.\n1[root@centos7 3.10.0-514.26.2.el7.x86_64]# ls -l kernel/ 2total 16 3drwxr-xr-x. 3 root root 17 Jul 8 05:10 arch 4drwxr-xr-x. 3 root root 4096 Jul 8 05:10 crypto 5drwxr-xr-x. 67 root root 4096 Jul 8 05:10 drivers 6drwxr-xr-x. 26 root root 4096 Jul 8 05:10 fs 7drwxr-xr-x. 3 root root 19 Jul 8 05:10 kernel 8drwxr-xr-x. 5 root root 222 Jul 8 05:10 lib 9drwxr-xr-x. 2 root root 32 Jul 8 05:10 mm 10drwxr-xr-x. 33 root root 4096 Jul 8 05:10 net 11drwxr-xr-x. 11 root root 156 Jul 8 05:10 sound 12drwxr-xr-x. 3 root root 17 Jul 8 05:10 virt Each directory within kernel contains modules depending on the area they're used for.\nFor example, kernel/fs/ contains filesystem drivers.\n1[root@centos7 3.10.0-514.26.2.el7.x86_64]# ls -l kernel/fs 2total 48 3-rw-r--r--. 1 root root 21853 Jul 4 11:51 binfmt_misc.ko 4drwxr-xr-x. 2 root root 22 Jul 8 05:10 btrfs 5drwxr-xr-x. 2 root root 27 Jul 8 05:10 cachefiles 6drwxr-xr-x. 2 root root 21 Jul 8 05:10 ceph 7drwxr-xr-x. 2 root root 21 Jul 8 05:10 cifs 8drwxr-xr-x. 2 root root 23 Jul 8 05:10 cramfs 9drwxr-xr-x. 2 root root 20 Jul 8 05:10 dlm 10drwxr-xr-x. 2 root root 23 Jul 8 05:10 exofs 11drwxr-xr-x. 2 root root 21 Jul 8 05:10 ext4 12drwxr-xr-x. 2 root root 51 Jul 8 05:10 fat 13drwxr-xr-x. 2 root root 24 Jul 8 05:10 fscache 14rwxr-xr-x. 2 root root 36 Jul 8 05:10 fuse 15drwxr-xr-x. 2 root root 21 Jul 8 05:10 gfs2 16drwxr-xr-x. 2 root root 22 Jul 8 05:10 isofs 17drwxr-xr-x. 2 root root 21 Jul 8 05:10 jbd2 18drwxr-xr-x. 2 root root 22 Jul 8 05:10 lockd 19-rw-r--r--. 1 root root 19597 Jul 4 11:51 mbcache.ko 20drwxr-xr-x. 6 root root 128 Jul 8 05:10 nfs 21drwxr-xr-x. 2 root root 40 Jul 8 05:10 nfs_common 22drwxr-xr-x. 2 root root 21 Jul 8 05:10 nfsd 23drwxr-xr-x. 2 root root 4096 Jul 8 05:10 nls 24drwxr-xr-x. 2 root root 24 Jul 8 05:10 overlayfs 25drwxr-xr-x. 2 root root 24 Jul 8 05:10 pstore 26drwxr-xr-x. 2 root root 25 Jul 8 05:10 squashfs 27drwxr-xr-x. 2 root root 20 Jul 8 05:10 udf 28drwxr-xr-x. 2 root root 20 Jul 8 05:10 xfs depmod, and related commands Modules can export the features it carry, called symbols which can be used by other modules.\nIf module A depends on a symbol exported by module B, module B should be loaded first followed by module A.\ndepmod creates a list of symbol dependencies each module has, so that modprobe can go ahead and load the modules serving the symbols, prior loading the actual module.\ndepmod works by:\nCreating a list of symbols each module exports. Creating a list of symbol dependencies each module has. Dumping the list of symbols each module exports, to lib/modules/$(uname -r)/modules.symbols.bin and /lib/modules/$(uname -r)/modules.symbols Dumping the module dependency information to /lib/modules/$(uname -r)/modules.dep.bin and /lib/modules/$(uname -r)/modules.dep. Creating /lib/modules/$(uname -r)/modules.devnames which contains the device file information (device type, major:minor number) that gets created at boot for this module to function properly. NOTE:\nmodprobe refers /lib/modules/$(uname -r)/modules.dep.bin to understand the dependencies each module require. A human-readable version of this file is maintained at /lib/modules/$(uname -r)/modules.dep but modprobe does not refer this. The binary file modules.symbols.bin carry the symbols exported (if any) by each module, one symbol per line. A human-readable version of the same is kept at modules.symbols. A sneak peek into modules.symbols and modules.dep:\nmodules.symbols 1[root@centos7 3.10.0-514.26.2.el7.x86_64]# head modules.symbols 2# Aliases for symbols, used by symbol_request(). 3alias symbol:cfg80211_report_obss_beacon cfg80211 4alias symbol:drm_dp_link_train_channel_eq_delay drm_kms_helper 5alias symbol:__twofish_setkey twofish_common 6alias symbol:mlx4_db_free mlx4_core 7alias symbol:nf_send_unreach nf_reject_ipv4 8alias symbol:sdhci_remove_host sdhci 9alias symbol:videobuf_dma_init_kernel videobuf_dma_sg 10alias symbol:ar9003_paprd_is_done ath9k_hw 11alias symbol:cxgbi_ep_disconnect libcxgbi modules.dep 1[root@centos7 3.10.0-514.26.2.el7.x86_64]# head modules.dep 2kernel/arch/x86/kernel/cpu/mcheck/mce-inject.ko: 3kernel/arch/x86/kernel/test_nx.ko: 4kernel/arch/x86/kernel/iosf_mbi.ko: 5kernel/arch/x86/crypto/ablk_helper.ko: 6kernel/crypto/cryptd.ko 7kernel/arch/x86/crypto/glue_helper.ko: 8kernel/arch/x86/crypto/camellia-x86_64.ko: 9kernel/crypto/xts.ko 10kernel/crypto/lrw.ko 11kernel/crypto/gf128mul.ko 12kernel/arch/x86/crypto/glue_helper.ko 13kernel/arch/x86/crypto/blowfish-x86_64.ko: 14kernel/crypto/blowfish_common.ko 15kernel/arch/x86/crypto/twofish-x86_64.ko: 16kernel/crypto/twofish_common.ko 17kernel/arch/x86/crypto/twofish-x86_64-3way.ko: 18kernel/arch/x86/crypto/twofish-x86_64.ko 19kernel/crypto/twofish_common.ko 20kernel/crypto/xts.ko 21kernel/crypto/lrw.ko 22kernel/crypto/gf128mul.ko 23kernel/arch/x86/crypto/glue_helper.ko 24kernel/arch/x86/crypto/salsa20-x86_64.ko: lsmod is a parser that reads through /proc/modules and presents it in an easy-to-read format.\nNote how lsmod parse throug the content of /proc/modules below:\n1[root@centos7 3.10.0-514.26.2.el7.x86_64]# head /proc/modules 2test 12498 0 - Live 0xffffffffa0492000 (POE) 3binfmt_misc 17468 1 - Live 0xffffffffa048c000 4uhid 17369 0 - Live 0xffffffffa0486000 5ipt_MASQUERADE 12678 2 - Live 0xffffffffa0481000 6nf_nat_masquerade_ipv4 13412 1 7ipt_MASQUERADE, Live 0xffffffffa0451000 8xt_addrtype 12676 2 - Live 0xffffffffa044c000 9br_netfilter 22209 0 - Live 0xffffffffa0468000 10dm_thin_pool 65565 1 - Live 0xffffffffa046f000 11dm_persistent_data 67216 1 12dm_thin_pool, Live 0xffffffffa0456000 13dm_bio_prison 15907 1 14dm_thin_pool, Live 0xffffffffa043f000 15 16[root@centos7 3.10.0-514.26.2.el7.x86_64]# lsmod | head 17Module Size Used by 18test 12498 0 19binfmt_misc 17468 1 20uhid 17369 0 21ipt_MASQUERADE 12678 2 22nf_nat_masquerade_ipv4 13412 1 23ipt_MASQUERADE xt_addrtype 12676 2 24br_netfilter 22209 0 25dm_thin_pool 65565 1 26dm_persistent_data 67216 1 dm_thin_pool NOTE:\nThe first field lists the module name. The second field lists the size of the module in memory. The third field lists the number of times the module is in use. `0` means the module is not used despite it being loaded. The fourth field lists the modules which uses this module as their dependency. Creating a dummy module The steps for creating a kernel module includes:\nWriting the module file. Writing the Makefile for the module. Compile the module file using make , which will refer the Makefile to build it. The module file and its corresponding Makefile are put in a separate directory so as to keep the kernel module directory clean. Once the module code and the Makefile are ready, the make command is used to build the module, $(PWD) being the directory with the module code and Makefile.\n1# make -C /lib/modules/$(uname -r)/build M=$PWD modules The make command above does the following:\nChange to the path mentioned after -C, ie.. to the location where the kernel Makefile is present. (/lib/modules/$(uname -r)/build/) Use the kernel Makefile's macro M which denotes the location from which the code should be compiled, ie.. in this case, the PWD where the module code/Makefile is present. Use the target modules which tells make to build the module. make is trying to build a module in the current working directory, using the kernel Makefile at /lib/modules/$(uname -r)/build/Makefile\nIf we have a module file named test.c and its corresponding Makefile in $(PWD), the make command would follow the steps below:\nmake calls the modules target and refers to the kernel Makefile. The kernel Makefile looks for the module Makefile in $PWD. The kernel Makefile read the module's Makefile and gets a list of the objects assigned to the macro obj-m. The make command builds modules for each object assigned to the macro obj-m. Writing a simple module The following is a very simple module, which prints a message while loading, and another one while unloading.\n1int test_module(void) { 2 printk(\u0026#34;Loading the test module!\\\\n\u0026#34;); 3 return 0; } 4 5void unload_test(void) { 6 printk(\u0026#34;Unloading the test module!\\\\n\u0026#34;); 7 } 8 9module_init(test_module) 10module_exit(unload_test) This has two functions, test_module() and unload_test() which simply prints a text banner upon loading and unloading respectively.\nmodule_init() is used to load the module, and can call whatever functions that needs to initialize the module. We load our test_module() function into module_init() so that it gets initialized when the module is loaded.\nmodule_exit() is called whenever the module has to be unloaded, and it can take in whatever functions are required to do a proper cleanup (if required) prior the module being unloaded. We load our unload_test() function in module_exit().\nWriting a Makefile Since the kernel Makefile will look in for the obj-m macro in the module Makefile with the object filename as its argument, add the following in the Makefile:\n1obj-m := test.o make will create an object file test.o from test.c, and then create a kernel object file test.ko.\nCompiling the module with make Let's compile the module\n1[root@centos7 test]# pwd 2/lib/modules/3.10.0-514.26.2.el7.x86_64/test 3 4[root@centos7 test]# ls 5Makefile test.c 6 7[root@centos7 test]# make -C /lib/modules/$(uname -r)/build M=$PWD modules 8make: Entering directory `/usr/src/kernels/3.10.0-514.26.2.el7.x86_64\u0026#39; 9CC \\[M\\] /lib/modules/3.10.0-514.26.2.el7.x86_64/test/test.o Building modules, stage 2. MODPOST 1 modules 10CC /lib/modules/3.10.0-514.26.2.el7.x86_64/test/test.mod.o 11LD \\[M\\] /lib/modules/3.10.0-514.26.2.el7.x86_64/test/test.ko 12make: Leaving directory \\`/usr/src/kernels/3.10.0-514.26.2.el7.x86_64\u0026#39; Listing the contents show lot of new files, including the module code, the Makefile, the object file test.o created from test.c, the kernel object file test.ko.\ntest.mod.c contains code which should be the one ultimately being built to test.ko, but that should be for another post since much more is yet to be read/learned on what's happening there.\n1[root@centos7 test]# ls -l 2total 292 3-rw-r--r--. 1 root root 16 Jul 27 11:52 Makefile 4-rw-r--r--. 1 root root 60 Jul 27 11:57 modules.order 5-rw-r--r--. 1 root root 0 Jul 27 11:57 Module.symvers 6-rw-r--r--. 1 root root 281 Jul 27 11:53 test.c 7-rw-r--r--. 1 root root 137768 Jul 27 11:57 test.ko 8-rw-r--r--. 1 root root 787 Jul 27 11:57 test.mod.c 9-rw-r--r--. 1 root root 52912 Jul 27 11:57 test.mod.o 10-rw-r--r--. 1 root root 87776 Jul 27 11:57 test.o Loading/Unloading the module Loading and unloading the module should print the messages passed via printk in dmesg.\n1[root@centos7 test]# insmod ./test.ko 2 3[root@centos7 test]# lsmod | grep test 4test 12498 0 5 6[root@centos7 test]# rmmod test Checking dmesg shows the informational messages in the module code:\n1[root@centos7 test]# dmesg | tail 2[35889.187282] test: loading out-of-tree module taints kernel. 3[35889.187288] test: module license \u0026#39;unspecified\u0026#39; taints kernel. 4[35889.187290] Disabling lock debugging due to kernel taint 5[35889.187338] test: module verification failed: signature and/or required key missing - tainting kernel 6[35889.187548] Loading the test module! 7[35899.216954] Unloading the test module! Note the messages about the module test tainting the kernel.\nRead more on how a module can taint the kernel, at https://www.kernel.org/doc/html/latest/admin-guide/tainted-kernels.html.\nMore on customizing the Makefile in another post.\n","link":"https://arvimal.github.io/posts/2017/07/writing-a-minimalistic-kernel-module/","section":"posts","tags":["kernel","module"],"title":"Writing a minimalistic kernel module in Linux - Part 1"},{"body":"","link":"https://arvimal.github.io/tags/algorithms/","section":"tags","tags":null,"title":"algorithms"},{"body":"","link":"https://arvimal.github.io/categories/data-structures-and-algorithms/","section":"categories","tags":null,"title":"data-structures-and-algorithms"},{"body":"","link":"https://arvimal.github.io/tags/programming/","section":"tags","tags":null,"title":"programming"},{"body":"","link":"https://arvimal.github.io/tags/recursion/","section":"tags","tags":null,"title":"recursion"},{"body":"_R_ecursion is a technique by which a function calls itself until a condition is met.\nIntroduction Loops or repetitive execution based on certain conditions are inevitable in programs. Usual loops include if, while and for loops. Recursion is an entirely different way to deal with such situations, and in many cases, easier.\nRecursion is a when a function calls itself in each iteration till a condition is met. Ideally, the data set in each iteration gets smaller until it reach the required condition, after which the recursive function exists.\nA typical example of recursion is a factorial function.\nHow does Recursion work? A recursive function ideally contains a Base case and a Recursive case.\nA Recursive case is when the function calls itself, until the Base case is met. Each level of iteration in the Recursive case moves the control to the next level.\nOnce a specific level finishes execution, the control is passed back to the previous level of execution. A Recursive function can go several layers deep until the Base condition is met. In short, a Recursive case is a loop in which the function calls itself.\nThe Base case is required so that the function doesn't continue running in the Recursive loop forever. Once the Base case is met, the control moves out of the Recursive case, executes the conditions in the Base case (if any), and exits.\nAs mentioned in the Introduction, a factorial function can be seen as an example of recursion.\nNOTE: The Base case for a factorial function is when n == 1\nConsider n!:\nn! can be written as:\nn x (n - 1) x (n - 2) x (n - 3) x .... x 1\nn! can also be represented as:\n[code language=\u0026quot;bash\u0026quot;] n! = n * (n - 1)! ---\u0026gt; [Step 1] (n - 1)! = (n - 1) * (n - 2)! ---\u0026gt; [Step 2] (n - 2)! = (n - 2) * (n - 3)! ---\u0026gt; [Step 3] . .. ... (n - (n - 1)) = 1 ---\u0026gt; [Base case] [/code]\nEach level/step is a product of a value and all the levels below it. Hence, Step 1 will end up moving to Step 2 to get the factorial of elements below it, then to Step 3 and so on.\nie.. the control of execution move as:\n[Step 1] -\u0026gt; [Step 2] -\u0026gt; [Step 3] -\u0026gt; ..... [Step n]\nIn a much easier-to-grasp example, a 5! would be:\n[code language=\u0026quot;bash\u0026quot;] 5! = 5 * 4! ---\u0026gt; [Step 1] 4! = 4 * 3! ---\u0026gt; [Step 2] 3! = 3 * 2! ---\u0026gt; [Step 3] 2! = 2 * 1! ---\u0026gt; [Step 4] 1! = 1 ---\u0026gt; [Step 5] / [Base case] [/code]\nThe order of execution will be :\n[Step 1] -\u0026gt; [Step 2] -\u0026gt; [Step 3] -\u0026gt; [Step 4] -\u0026gt; [Step 5]\nAs we know, in Recursion, each layer pause itself and pass the control to the next level. Once it reach the end or the Base case, it returns the result back to the previous level one by one until it reaches where it started off.\nIn this example, once the control of execution reaches Step 5 / Base case , the control is returned back to its previous level Step 4 . This level returns the result back to Step 3 which completes its execution and returns to Step 2 , so on and so forth until it reach Step 1 .\nThe return control flow would be as:\n[Base case / Step 5] -\u0026gt; [Step 4] -\u0026gt; [Step 3] -\u0026gt; [Step 2] -\u0026gt; [Step 1] -\u0026gt; Result.\nThis can be summed up using an awesome pictorial representation, from the book Grokking Algorithms by Adit. Please check out the References section for the link for more information about this awesome book.\nFigure 1: Recursion, Recursive case and Base case (Copyright Manning Publications, drawn by adit.io)\nCode Example 1: A factorial function in a while loop [code language=\u0026quot;python\u0026quot;] def fact(n): factorial = 1 while n \u0026gt; 1: factorial = factorial * n n = n - 1 return factorial\nprint(\u0026quot;Factorial of {0} is {1}\u0026quot;.format(10, fact(10))) print(\u0026quot;Factorial of {0} is {1}\u0026quot;.format(20, fact(20))) [/code]\nThe same function above, in a recursive loop [code language=\u0026quot;python\u0026quot;] def factorial(n): if n == 0: return 1 else: return n * factorial(n - 1)\nprint(\u0026quot;Factorial of {0} is {1}\u0026quot;.format(10, factorial(10))) print(\u0026quot;Factorial of {0} is {1}\u0026quot;.format(20, factorial(20))) [/code]\nExample 2: A function to sum numbers in a normal for loop. [code language=\u0026quot;python\u0026quot;] def my_sum(my_list): num = 0 for i in my_list: num += i return num\nprint(my_sum([10, 23, 14, 12, 11, 94, 20])) [/code]\nThe same function to add numbers, in a recursive loop [code language=\u0026quot;python\u0026quot;] def my_sum(my_list): if my_list == []: return 0 else: return my_list[0] + my_sum(my_list[1:])\nprint(my_sum([10, 23, 14, 12, 11, 94, 20])) [/code]\nCode explanation Both Example 1 and Example 2 are represented as an iterative function as well as a recursive function.\nThe iterative function calls the next() function on the iterator sum.__iter__() magic method iterate over the entire data set. The recursive function calls itself to reach a base case and return the result.\nObservations: While a recursive function does not necessarily give you an edge on performance, it is much easier to understand and the code is cleaner.\nRecursion has a disadvantage though, for large data sets. Each loop is put on a call stack until it reaches a Base case. Once the Base case is met, the call stack is rewound back to reach where it started, executing each of the previous levels on the way. The examples above showed a sum function and a factorial function. In large data sets, this can lead to a large call stack which in turns take a lot of memory.\nReferences: Grokking Algorithms Data Structures and Algorithms in Python ","link":"https://arvimal.github.io/posts/2017/06/recursion-algorithm-study/","section":"posts","tags":["algorithms","programming","python","recursion"],"title":"Recursion - Algorithm Study"},{"body":"Selection Sort is a sorting algorithm used to sort a data set either in incremental or decremental order.\nIt goes through the entire elements one by one and hence it's not a very efficient algorithm to work on large data sets.\n1. How does Selection sort work? Selection sort starts with an unsorted data set. With each iteration, it builds up a sub dataset with the sorted data.\nBy the end of the sorting process, the sub dataset contains the entire elements in a sorted order.\nIterate through the data set one element at a time. Find the biggest element in the data set (Append it to another if needed) Reduce the sample space by the biggest element just found. The new data set becomes n - 1 compared to the previous iteration. Start over the iteration again, on the reduced sample space. Continue till we have a sorted data set, either incremental or decremental 2. How does the data sample change in each iteration? Consider the data set [10, 4, 9, 3, 6, 19, 8]\nData set - [10, 4, 9, 3, 6, 19, 8]\nAfter Iteration 1 - [10, 4, 9, 3, 6, 8] - [19] After Iteration 2 - [4, 9, 3, 6, 8] - [10, 19] After Iteration 3 - [4, 3, 6, 8] - [9, 10, 19] After Iteration 4 - [4, 3, 6] - [8, 9, 10, 19] After Iteration 5 - [4, 3] - [6, 8, 9, 10, 19] After Iteration 6 - [3] - [4, 6, 8, 9, 10, 19] After Iteration 7 - [3, 4, 6, 8, 9, 10, 19] Let's check what the Selection Sort algorithm has to go through in each iteration.\nIter 1 - [10, 4, 9, 3, 6, 8] Iter 2 - [4, 9, 3, 6, 8] Iter 3 - [4, 3, 6, 8] Iter 4 - [4, 3, 6] Iter 5 - [4, 3] Iter 6 - [3] Sorted Dataset - [3, 4, 6, 8, 9, 10, 19]\n3. Performance / Time Complexity Selection Sort has to go through all the elements in the data set, no matter what. Hence, the Worst case, Best case and Average Time Complexity would be O(n^2). Since Selection Sort takes in n elements while starting, and goes through the data set n times (each step reducing the data set size by 1 member), the iterations would be:\n1n + [ (n - 1) + (n - 2) + (n - 3) + (n - 4) + ... + 2 + 1 ] We are more interested in the worse-case scenario. In a very large data set, an n - 1, n - 2 etc.. won't make a difference.\nHence we can re-write the above iterations as:\n1n + [n + n + n + n ..... n] Or also as:\n1n * n = (n^2) 4. Code 1def find_smallest(my_list): 2 smallest = my_list[0] 3 smallest_index = 0 4 5for i in range(1, len(my_list)): 6 if my_list[i] \u0026lt; smallest: 7 smallest = my_list[i] 8 smallest_index = i 9 return smallest_index 10 11def selection_sort(my_list): 12 new_list = [] 13 for i in range(len(my_list)): 14 smallest = find_smallest(my_list) 15 new_list.append(my_list.pop(smallest)) 16 return new_list[code] 5. Observations Selection Sort is an algorithm to sort a data set, but it is not particularly fast. It takes n iterations in each step to find the biggest element in that iteration. The next iteration has to run on a data set of n - 1 elements compared to the previous iteration. For n elements in a sample space, Selection Sort takes n x n iterations to sort the data set. 6. References https://en.wikipedia.org/wiki/Selection_sort http://bigocheatsheet.com https://github.com/egonschiele/grokking_algorithms ","link":"https://arvimal.github.io/posts/2017/02/selection-sort-algorithm-study/","section":"posts","tags":["algorithms","python"],"title":"Selection Sort - Algorithm Study"},{"body":"Introduction **B**inary Search is a search method used to find an object in a data set. This is much faster compared to the Linear Search algorithm we saw in a previous post.\nThis algorithm works on the Divide and Conquer principle. Binary Search gets its speed by essentially dividing the list/array in half in each iteration, thus reducing the dataset size for the next iteration.\nImagine searching for an element in a rather large dataset. Searching for an element one by one using Linear Search would take n iterations. In a worst case scenario, if the element being searched is not present in the dataset or is at the end of the dataset, the time taken to find the object/element would be proportional to the size of the dataset.\nThe element of interest is returned if it is present in the dataset, else a NULL/None value is.\nNote: Binary search will only work effectively on a Sorted collection. The code implementation will need minor changes depending on how the dataset is sorted, ie.. either in an increasing order or in a decreasing order. Performance 1. Worst-case performance: log(n) As discussed in the post on, Linear Search a worst-case analysis is done with the upper bound of the running time of the algorithm. ie.. the case when the maximum number of operations are needed/executed to find/search the element of interest in the dataset.\nOf course, the worst-case scenario for any search algorithms is when the element of interest is not present in the dataset. The maximum number of searches has to be done in such a case, and it still ends up with no fruitful result. A similar but less worse case is when the element is found in the final (or somewhere near the last) iteration.\nDue to the divide-and-conquer method, the maximum number of iterations needed for a dataset of n elements is, log(n) where the log base is 2.\nHence, for a data set of 10240 elements, Binary Search takes a maximum of 13 iterations.\n[code language=\u0026quot;python\u0026quot;] In [1]: import math\nIn [2]: math.log(10240, 2) Out[2]: 13.321928094887364 [/code] For a data set of 50,000 elements, Binary Search takes 16 iterations in the worst case scenario while a Linear Search may take 50,000 iterations in a similar case.\n[code language=\u0026quot;python\u0026quot;] In [1]: import math\nIn [2]: math.log(50000, 2) Out[2]: 15.609640474436812 [/code] ie.. the Worst case for Binary search takes log(n) iterations to find the element.\n2. Best-case performance: O(1) The best case scenario is when the element of interest is found in the first iteration itself. Hence the best-case would be where the search finishes in one iteration.\nie.. The best-case scenario would be O(1).\nHow does Binary Search work? Imagine a sorted dataset of 100 numbers and we're searching for 98 is in the list. A simple search would start from index 0 , moves to the element at index 1, progresses element by element until the one in interest is found. Since we're searching for 98, it'll take n iterations depending on the number of elements between the first element in the dataset and 98.\nBinary Search uses the following method, provided the dataset is sorted.\nFind the length of the data set. Find the lowest (index 0), highest (index n), and the middle index of the dataset. Find the subsequent elements residing in the first, last, and middle index. Check if the element of interest is the middle element. If not, check if the element-of-interest is higher or lower than the middle element. If it is higher, assuming the dataset is sorted in an increasing order, move the lower index to one above the middle index. if it is lower, move the highest index to one below the middle index. Check if the element of interest is the middle element in the new/shorter dataset. Continue till the element of interest is found. [caption id=\u0026quot;attachment_2310\u0026quot; align=\u0026quot;alignnone\u0026quot; width=\u0026quot;1280\u0026quot;] Binary Search - Source: Wikipedia[/caption]\nThe figure above shows how Binary Search works on a dataset of 16 elements, to find the element 7.\nIndex 0 , Index 16, and the middle index are noted. Subsequent values/elements at these indices are found out as well. Check if the element of interest 7 is equal to, lower, or higher than the middle element 14 at index 8. Since it's lower and the dataset is sorted in an increasing order, the search moves to the left of the middle index, ie.. from index 0 to index 7. ---- The lower index is now 0, the higher index is now 7, and the middle index is now 3, the element in the middle index is 6. Check if the element of interest 7 is lower or higher than the middle element 6 at index 3. Since it's higher and the dataset is sorted in an increasing order, the search moves to the right of the middle index, ie.. from index 4 to index 7. ---- So on and so forth.. till we arrive at the element of interest, ie.. 7. As noted earlier, the data set is divided into half in each iteration. A numeric representation on how Binary search progress can be seen as:\n100 elements -\u0026gt; 50 elements -\u0026gt; 25 elements -\u0026gt; 12 elements -\u0026gt; 6 elements - 3 elements -\u0026gt; 1 element\nCode Example 1 : (Data set sorted in Increasing order) [code language=\u0026quot;python\u0026quot;] def binary_search(my_list, item): low_position = 0 high_position = len(my_list) - 1\nwhile low_position = high_position: mid_position = (low_position + high_position) // 2 mid_element = my_list[mid_position]\nif mid_element == item: print(\u0026quot;\\nYour search item {0} is at index {1}\u0026quot;.format( item, mid_position)) return mid_element\nelif mid_element \u0026lt;= item: high_position = mid_position - 1\nelse: low_position = mid_position + 1 return None\nif __name__ == \u0026quot;__main__\u0026quot;: my_list = [1, 2, 3, 4, 5, 6] binary_search(my_list, 3) [/code]\nExample 2 : (Same as above, with statements on how the search progresses) [code language=\u0026quot;python\u0026quot;] def binary_search(my_list, item):\n# Find and set the low and high positions of the data set # Note that these are not the values, but just positions. low_position = 0 high_position = len(my_list) - 1\n# Calculate the Complexity import math complexity = math.ceil(math.log(len(my_list), 2))\n# Print some info on the dataset print(\u0026quot;\\nDataset size : {0} elements\u0026quot;.format(len(my_list))) print(\u0026quot;Element of interest : {0}\u0026quot;.format(item)) print(\u0026quot;Maximum number of iterations to find {0} : {1}\\n\u0026quot;.format( item, complexity))\nwhile low_position \u0026lt;= high_position:\n# Find the middle position from the low and high positions mid_position = (low_position + high_position) // 2\n# Find the element residing in the middle position of the data set. mid_element = my_list[mid_position]\nprint(\u0026quot;Element at min index : {0}\u0026quot;.format(my_list[low_position])) print(\u0026quot;Element at max index : {1}\u0026quot;.format(high_position, my_list[high_position])) print(\u0026quot;Element at mid index {0} : {1}\u0026quot;.format(mid_position, mid_element))\nif mid_element == item: print(\u0026quot;\\nYour search item {0} is at index {1}\u0026quot;.format( item, mid_position)) return mid_element\nelif mid_element \u0026gt; item: high_position = mid_position - 1 print(\u0026quot;{0} in the left subset, omitting the right subset\\n\u0026quot;.format(item))\nelse: low_position = mid_position + 1 print(\u0026quot;{0} in the right subset, omitting the left subset\\n\u0026quot;.format(item))\nprint(\u0026quot;Element of interest not in dataset\\n\u0026quot;) return None\nif __name__ == \u0026quot;__main__\u0026quot;: my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13] binary_search(my_list, 13) [/code]\nObservations: Binary Search needs a Sorted dataset to work, either increasing or decreasing. It finds the element of interest in logarithmic time, hence is also known as, Logarithmic Search. Binary Search searches through a dataset of n elements in log(n) iterations, in the worst case scenario. NOTE: All the examples used in this blog are available at https://github.com/arvimal/DataStructures-and-Algorithms-in-Python, with more detailed notes.\nReferences: https://en.wikipedia.org/wiki/Binary_search_algorithm http://quiz.geeksforgeeks.org/binary-search/ https://www.hackerearth.com/practice/algorithms/searching/binary-search/tutorial/ http://research.cs.queensu.ca/home/cisc121/2006s/webnotes/search.html ","link":"https://arvimal.github.io/posts/2017/01/binary-search-algorithm-study/","section":"posts","tags":null,"title":"Binary Search - Algorithm Study"},{"body":"autoauto- [Introduction](#introduction)auto- [Performance](#performance)auto - [1\\. Worst-case performance: O(n)](#1\\-worst-case-performance-on)auto - [2\\. Best-case performance: O(1)](#2\\-best-case-performance-o1)auto - [3\\. Average performance: O(n/2)](#3\\-average-performance-on2)auto - [Observations:](#observations)auto- [How does Linear Search work?](#how-does-linear-search-work)auto- [Code](#code)auto - [Reference:](#reference)autoauto Introduction _L_inear Search is an way to search a data set for an element of interest. It is one of the many search algorithms available and is also the most direct and simple of the lot.\nLinear search looks for the element of interest in a dataset starting from the first element and moves on to the consecutive elements till it finds the one we're interested in. Due to this behaviour, it's not the fastest search algorithm around.\nIn the worst case, when the element of interest is the last (or near-last) in the data set, linear-search has to sift through till the end. Hence, in a worst-case scenario, the larger the data set is, the more the iterations it take to find the element of interest. Hence, the performance of Linear search takes a toll as the data set grows.\nLinear search works on sorted and unsorted data sets equally, since it has to go through the elements one by one and so doesn't mind if the data is ordered or not.\nPerformance 1. Worst-case performance: O(n) A worst-case analysis is done with the upper bound of the running time of the algorithm. ie.. the case when the maximum number of operations are executed.\nThe worst-case scenario for a linear search happens when the element-of-interest is not present in the dataset. A near worst-case scenario is when the element-of-interest is the last element of the dataset. In the first case, the search has to go through each element only to find that the element is not present in the dataset. In the second scenario, the search has to be done till the last element, which still takes n iterations.\nIn the worst-case, the performance is O(n), where n is the number of elements in the dataset.\n2. Best-case performance: O(1) In the best-case, where the element-of-interest is the first element in the dataset, only one search/lookup is needed. Hence the performance is denoted as O(1), for n elements.\n3. Average performance: O(n/2) On an average, the performance can be denoted as O(n/2).\nObservations: Linear Search iterates through every element in the dataset until it finds the match. In Linear Search, the number of iterations grows linearly if the data set grows in size. This algorithm is called Linear Search due to this linear increase in the complexity depending on the dataset. The best case scenario is when the first iteration finds the element. The Worst case is when the element of interest is not present in the dataset. A very near worse case is when the element of interest is the last one in the dataset. How does Linear Search work? Linear search progresses as following:\n1. Takes in a dataset as well as an element of interest. 2. Checks if the first element is the element of interest. 3. If yes, returns the element. 4. If not, move to the next element in the dataset. 5. Iterate till the dataset is exhausted. 6. Return None if the element of interest is not present in the dataset.\nCode [code language=\u0026quot;python\u0026quot;] def linear_search(my_list, item): \u0026quot;\u0026quot;\u0026quot;Linear search\u0026quot;\u0026quot;\u0026quot;\nlow_position = 0 high_position = len(my_list) - 1\nwhile low_position \u0026lt; high_position:\nif my_list[low_position] == item: print(\u0026quot;Your search item {0} is at position {1}\u0026quot;.format( item, low_position)) return low_position else: low_position += 1\nif __name__ == \u0026quot;__main__\u0026quot;: my_list = [1, 2, 3, 4, 5, 6] linear_search(my_list, 5) [/code]\nReference: http://quiz.geeksforgeeks.org/linear-search/ http://research.cs.queensu.ca/home/cisc121/2006s/webnotes/search.html ","link":"https://arvimal.github.io/posts/2017/01/linear-search-algorithm-study/","section":"posts","tags":null,"title":"Linear Search - Algorithm Study"},{"body":"A method defined within a class can either be an Accessor or a Mutator method.\nAn Accessor method returns the information about the object, but do not change the state or the object.\nA Mutator method, also called an Update method, can change the state of the object.\nConsider the following example:\n[code language=\u0026quot;python\u0026quot;] In [10]: a = [1,2,3,4,5]\nIn [11]: a.count(1) Out[11]: 1\nIn [12]: a.index(2) Out[12]: 1\nIn [13]: a Out[13]: [1, 2, 3, 4, 5]\nIn [14]: a.append(6)\nIn [15]: a Out[15]: [1, 2, 3, 4, 5, 6] [/code]\nThe methods a.count() and a.index() are both Accessor methods since it doesn't alter the object a in any sense, but only pulls the relevant information.\nBut a.append() is a mutator method, since it effectively changes the object (list a) to a new one.\nIn short, knowing the behavior of a method is helpful to understand how it alters the objects it acts upon.\n","link":"https://arvimal.github.io/posts/2016/12/accessor-and-mutator-methods/","section":"posts","tags":["object-oriented-programming","python"],"title":"Accessor and Mutator methods - Python"},{"body":"","link":"https://arvimal.github.io/tags/object-oriented-programming/","section":"tags","tags":null,"title":"object-oriented-programming"},{"body":"","link":"https://arvimal.github.io/tags/namespace/","section":"tags","tags":null,"title":"namespace"},{"body":"","link":"https://arvimal.github.io/tags/objects/","section":"tags","tags":null,"title":"objects"},{"body":"","link":"https://arvimal.github.io/tags/python-namespace/","section":"tags","tags":null,"title":"python-namespace"},{"body":"_E_verything in Python is an object, what does that mean? This post tries to discuss some very basic concepts.\nWhat does the following assignment do?\n[code language=\u0026quot;python\u0026quot;]\na = 1 [/code] Of course, anyone dabbled in code knows this. The statement above creates a container `a` and stores the value `1` in it.\nBut it seem that's not exactly what's happening, at least from Python's view-point.\nWhen a = 1 is entered or executed by the python interpreter, the following happens in the backend, seemingly unknown to the user.\nThe Python interpreter evaluates the literal 1 and tries to understand what data type can be assigned for it. There are several in-built data types such as str, float, bool, list, dict, set etc.. Builtin types are classes implemented in the python core. For a full list of types and explanation, read the python help at python-\u0026gt; help()-\u0026gt; topics -\u0026gt; TYPES Read the help sections for builtin types, eg.. help(int), help(list) etc.. The interpreter finds the appropriate builtin type for the literal. Since the literal 1 fits the type int, the interpreter creates an instance from class int() in memory. This instance is called an object since it's just a blob with some metadata. This object has a memory address, a value, a name in one or more namespace, some metadata etc.. type(a) helps in understanding the instance type. In short, an assignment statement simply creates an instance in memory from a pre-defined class. The interpreter reads the LHS (Left hand side) of the statement a = 1, and creates the name a in the current namespace. The name in the namespace is a reference to the object in memory. Through this reference, we can access the data portion as well as the attributes of that object. A single object can have multiple names (references). The name a created in the current namespace is linked to the corresponding object in memory. When a name that's already defined is entered at the python prompt, the interpreter reads the namespace, finds the name (reference), goes to the memory location it's referring to, and pull the value of the object, and prints it on-screen.\nEvery object has the following features: A single value, available in its data section. [code language=\u0026quot;python\u0026quot;] In [1]: a = 1\nIn [2]: a Out[2]: 1 [/code]\nA single type, since the object is an instance of a pre-defined type class such as int , float etc.. [code language=\u0026quot;python\u0026quot;] In [3]: type(a) Out[3]: int [/code]\nAttributes either inherited from the parent type class or defined by the user. [code language=\u0026quot;python\u0026quot;] In [10]: dir(a) Out[10]: ['__abs__', '__add__', '__and__', '__bool__', '__ceil__', '__class__', '__delattr__', '__dir__', '__divmod__', '__doc__', '__eq__', '__float__', ...[content omitted] '__setattr__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__truediv__', '__trunc__', '__xor__', 'bit_length', 'conjugate', 'denominator', 'from_bytes', 'imag', 'numerator', 'real', 'to_bytes'] [/code]\nOne or more base classes. All new-stlye classes in Python ultimately inherits from the object class. [code language=\u0026quot;python\u0026quot;] In [4]: type(a) Out[4]: int\nIn [5]: int.mro() Out[5]: [int, object] [/code]\nNOTE: a is an instance of the int class, and int inturn inherits from the object class. Read more on Method Resolution Order.\nA unique ID representing the object. [code language=\u0026quot;python\u0026quot;] In [6]: id(a) Out[6]: 140090033476640 [/code]\nZero, One, or more names. Use dir() to check the current namespace. Use dir(\u0026lt;object-name\u0026gt;) to refer the indirect namespace. Several other builtins are available in the default namespace without defining them specifically, possible due to the inclusion of the builtin module available under the reference __builtin__ in the current namespace.\nFor a full list of the pre-defined variables, refer dir(__builtins__), help(__builtin__) or help(builtins) after an import builtins.\nA few questions and observations: Q1. How can an assignment have zero names in the namespace?\nAns: An assignment such as a = 1 creates an object in memory and creates a corresponding name (a in our case) in the namespace. a acts as a reference to the object in memory.\nBut, simply entering 1 at the python prompt creates an object in memory which is an instance of a type class, without creating the reference in the namespace.\nObjects which don't have a reference from the current namespace are usually garbage-collected due to lack of references. Hence, an object which doesn't have a reference (a name), or had multiple references (more than one names) but had them deleted (for example, del() gets garbage-collected by python.\nIf the assignment 1 happens to be at a python prompt, it echoes the literal back after creating the object and reference since the prompt is essentially a REPL (Read Eval Print loop)\nQ2. Can an object have more than one name references?\nAns: It's perfectly fine to have more than one reference to a single object. The example below should explain things very well.\n[code language=\u0026quot;python\u0026quot;] In [1]: a = 5000\nIn [2]: id(a) Out[2]: 140441367080400\nIn [3]: b = a\nIn [4]: b Out[4]: 5000\nIn [5]: id(b) Out[5]: 140441367080400\nIn [6]: c = 5000\nIn [7]: id(c) Out[7]: 140441367080432\nIn [8]: a is b Out[8]: True\nIn [9]: a == b Out[9]: True\nIn [10]: a is c Out[10]: False\nIn [11]: a == c Out[11]: True [/code]\nThe example shown above creates an object with value 5000 and assign it a name a in the current namespace. We checked the identifier of the object using id(a) and found out it to be 140441367080400.\nAs the next step, we created another name in the namespace, ie.. b which takes in whatever a points to. Hence, b would default to 5000 and it will have the same identifier as a.\nThis shows that an object in memory can have multiple references in a namespace.\nAnother object of value 5000 is created with a name c , but we can see that the identifier differs from what id(a) and id(b) is. This shows that c points to an entirely different object in memory.\nTo test if a is exactly the same object as b, use the keyword is. Meanwhile, if you want to test if two objects contain the same value, use the equality == symbol.\n","link":"https://arvimal.github.io/posts/2016/10/python-objects/","section":"posts","tags":["namespace","objects","programming","python-namespace","python-objects"],"title":"Python, Objects, and some more.."},{"body":"","link":"https://arvimal.github.io/tags/dentry/","section":"tags","tags":null,"title":"dentry"},{"body":"","link":"https://arvimal.github.io/tags/directory-entry-structure/","section":"tags","tags":null,"title":"directory-entry-structure"},{"body":"","link":"https://arvimal.github.io/tags/ext4/","section":"tags","tags":null,"title":"ext4"},{"body":"","link":"https://arvimal.github.io/tags/ext4_dir_entry/","section":"tags","tags":null,"title":"ext4_dir_entry"},{"body":"","link":"https://arvimal.github.io/tags/ext4_dir_entry_2/","section":"tags","tags":null,"title":"ext4_dir_entry_2"},{"body":"","link":"https://arvimal.github.io/tags/file-systems/","section":"tags","tags":null,"title":"file-systems"},{"body":"","link":"https://arvimal.github.io/tags/filesystem/","section":"tags","tags":null,"title":"filesystem"},{"body":"A recent discussion at work brought up the question \u0026quot;What can be the length of a file name in EXT4\u0026quot;. Or in other words, what would be the maximum character length of the name for a file in EXT4?\nWikipedia states that it's 255 Bytes, but how does that come to be? Is it 255 Bytes or 255 characters?\nIn the kernel source for the 2.6 kernel series (the question was for a RHEL6/EXT4 combination), in fs/ext4/ext4.h, we'd be able to see the following:\n[code language=\u0026quot;c\u0026quot;]\n#define EXT4_NAME_LEN 255\nstruct ext4_dir_entry { __le32 inode; /* Inode number */ __le16 rec_len; /* Directory entry length */ __le16 name_len; /* Name length */ char name[EXT4_NAME_LEN]; /* File name */ };\n/* * The new version of the directory entry. Since EXT4 structures are * stored in intel byte order, and the name_len field could never be * bigger than 255 chars, it's safe to reclaim the extra byte for the * file_type field. */\nstruct ext4_dir_entry_2 { __le32 inode; /* Inode number */ __le16 rec_len; /* Directory entry length */ __u8 name_len; /* Name length */ __u8 file_type; char name[EXT4_NAME_LEN]; /* File name */ }; [/code] This shows that there are two versions of the directory entry structure, ie.. ext4_dir_entry and ext4_dir_entry_2\nA directory entry structure carries the file/folder name and the corresponding inode number under every directory.\nBoth structs use an element named name_len to denote the length of the file/folder name.\nIf the EXT filesystem feature filetype is not set, the directory entry structure falls to the first method ext4_dir_entry, else it's the second, ie.. ext4_dir_entry_2.\nBy default, the file system feature filetype is set, hence the directory entry structure is ext4_dir_entry_2 . As seen above, in this case, the name_len field is set to 8 bits.\n__u8 represents an unsigned 8-bit integer in C, and can store values from 0 to 255.\nie.. 2^8 = 255 (0 t0 255 == 256)\next4_dir_entry has a name_len of __le16, but it seems that the file-name length can only go to a max of 256.\nObservations: The maximum name length is 255 characters on Linux machines. The actual name length of a file/folder is stored in name_len in each directory entry, under its parent folder. So if the file name length is 5 characters, 5 would be the value set for name_len for that particular file. ie.. the actual length. A character will consume a byte of storage, so the number of characters in a file name will map to the respective number bytes. If so, a file with a name_len of 5 will be using 5 bytes of memory to store the name. Hence, name_len denotes the number of characters that a file can have. Since U8 is 8-bits, name_len can store a file name with upto 255 chars.\nNow the actual memory being consumed for storing these characters is not denoted by name_len. Since the size of a character translates to a byte, the maximum size wrt memory that a file name can have is 255 Bytes.\nNOTE: The initial dir entry structure ext4_dir_entry had __le16 for name_len, it was later re-sized to __u8 in ext4_dir_entry_2 , by culling 8 bits from the existing 16 bits of name_len.\nThe remaining free space culled from name_len was assigned to store the file type, in ext4_dir_entry_2. It was named file_type with size __u8.\nfile_type helps to identity the file types such as regular files, sockets, character devices, block devices etc..\nReferences: RHEL6 kernel-2.6.32-573.el6 EXT4 header file (ext4.h) EXT4 Wiki - Disk layout http://unix.stackexchange.com/questions/32795/what-is-the-maximum-allowed-filename-and-folder-size-with-ecryptfs ","link":"https://arvimal.github.io/posts/2016/07/max-file-name-in-ext4/","section":"posts","tags":["dentry","directory-entry-structure","ext4","ext4_dir_entry","ext4_dir_entry_2","file-systems","filesystem","name_len"],"title":"Max file-name length in an EXT4 file system."},{"body":"","link":"https://arvimal.github.io/tags/name_len/","section":"tags","tags":null,"title":"name_len"},{"body":"","link":"https://arvimal.github.io/categories/techno/","section":"categories","tags":null,"title":"techno"},{"body":"","link":"https://arvimal.github.io/tags/inheritance/","section":"tags","tags":null,"title":"inheritance"},{"body":"_s_uper() is a feature through which inherited methods can be accessed, which has been overridden in a class. It can also help with the MRO lookup order in case of multiple inheritance. This may not be obvious first, but a few examples should help to drive the point home.\nInheritance and method overloading was discussed in a previous post, where we saw how inherited methods can be overloaded or enhanced in the child classes.\nIn many scenarios, it's needed to overload an inherited method, but also call the actual method defined in the Parent class.\nLet's start off with a simple example based on Inheritance, and build from there.\nExample 0:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object):\ndef func(self): print(\u0026quot;I'm being called from the Parent class!\u0026quot;)\nclass ChildClass(MyClass): pass\nmy_instance_1 = ChildClass() my_instance_1.func() [/code] This outputs:\n[code language=\u0026quot;python\u0026quot;] In [18]: %run /tmp/super-1.py I'm being called from the Parent class [/code] In Example 0, we have two classes, MyClass and ChildClass. The latter inherits from the former, and the parent class MyClass has a method named func defined.\nSince ChildClass inherits from MyClass, the child class has access to the methods defined in the parent class. An instance is created my_instance_2, for ChildClass.\nCalling my_instance_1.func() will print the statement from the Parent class, due to the inheritance.\nBuilding up on the first example:\nExample 1:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object):\ndef func(self): print(\u0026quot;I'm being called from the Parent class\u0026quot;)\nclass ChildClass(MyClass):\ndef func(self): print(\u0026quot;I'm being called from the Child class\u0026quot;)\nmy_instance_1 = MyClass() my_instance_2 = ChildClass()\nmy_instance_1.func() my_instance_2.func() [/code] This outputs:\n[code language=\u0026quot;python\u0026quot;] In [19]: %run /tmp/super-1.py I'm being called from the Parent class I'm being called from the Child class [/code] This example has a slight difference, both the child class as well as the parent class have the same method defined, ie.. func. In this scenario, the parent class' method is overridden by the child class method.\nie.. if we call the func() method from the instance of ChildClass, it need not go a fetch the method from its Parent class, since it's already defined locally.\nNOTE: This is due to the Method Resolution Order, discussed in an earlier post.\nBut what if there is a scenario that warranties the need for specifically calling methods defined in the Parent class, from the instance of a child class?\nie.. How to call the methods defined in the Parent class, through the instance of the Child class, even if the Parent class method is overloaded in the Child class?\nIn such a case, the inbuilt function super() can be used. Let's add to the previous example.\nExample 2:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object):\ndef func(self): print(\u0026quot;I'm being called from the Parent class\u0026quot;)\nclass ChildClass(MyClass):\ndef func(self): print(\u0026quot;I'm actually being called from the Child class\u0026quot;) print(\u0026quot;But...\u0026quot;) # Calling the `func()` method from the Parent class. super(ChildClass, self).func()\nmy_instance_2 = ChildClass() my_instance_2.func() [/code] This outputs:\n[code language=\u0026quot;python\u0026quot;] In [21]: %run /tmp/super-1.py I'm actually being called from the Child class But... I'm being called from the Parent class [/code]\nHow is the code structured? We have two classes MyClass and ChildClass. The latter is inheriting from the former. Both classes have a method named func The child class ChildClass is instantiated as my_instance_2 The func method is called from the instance. How does the code work? When the func method is called, the interpreter searches it using the Method Resolution Order, and find the method defined in the class ChildClass. Since it finds the method in the child class, it executes it, and prints the string \u0026quot;I'm actually being called from the Child class\u0026quot;, as well \u0026quot;But...\u0026quot; The next statement is super which calls the method func defined in the parent class of ChildClass Since the control is now passed onto the func method in the Parent class via super, the corresponding print() statement is printed to stdout. Example 2 can also be re-written as :\n[code language=\u0026quot;python\u0026quot;] class MyClass(object):\ndef func(self): print(\u0026quot;I'm being called from the Parent class\u0026quot;)\nclass ChildClass(MyClass):\ndef func(self): print(\u0026quot;I'm actually being called from the Child class\u0026quot;) print(\u0026quot;But...\u0026quot;) # Calling the `func()` method from the Parent class. # super(ChildClass, self).func() MyClass.func(self) # Call the method directly via Parent class\nmy_instance_2 = ChildClass() my_instance_2.func() [/code]\nNOTE: The example above uses the Parent class directly to access it's method. Even though it works, it is not the best way to do it since the code is tied to the Parent class name. If the Parent class name changes, the child/sub class code has to be changed as well.\nLet's see another example for super() . This is from our previous article on Inheritance and method overloading.\nExample 3:\n[code language=\u0026quot;python\u0026quot;] import abc\nclass MyClass(object):\n__metaclass__ = abc.ABCMeta\ndef my_set_val(self, value): self.value = value\ndef my_get_val(self): return self.value\n@abc.abstractmethod def print_doc(self): return\nclass MyChildClass(MyClass):\ndef my_set_val(self, value): if not isinstance(value, int): value = 0 super(MyChildClass, self).my_set_val(self)\ndef print_doc(self): print(\u0026quot;Documentation for MyChild Class\u0026quot;)\nmy_instance = MyChildClass() my_instance.my_set_val(100) print(my_instance.my_get_val()) print(my_instance.print_doc()) [/code] The code is already discussed here. The my_set_val method is defined in both the child class as well as the parent class.\nWe overload the my_set_val method defined in the parent class, in the child class. But after enhancing/overloading it, we call the my_set_val method specifically from the Parent class using super() and thus enhance it.\nTakeaway: super() helps to specifically call the Parent class method which has been overridden in the child class, from the child class. The super() in-built function can be used to call/refer the Parent class without explicitly naming them. This helps in situations where the Parent class name may change. Hence, super() helps in avoiding strong ties with class names and increases maintainability. super() helps the most when there are multiple inheritance happening, and the MRO ends up being complex. In case you need to call a method from a specific parent class, use super(). There are multiple ways to call a method from a Parent class. . super(, self). super(). References: https://docs.python.org/2/library/functions.html#super https://rhettinger.wordpress.com/2011/05/26/super-considered-super/ https://stackoverflow.com/questions/222877/how-to-use-super-in-python ","link":"https://arvimal.github.io/posts/2016/07/inheritance-and-super-oop/","section":"posts","tags":["inheritance","object-oriented-programming","python","super"],"title":"Inheritance and super() - Object Oriented Programming"},{"body":"","link":"https://arvimal.github.io/tags/super/","section":"tags","tags":null,"title":"super"},{"body":"_E_xt3 and Ext4 recently have been the most commonly used file system on Linux machines.\nWhat does uninit_bg actually do?\nRead https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout\nsection `Meta Block Groups and Lazy Block Group Initialization`.\nhttps://ext4.wiki.kernel.org/index.php/Frequently_Asked_Questions\nhttps://www.thomas-krenn.com/en/wiki/Ext4_Filesystem\nhttps://access.redhat.com/labs/psb/versions/kernel-3.10.0-327.18.2.el7/Documentation/filesystems/ext4.txt\nhttps://access.redhat.com/labs/psb/versions/kernel-3.10.0-327.18.2.el7/fs/ext4/ext4.h\n","link":"https://arvimal.github.io/posts/2016/06/uninit-bg-and-lazy-block-group-allocation/","section":"posts","tags":["ext3","ext4","file-systems","lazy-block-group-allocation","uninit_bg"],"title":"`uninit_bg` and lazy block group allocation in EXT3/4"},{"body":"","link":"https://arvimal.github.io/tags/ceph/","section":"tags","tags":null,"title":"ceph"},{"body":"","link":"https://arvimal.github.io/categories/ceph/","section":"categories","tags":null,"title":"ceph"},{"body":"","link":"https://arvimal.github.io/tags/ext3/","section":"tags","tags":null,"title":"ext3"},{"body":"","link":"https://arvimal.github.io/tags/lazy-block-group-allocation/","section":"tags","tags":null,"title":"lazy-block-group-allocation"},{"body":"","link":"https://arvimal.github.io/tags/rados/","section":"tags","tags":null,"title":"rados"},{"body":"","link":"https://arvimal.github.io/tags/rados-gateway/","section":"tags","tags":null,"title":"rados-gateway"},{"body":"","link":"https://arvimal.github.io/tags/rgw/","section":"tags","tags":null,"title":"rgw"},{"body":"","link":"https://arvimal.github.io/tags/rgw-index/","section":"tags","tags":null,"title":"rgw-index"},{"body":"","link":"https://arvimal.github.io/tags/sharding/","section":"tags","tags":null,"title":"sharding"},{"body":"_S_harding is the process of breaking down data onto multiple locations so as to increase parallelism, as well as distribute load. This is a common feature used in databases. Read more on this at Wikipedia.\nThe concept of sharding is used in Ceph, for splitting the bucket index in a RADOS Gateway.\nRGW or RADOS Gateway keeps an index for all the objects in its buckets for faster and easier lookup. For each RGW bucket created in a pool, the corresponding index is created in the XX.index pool.\nFor example, for each of the buckets created in .rgw pool, the bucket index is created in .rgw.buckets.index pool. For each bucket, the index is stored in a single RADOS object.\nWhen the number of objects increases, the size of the RADOS object increases as well. Two problems arise due to the increased index size.\nRADOS does not work good with large objects since it's not designed as such. Operations such as recovery, scrubbing etc.. work on a single object. If the object size increases, OSDs may start hitting timeouts because reading a large object may take a long time. This is one of the reason that all RADOS client interfaces such as RBD, RGW, CephFS use a standard 4MB object size. Since the index is stored in a single RADOS object, only a single operation can be done on it at any given time. When the number of objects increases, the index stored in the RADOS object grows. Since a single index is handling a large number of objects, and there is a chance the number of operations also increase, parallelism is not possible which can end up being a bottleneck. Multiple operations will need to wait in a queue since a single operation is possible at a time. In order to work around these problems, the bucket index is sharded into multiple parts. Each shard is kept on a separate RADOS object within the index pool.\nSharding is configured with the tunable bucket_index_max_shards . By default, this tunable is set to 0 which means that there are no shards.\nHow to check if Sharding is set? List the buckets [code language=\u0026quot;bash\u0026quot;] # radosgw-admin metadata bucket list [ \u0026quot;my-new-bucket\u0026quot; ] [/code]\nGet information on the bucket in question[code language=\u0026quot;bash\u0026quot;]\n# radosgw-admin metadata get bucket:my-new-bucket { \u0026quot;key\u0026quot;: \u0026quot;bucket:my-new-bucket\u0026quot;, \u0026quot;ver\u0026quot;: { \u0026quot;tag\u0026quot;: \u0026quot;_bGZAVUgayKVwGNgNvI0328G\u0026quot;, \u0026quot;ver\u0026quot;: 1 }, \u0026quot;mtime\u0026quot;: 1458940225, \u0026quot;data\u0026quot;: { \u0026quot;bucket\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;my-new-bucket\u0026quot;, \u0026quot;pool\u0026quot;: \u0026quot;.rgw.buckets\u0026quot;, \u0026quot;data_extra_pool\u0026quot;: \u0026quot;.rgw.buckets.extra\u0026quot;, \u0026quot;index_pool\u0026quot;: \u0026quot;.rgw.buckets.index\u0026quot;, \u0026quot;marker\u0026quot;: \u0026quot;default.2670570.1\u0026quot;, \u0026quot;bucket_id\u0026quot;: \u0026quot;default.2670570.1\u0026quot; }, \u0026quot;owner\u0026quot;: \u0026quot;rgw_user\u0026quot;, \u0026quot;creation_time\u0026quot;: 1458940225, \u0026quot;linked\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;has_bucket_info\u0026quot;: \u0026quot;false\u0026quot; } }\n[/code]\nUse the bucket ID to get more information, including the number of shards.\n[code language=\u0026quot;bash\u0026quot;] radosgw-admin metadata get bucket.instance:my-new-bucket:default.2670570.1 { \u0026quot;key\u0026quot;: \u0026quot;bucket.instance:my-new-bucket:default.2670570.1\u0026quot;, \u0026quot;ver\u0026quot;: { \u0026quot;tag\u0026quot;: \u0026quot;_xILkVKbfQD7reDFSOB4a5VU\u0026quot;, \u0026quot;ver\u0026quot;: 1 }, \u0026quot;mtime\u0026quot;: 1458940225, \u0026quot;data\u0026quot;: { \u0026quot;bucket_info\u0026quot;: { \u0026quot;bucket\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;my-new-bucket\u0026quot;, \u0026quot;pool\u0026quot;: \u0026quot;.rgw.buckets\u0026quot;, \u0026quot;data_extra_pool\u0026quot;: \u0026quot;.rgw.buckets.extra\u0026quot;, \u0026quot;index_pool\u0026quot;: \u0026quot;.rgw.buckets.index\u0026quot;, \u0026quot;marker\u0026quot;: \u0026quot;default.2670570.1\u0026quot;, \u0026quot;bucket_id\u0026quot;: \u0026quot;default.2670570.1\u0026quot; }, \u0026quot;creation_time\u0026quot;: 1458940225, \u0026quot;owner\u0026quot;: \u0026quot;rgw_user\u0026quot;, \u0026quot;flags\u0026quot;: 0, \u0026quot;region\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;placement_rule\u0026quot;: \u0026quot;default-placement\u0026quot;, \u0026quot;has_instance_obj\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;quota\u0026quot;: { \u0026quot;enabled\u0026quot;: false, \u0026quot;max_size_kb\u0026quot;: -1, \u0026quot;max_objects\u0026quot;: -1 }, \u0026quot;num_shards\u0026quot;: 0, \u0026quot;bi_shard_hash_type\u0026quot;: 0 }, \u0026quot;attrs\u0026quot;: [ { \u0026quot;key\u0026quot;: \u0026quot;user.rgw.acl\u0026quot;, \u0026quot;val\u0026quot;: \u0026quot;AgKPAAAAAgIaAAAACAAAAHJnd191c2VyCgAAAEZpcnN0IFVzZXIDA2kAAAABAQAAAAgAAAByZ3dfdXNlcg8AAAABAAAACAAAAHJnd191c2VyAwM6AAAAAgIEAAAAAAAAAAgAAAByZ3dfdXNlcgAAAAAAAAAAAgIEAAAADwAAAAoAAABGaXJzdCBVc2VyAAAAAAAAAAA=\u0026quot; }, { \u0026quot;key\u0026quot;: \u0026quot;user.rgw.idtag\u0026quot;, \u0026quot;val\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;key\u0026quot;: \u0026quot;user.rgw.manifest\u0026quot;, \u0026quot;val\u0026quot;: \u0026quot;\u0026quot; } ] } }\n[/code] Note that `num_shards` is set to 0, which means that sharding is not enabled.\nHow to configure Sharding? To configure sharding, we need to first dump the region info.\nNOTE: By default, RGW has a region named default even if regions are not configured.\n[code language=\u0026quot;bash\u0026quot;] # radosgw-admin region get \u0026gt; /tmp/region.txt\n# cat /tmp/region.txt { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;api_name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;is_master\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;endpoints\u0026quot;: [], \u0026quot;hostnames\u0026quot;: [], \u0026quot;master_zone\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;zones\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;endpoints\u0026quot;: [], \u0026quot;log_meta\u0026quot;: \u0026quot;false\u0026quot;, \u0026quot;log_data\u0026quot;: \u0026quot;false\u0026quot;, \u0026quot;bucket_index_max_shards\u0026quot;: 0 } ], \u0026quot;placement_targets\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default-placement\u0026quot;, \u0026quot;tags\u0026quot;: [] } ], \u0026quot;default_placement\u0026quot;: \u0026quot;default-placement\u0026quot; }\n[/code] Edit the file /tmp/region.txt, change the value for `bucket_index_max_shards` to the needed shard value (we're setting it to 8 in this example), and inject it back to the region.\n[code language=\u0026quot;bash\u0026quot;] # radosgw-admin region set \u0026lt; /tmp/region.txt { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;api_name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;is_master\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;endpoints\u0026quot;: [], \u0026quot;hostnames\u0026quot;: [], \u0026quot;master_zone\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;zones\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default\u0026quot;, \u0026quot;endpoints\u0026quot;: [], \u0026quot;log_meta\u0026quot;: \u0026quot;false\u0026quot;, \u0026quot;log_data\u0026quot;: \u0026quot;false\u0026quot;, \u0026quot;bucket_index_max_shards\u0026quot;: 8 } ], \u0026quot;placement_targets\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;default-placement\u0026quot;, \u0026quot;tags\u0026quot;: [] } ], \u0026quot;default_placement\u0026quot;: \u0026quot;default-placement\u0026quot; } [/code] Reference:\nRed Hat Ceph Storage 1.3 Rados Gateway documentation https://en.wikipedia.org/wiki/Shard_(database_architecture) ","link":"https://arvimal.github.io/posts/2016/06/sharding-the-ceph-rgw-bucket-index/","section":"posts","tags":["ceph","rados","rados-gateway","rgw","rgw-index","sharding"],"title":"Sharding the Ceph RADOS Gateway bucket index"},{"body":"","link":"https://arvimal.github.io/tags/uninit_bg/","section":"tags","tags":null,"title":"uninit_bg"},{"body":"","link":"https://arvimal.github.io/tags/abstract-methods/","section":"tags","tags":null,"title":"abstract-methods"},{"body":"","link":"https://arvimal.github.io/tags/abstractmethod/","section":"tags","tags":null,"title":"abstractmethod"},{"body":"","link":"https://arvimal.github.io/tags/builtins/","section":"tags","tags":null,"title":"builtins"},{"body":"_I_nheritance is a usual theme in Object Oriented Programming. Because of Inheritance, the functions/methods defined in parent classes can be called in Child classes which enables code reuse, and several other features. In this article, we try to understand some of those features that come up with Inheritance.\nWe've discussed Abstract Methods in an earlier post, which is a feature part of Inheritance, and can be applied on child classes that inherits from a Parent class.\nE the methods which are inherited can also be seen as another feature or possibility in Inheritance. In many cases, it's required to override or specialize the methods inherited from the Parent class. This is of course possible, and is called as 'Method Overloading'.\nConsider the two classes and its methods defined below:\nExample 0:\n[code language=\u0026quot;python\u0026quot;] import abc\nclass MyClass(object):\n__metaclass__ = abc.ABCMeta\ndef __init__(self): pass\ndef my_set_method(self, value): self.value = value\ndef my_get_method(self): return self.value\n@abc.abstractmethod def printdoc(self): return\nclass MyChildClass(MyClass):\ndef my_set_method(self, value): if not isinstance(value, int): value = 0 super(MyChildClass, self).my_set_method(self)\ndef printdoc(self): print(\u0026quot;\\nDocumentation for MyChildClass()\u0026quot;)\ninstance_1 = MyChildClass() instance_1.my_set_method(10) print(instance_1.my_get_method()) instance_1.printdoc() [/code]\nWe have two classes, the parent class being MyClass and the child class being MyChildClass.\nMyClass has three methods defined.\nmy_set_method() my_get_method() printdoc() The printdoc() method is an Abstract method, and hence should be implemented in the Child class as a mandatory method.\nThe child class MyChildClass inherits from MyClass and has access to all it's methods.\nNormally, we can just go ahead and use the methods defined in MyClass , in MyChildClass. But there can be situations when we want to improve or build upon the methods inherited. As said earlier, this is called Method Overloading.\nMyChildClass extends the parent's my_set_method() function by it's own implementation. In this example, it does an additional check to understand if the input value is an int or not, and then calls the my_set_method() of it's parent class using super. Hence, this method in the child class extends the functionality prior calling method in the parent. A post on super is set for a later time.\nEven though this is a trivial example, it helps to understand how the features inherited from other classes can be extended or improved upon via method overloading.\nThe my_get_method() is not overridden in the child class but still called from the instance, as instance_1.my_get_method(). We're using it as it is available via Inheritance. Since it's defined in the parent class, it works in the child class' instance when called, even if not overridden.\nThe printdoc() method is an abstract method and hence is mandatory to be implemented in the child class, and can be overridden with what we choose to do.\nInheritance is possible from python builtins, and can be overridden as well. Let's check out another example:\nExample 1:\n[code language=\u0026quot;python\u0026quot;] class MyList(list):\ndef __getitem__(self, index): if index == 0: raise IndexError if index \u0026gt; 0: index -= 1 return list.__getitem__(self, index)\ndef __setitem__(self, index, value): if index == 0: raise IndexError if index \u0026gt; 0: index -= 1 list.__setitem__(self, index, value)\nx = MyList(['a', 'b', 'c']) print(x) print(\u0026quot;-\u0026quot; * 10)\nx.append('d') print(x) print(\u0026quot;-\u0026quot; * 10)\nx.__setitem__(4, 'e') print(x) print(\u0026quot;-\u0026quot; * 10)\nprint(x[1]) print(x.__getitem__(1)) print(\u0026quot;-\u0026quot; * 10)\nprint(x[4]) print(x.__getitem__(4)) [/code] This outputs:\n[code language=\u0026quot;python\u0026quot;] ['a', 'b', 'c'] ---------- ['a', 'b', 'c', 'd'] ---------- ['a', 'b', 'c', 'e'] ---------- a a ---------- e e [/code]\nHow does the code work? The class MyList() inherits from the builtin list. Because of the inheritance, we can use list's available magic methods such as __getitem__() , __setitem__() etc..\nNOTE: In order to see the available methods in list, use dir(list).\nWe create two functions/methods named `__getitem__()` and `__setitem__()` to override the inherited methods. Within these functions/methods, we set our own conditions. Wie later call the builtin methods directly within these functions, using list.__getitem__() list.__setitem__() We create an instance named x from MyList(). We understand that x[1] and x.__getitem__(1) are same. x[4, 'e'] and x.__setitem__(4, 'e') are same. x.append(f) is same as x.__setitem__(\u0026lt;n\u0026gt;, f) where is the element to the extreme right which the python interpreter iterates and find on its own. Hence, in Inheritance, child classes can:\nInherit from parent classes and use those methods. Parent classes can either be user-defined classes or buitins like list , dict etc.. Override (or Overload) an inherited method. Extend an inherited method in its own way. Implement an Abstract method the parent class requires. Reference: Python beyond the basics - Object Oriented Programming ","link":"https://arvimal.github.io/posts/2016/06/inheritance-and-method-overloading-oop/","section":"posts","tags":["abstract-methods","abstractmethod","builtins","inheritance","method-overloading"],"title":"Inheritance and Method overloading - Object Oriented Programming"},{"body":"","link":"https://arvimal.github.io/tags/method-overloading/","section":"tags","tags":null,"title":"method-overloading"},{"body":"_A_bstract classes, in short, are classes that are supposed to be inherited or subclassed, rather than instantiated.\nThrough Abstract Classes, we can enforce a blueprint on the subclasses that inherit the Abstract Class. This means that Abstract classes can be used to define a set of methods that must be implemented by it subclasses.\nAbstract classes are used when working on large projects where classes have to be inherited, and need to strictly follow certain blueprints.\nPython supports Abstract Classes via the module abc from version 2.6. Using the abc module, its pretty straight forward to implement an Abstract Class.\nExample 0:\n[code language=\u0026quot;python\u0026quot;] import abc\nclass My_ABC_Class(object): __metaclass__ = abc.ABCMeta\n@abc.abstractmethod def set_val(self, val): return\n@abc.abstractmethod def get_val(self): return\n# Abstract Base Class defined above ^^^\n# Custom class inheriting from the above Abstract Base Class, below\nclass MyClass(My_ABC_Class):\ndef set_val(self, input): self.val = input\ndef get_val(self): print(\u0026quot;\\nCalling the get_val() method\u0026quot;) print(\u0026quot;I'm part of the Abstract Methods defined in My_ABC_Class()\u0026quot;) return self.val\ndef hello(self): print(\u0026quot;\\nCalling the hello() method\u0026quot;) print(\u0026quot;I'm *not* part of the Abstract Methods defined in My_ABC_Class()\u0026quot;)\nmy_class = MyClass()\nmy_class.set_val(10) print(my_class.get_val()) my_class.hello() [/code] In the code above, set_val() and get_val() are both abstract methods defined in the Abstract Class My_ABC_Class(). Hence it should be implemented in the child class inheriting from My_ABC_Class().\nIn the child class MyClass() , we have to strictly define the abstract classes defined in the Parent class. But the child class is free to implement other methods of their own. The hello() method is one such.\nThis will print :\n[code language=\u0026quot;bash\u0026quot;] # python abstractclasses-1.py\nCalling the get_val() method I'm part of the Abstract Methods defined in My_ABC_Class() 10\nCalling the hello() method I'm *not* part of the Abstract Methods defined in My_ABC_Class() [/code] The code gets executed properly even if the hello() method is not an abstract method.\nLet's check what happens if we don't implement a method marked as an abstract method, in the child class.\nExample 1:\n[code language=\u0026quot;python\u0026quot;] import abc\nclass My_ABC_Class(object): __metaclass__ = abc.ABCMeta\n@abc.abstractmethod def set_val(self, val): return\n@abc.abstractmethod def get_val(self): return\n# Abstract Base Class defined above ^^^\n# Custom class inheriting from the above Abstract Base Class, below\nclass MyClass(My_ABC_Class):\ndef set_val(self, input): self.val = input\ndef hello(self): print(\u0026quot;\\nCalling the hello() method\u0026quot;) print(\u0026quot;I'm *not* part of the Abstract Methods defined in My_ABC_Class()\u0026quot;)\nmy_class = MyClass()\nmy_class.set_val(10) print(my_class.get_val()) my_class.hello() [/code] Example 1 is the same as Example 0 except we don't have the get_val() method defined in the child class.\nThis means that we're breaking the rule of abstraction. Let's see what happens:\n[code language=\u0026quot;bash\u0026quot;] # python abstractclasses-2.py Traceback (most recent call last): File \u0026quot;abstractclasses-2.py\u0026quot;, line 50, in my_class = MyClass() TypeError: Can't instantiate abstract class MyClass with abstract methods get_val [/code]\nThe traceback clearly states that the child class MyClass() cannot be instantiated since it does not implement the Abstract methods defined in it's Parent class.\nWe mentioned that an Abstract class is supposed to be inherited rather than instantiated. What happens if we try instantiating an Abstract class?\nLet's use the same example, this time we're instantiating the Abstract class though.\nExample 2:\n[code language=\u0026quot;python\u0026quot;] import abc\nclass My_ABC_Class(object): __metaclass__ = abc.ABCMeta\n@abc.abstractmethod def set_val(self, val): return\n@abc.abstractmethod def get_val(self): return\n# Abstract Base Class defined above ^^^\n# Custom class inheriting from the above Abstract Base Class, below\nclass MyClass(My_ABC_Class):\ndef set_val(self, input): self.val = input\ndef hello(self): print(\u0026quot;\\nCalling the hello() method\u0026quot;) print(\u0026quot;I'm *not* part of the Abstract Methods defined in My_ABC_Class()\u0026quot;)\nmy_class = My_ABC_Class() # \u0026lt;- Instantiating the Abstract Class\nmy_class.set_val(10) print(my_class.get_val()) my_class.hello() [/code] What does this output?\n[code language=\u0026quot;bash\u0026quot;] # python abstractclasses-3.py Traceback (most recent call last): File \u0026quot;abstractclasses-3.py\u0026quot;, line 54, in my_class = My_ABC_Class() TypeError: Can't instantiate abstract class My_ABC_Class with abstract methods get_val, set_val [/code] As expected, the Python interpreter says that it can't instantiate the abstract class My_ABC_Class.\nTakeaway: An Abstract Class is supposed to be inherited, not instantiated. The Abstraction nomenclature is applied on the methods within a Class. The abstraction is enforced on methods which are marked with the decorator @abstractmethod or @abc.abstractmethod, depending on how you imported the module, from abc import abstractmethod or import abc. It is not mandatory to have all the methods defined as abstract methods, in an Abstract Class. Subclasses/Child classes are enforced to define the methods which are marked with @abstractmethod in the Parent class. Subclasses are free to create methods of their own, other than the abstract methods enforced by the Parent class. Reference: https://pymotw.com/2/abc/ Python beyond the basics - Object Oriented Programming ","link":"https://arvimal.github.io/posts/2016/06/abc-oop-python/","section":"posts","tags":["abstract-base-class","abstract-methods","abstractmethod","object-oriented-programming","programming","python"],"title":"Abstract Base Classes/Methods - Object Oriented Programming"},{"body":"","link":"https://arvimal.github.io/tags/abstract-base-class/","section":"tags","tags":null,"title":"abstract-base-class"},{"body":"_T_his article was long overdue and should have been published before many of the articles in this blog. Better late than never.\nself in Python is usually used in an Object Oriented nomenclature, to denote the instance/object created from a Class.\nIn short, self is the instance itself.\nLet's check the following example:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object): def __init__(self, name): self.name = name print(\u0026quot;Initiating the instance!\u0026quot;)\ndef hello(self): print(self.name)\nmyclass = MyClass(\u0026quot;Dan Inosanto\u0026quot;)\n# Calling the `hello` method via the Instance `myclass` myclass.hello()\n# Calling the `hello` method vai the class. MyClass.hello(myclass) [/code]\nThe code snippet above is trivial and stupid, but I think it gets the idea across.\nWe have a class named MyClass() which takes a name value as an argument. It also prints the string \u0026quot;Initiating the instance\u0026quot;. The name value is something that has to be passed while creating an instance.\nThe function hello() just prints the name value that is passed while instantiating the class MyClass().\nWe instantiate the class MyClass() as myclass and pass the string Dan Inosanto as an argument. Read about the great Inosanto here.\nNext, we call the hello() method through the instance. ie..\n[code language=\u0026quot;python\u0026quot;] myclass.hello() [/code]\nThis should print the name we passed while instantiating MyClass() as myclass , which should be pretty obvious.\nThe second and last instruction is doing the same thing, but in a different way.\n[code language=\u0026quot;python\u0026quot;] MyClass.hello(myclass) [/code] Here, we call the class MyClass() directly as well as it's method hello(). Let's check out what both prints:\n[code language=\u0026quot;bash\u0026quot;] # python /tmp/test.py\nInitiating the instance! Dan Inosanto Dan Inosanto [/code]\nAs we can see, both prints the same output. This means that :\nmyclass.hello(self) == MyClass.hello(myclass)\nIn general, we can say that:\n.(self) == .()\nie.. The keyword self actually represents the instance being instantiated from the Class. Hence self can be seen as Syntactic sugar.\n","link":"https://arvimal.github.io/posts/2016/06/self-in-python/","section":"posts","tags":null,"title":"`self` in Python - Object Oriented Programming"},{"body":"_F_unctions defined under a class are also called methods. Most of the methods are accessed through an instance of the class.\nThere are three types of methods:\nInstance methods Static methods Class methods Both Static methods and Class methods can be called using the @staticmethod and @classmethod syntactic sugar respectively.\nInstance methods _I_nstance methods are also called Bound methods since the instance is bound to the class via self. Read a simple explanation on self here.\nAlmost all methods are Instance methods since they are accessed through instances.\nFor example:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object):\ndef set_val(self, val): self.value = val\ndef get_val(self): print(self.value) return self.value\na = MyClass() b = MyClass()\na.set_val(10) b.set_val(100)\na.get_val() b.get_val() [/code] The above code snippet shows manipulating the two methods set_val() and get_val() . These are done through the instances a and b. Hence these methods are called Instance methods.\nNOTE: Instance methods have self as their first argument. self is the instance itself.\nAll methods defined under a class are usually called via the instance instantiated from the class. But there are methods which can work without instantiating an instance.\nClass methods and Static methods don't require an instance, and hence don't need self as their first argument.\nStatic methods Static methods are functions/methods which doesn't need a binding to a class or an instance.\nStatic methods, as well as Class methods, don't require an instance to be called. Static methods doesn't need self or cls as the first argument since it's not bound to an instance or class. Static methods are normal functions, but within a class. Static methods are defined with the keyword @staticmethod above the function/method. Static methods are usually used to work on Class Attributes. ============================= A note on class attributes\nAttributes set explicitly under a class (not under a function) are called Class Attributes.\nFor example:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object): value = 10\ndef my_func(self): pass [/code] In the code snippet above, value = 10 is an attribute defined under the class MyClass() and not under any functions/methods. Hence, it's called a Class attribute. =============================\nLet's check out an example on static methods and class attributes:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object): # A class attribute count = 0\ndef __init__(self, name): print(\u0026quot;An instance is created!\u0026quot;) self.name = name MyClass.count += 1\n# Our class method @staticmethod def status(): print(\u0026quot;The total number of instances are \u0026quot;, MyClass.count)\nprint(MyClass.count)\nmy_func_1 = MyClass(\u0026quot;MyClass 1\u0026quot;) my_func_2 = MyClass(\u0026quot;MyClass 2\u0026quot;) my_func_3 = MyClass(\u0026quot;MyClass 3\u0026quot;)\nMyClass.status() print(MyClass.count) [/code] This prints the following:\n[code language=\u0026quot;bash\u0026quot;] # python statismethod.py\n0 An instance is created! An instance is created! An instance is created!\nThe total number of instances are 3 3 [/code]\nHow does the code work?\nThe example above has a class MyClass() with a class attribute count = 0. An __init__ magic method accepts a name variable. The __init__ method also increments the count in the count counter at each instantiation. We define a staticmethod status() which just prints the number of the instances being created. The work done in this method is not necessarily associated with the class or any functions, hence its defined as a staticmethod. We print the initial value of the counter count via the class, as MyClass.count. This will print 0since the counter is called before any instances are created. We create three instances from the class MyClass We can check the number of instances created through the status() method and the count counter. Another example:\n[code language=\u0026quot;python\u0026quot;] class Car(object):\ndef sound(): print(\u0026quot;vroom!\u0026quot;) [/code]\nThe code above shows a method which is common to all the Car instances, and is not limited to a specific instance of Car. Hence, this can be called as a staticmethod since it's not necessarily bound to a Class or Instance to be called.\n[code language=\u0026quot;python\u0026quot;] class Car(object):\n@staticmethod def sound(): print(\u0026quot;vroom!\u0026quot;) [/code]\nClass methods We can define functions/methods specific to classes. These are called Class methods.\nThe speciality of a class methods is that an instance is not required to access a class method. It can be called directly via the Class name.\nClass methods are used when it's not necessary to instantiate a class to access a method.\nNOTE: A method can be set as a Class method using the decorator @classmethod.\nExample:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object): value = 10\n@classmethod def my_func(cls): print(\u0026quot;Hello\u0026quot;) [/code]\nNOTE: Class methods have cls as their first argument, instead of self.\nExample:\n[code language=\u0026quot;python\u0026quot;] class MyClass(object): count = 0\ndef __init__(self, val): self.val = val MyClass.count += 1\ndef set_val(self, newval): self.val = newval\ndef get_val(self): return self.val\n@classmethod def get_count(cls): return cls.count\nobject_1 = MyClass(10) print(\u0026quot;\\nValue of object : %s\u0026quot; % object_1.get_val()) print(MyClass.get_count())\nobject_2 = MyClass(20) print(\u0026quot;\\nValue of object : %s\u0026quot; % object_2.get_val()) print(MyClass.get_count())\nobject_3 = MyClass(40) print(\u0026quot;\\nValue of object : %s\u0026quot; % object_3.get_val()) print(MyClass.get_count()) [/code] Here, we use a get_count() function to get the number of times the counter was incremented. The counter is incremented each time an instance is created.\nSince the counter is not really tied with the instance but only counts the number of instance, we set it as a classmethod, and calls it each time using MyClass.get_count()when an instance is created. The output looks as following:\n[code language=\u0026quot;bash\u0026quot;] # python classmethod.py\nValue of object : 10 1\nValue of object : 20 2\nValue of object : 40 3 [/code]\nCourtsey: This was written as part of studying class and static methods. Several articles/videos have helped including but not limited to the following:\nhttps://jeffknupp.com/blog/2014/06/18/improve-your-python-python-classes-and-object-oriented-programming/ Python beyond the basics - Object Oriented Programming - O'Reilly Learning Paths ","link":"https://arvimal.github.io/posts/2016/06/instance-class-static-method-oop/","section":"posts","tags":null,"title":"Instance, Class, and Static methods - Object Oriented Programming"},{"body":"Magic methods _M_agic methods are special methods which can be defined (or already designed and available) to act on objects.\nMagic methods start and end with underscores \u0026quot;__\u0026quot;, and are not implicitly called by the user even though they can be. Most magic methods are used as syntactic sugar by binding it to more clear/easy_to_understand keywords.\nPython is mostly objects and method calls done on objects. Many available functions in Python are actually tied to magic methods_._ Let's checkout a few examples.\nExample 0:\n[code language=\u0026quot;python\u0026quot;] In [1]: my_var = \u0026quot;Hello!\u0026quot;\nIn [2]: print(my_var) Hello!\nIn [3]: my_var.__repr__() Out[3]: \u0026quot;'Hello!'\u0026quot; [/code] As we can see, the __repr__() magic method can be called to print the object, ie.. it is bound to the print() keyword.\nThis is true for many other builtin keywords/operators as well.\nExample 1:\n[code language=\u0026quot;python\u0026quot;] In [22]: my_var = \u0026quot;Hello, \u0026quot; In [23]: my_var1 = \u0026quot;How are you?\u0026quot;\nIn [24]: my_var + my_var1 Out[24]: 'Hello, How are you?'\nIn [25]: my_var.__add__(my_var1) Out[25]: 'Hello, How are you?' [/code] Here, Python interprets the + sign as a mapping to the magic method __add__(), and calls it on the L-value (Left hand object value) my_var, with the R-value (Right hand object value) as the argument.\nWhen a builtin function is called on an object, in many cases it is mapped to the magic method.\nExample 2:\n[code language=\u0026quot;python\u0026quot;] In [69]: my_list_1 = ['a', 'b', 'c', 'd']\nIn [70]: 'a' in my_list_1 Out[70]: True\nIn [71]: my_list_1.__contains__(\u0026quot;a\u0026quot;) Out[71]: True [/code]\nThe in builtin is mapped to the __contains__()method.\nThe methods available for an object should mostly be dependent on the type of the object.\nExample 3:\n[code language=\u0026quot;python\u0026quot; wraplines=\u0026quot;true\u0026quot;] In [59]: my_num = 1\nIn [60]: type(my_num) Out[60]: int\nIn [61]: my_num.__doc__ Out[61]: Out[61]: \u0026quot;int(x=0) -\u0026gt; int or long\\nint(x, base=10) -\u0026gt; int or long\\n\\nConvert a number or string to an integer, or return 0 if no arguments\\nare given. ....\u0026gt;\u0026gt;\u0026gt;\nIn [62]: help(my_num) class int(object) | int(x=0) -\u0026gt; int or long | int(x, base=10) -\u0026gt; int or long | | Convert a number or string to an integer, or return 0 if no arguments | are given. If x is floating point, the conversion truncates towards zero. | If x is outside the integer range, the function returns a long instead.\n[/code]\nFrom the tests above, we can understand that the help() function is actually mapped to the object.__doc__ magic method. It's the same doc string that __doc__ and help() uses.\nNOTE: Due to the syntax conversion (+ to __add__(),and other conversions), operators like + , in, etc.. are also called Syntactic sugar.\nWhat is Syntactic sugar? _A_ccording to Wikipedia, Syntact sugar is:\nIn computer science, syntactic sugar is syntax within a programming language that is designed to make things easier to read or to express. It makes the language \u0026quot;sweeter\u0026quot; for human use: things can be expressed more clearly, more concisely, or in an alternative style that some may prefer.\nHence, magic methods can be said to be Syntactic sugar. But it's not just magic methods that are mapped to syntactic sugar methods, but higher order features such as Decorators are as well.\nExample 4:\n[code language=\u0026quot;python\u0026quot;] def my_decorator(my_function): def inner_decorator(): print(\u0026quot;This happened before!\u0026quot;) my_function() print(\u0026quot;This happens after \u0026quot;) print(\u0026quot;This happened at the end!\u0026quot;) return inner_decorator\ndef my_decorated(): print(\u0026quot;This happened!\u0026quot;)\nvar = my_decorator(my_decorated)\nif __name__ == '__main__': var() [/code] The example above borrows from one of the examples in the post on Decorators.\nHere, my_decorator() is a decorator and is used to decorate my_decorated(). But rather than calling the decorator function my_decorator() with the argument my_decorated(), the above code can be syntactically sugar-coated as below:\n[code language=\u0026quot;python\u0026quot;] def my_decorator(my_function): def inner_decorator(): print(\u0026quot;This happened before!\u0026quot;) my_function() print(\u0026quot;This happens after \u0026quot;) print(\u0026quot;This happened at the end!\u0026quot;) return inner_decorator\n@my_decorator def my_decorated(): print(\u0026quot;This happened!\u0026quot;)\nif __name__ == '__main__': my_decorated() [/code] Observing both code snippets, the decorator is syntactically sugar coated and called as:\n@my_decorator\ninstead of instantiating the decorator with the function to be decorated as an argument, ie..\nvar = my_decorator(my_decorated)\nA few syntax resolution methods: 'name' in my_list -\u0026gt; my_list.__contains__('name') len(my_list) -\u0026gt; my_list.__len__() print(my_list) -\u0026gt; my_list.__repr__() my_list == \u0026quot;value\u0026quot; -\u0026gt; my_list.__eq__(\u0026quot;value\u0026quot;) my_list[5] -\u0026gt; my_list.__getitem__(5) my_list[5:10] -\u0026gt; my_list.__getslice__(5, 10) NOTE: This article is written from the notes created while learning magic methods. The following articles (along with several others) were referred as part of the process.\nA Guide to Python's Magic Methods, by Rafe Kettler Special method names, The Official Python 3 documentation ","link":"https://arvimal.github.io/posts/2016/06/magic-methods-in-python/","section":"posts","tags":["programming","python"],"title":"Magic methods and Syntactic sugar in Python"},{"body":"","link":"https://arvimal.github.io/tags/classmethod/","section":"tags","tags":null,"title":"classmethod"},{"body":"","link":"https://arvimal.github.io/tags/decorators/","section":"tags","tags":null,"title":"decorators"},{"body":"_D_ecorators are wrapper functions (or classes) that wrap and modify another function (or class), and change it's behavior as required. Decorators help to modify your code without actually modifying the working function/class itself.\nThere are several inbuilt Decorators in Python, such as @classmethod and @staticmethod. Examples on these are due for another post.\nDecorators are called to act upon a function or class, by mentioning the Decorator name just above the function/class.\nDecorators are written such as it returns a function, rather than output something.\nExample 0:\n[code language='python'] @my_decorator def my_func(): print(\u0026quot;Hello\u0026quot;)\nmy_func() [/code]\nIn the above code snippet, when my_func() is called, the python interpreter calls the decorator function my_decorator, executes it, and then passes the result to my_func().\nThe example above doesn't do anything worth, but the following example should help to get a better idea.\nNOTE: The examples below are taken from the excellent talks done by Jillian Munson (in PyGotham 2014) and Mike Burns for ThoughtBot. The URLs are at [1] and [2]. All credit goes to them.\nExample 1:\n[code language=\u0026quot;python\u0026quot;] def my_decorator(my_function): def inner_decorator(): print(\u0026quot;This happened before!\u0026quot;) my_function() print(\u0026quot;This happens after \u0026quot;) print(\u0026quot;This happened at the end!\u0026quot;) return inner_decorator\n@my_decorator def my_decorated(): print(\u0026quot;This happened!\u0026quot;)\nif __name__ == '__main__': my_decorated() [/code]\nComponents: A function named my_decorated(). A decorator function named my_decorator(). The decorator function my_decorator() has a function within itself named inner_decorator(). The decorator function my_decorator(), returns the inner function inner_decorator(). Every function should return a value, if not it defaults to None. my_decorator() decorator should return the inner_decorator() inner function, else the decorator cannot be used with the my_decorated() function. To understand this, test with 'return None' for the decorator function my_decorator(). The inner function inner_decorator() is the one that actually decorates (modifies) the function my_decorated(). The decorator function is called on the function my_decorated() using the format @my_decorator. The decorator function takes an argument, which can be named whatever the developer decides. When the decorator function is executed, the argument is replaced with the function name on which the decorator is executed. In our case, it would be my_decorated() How does the code work? The function my_decorated() is called. The interpreter sees that the decorator @my_decorator is called wrt this function. The interpreter searches for a function named my_decorator()and executes it. Since the decorator function returns the inner function inner_decorator(), the python interpreter executes the inner function. It goes through each steps, reaches my_function() , and gets it executed. Once that function is executed, it goes back and continues with the execution of the decorator my_decorator(). Output: [code language=\u0026quot;bash\u0026quot;] # python decorators-1.py This happened before! # Called from the decorator This happened! # Called from the function This happens after # Called from the decorator This happened at the end! # Called from the decorator [/code]\nExample 2:\n[code language=\u0026quot;python\u0026quot;] def double(my_func): def inner_func(a, b): return 2 * my_func(a, b) return inner_func\n@double def adder(a, b): return a + b\n@double def subtractor(a, b): return a - b\nprint(adder(10, 20)) print(subtractor(6, 1)) [/code]\nComponents: Two functions named adder() and subtractor(). A decorator function named double(). The decorator has an inner function named inner_func() which does the actual intended work. The decorator returns the value of the inner function inner_func() Both the adder() and subtractor()functions are decorated with the decorator double() How does the code work? We call the adder() and subtractor() functions with a print(), since the said functions don't print by default (due to the return statement). The python interpreter sees the decorator @double and calls it. Since the decorator returns the inner function inner_func(), the interpreter executes it. The decorator takes an argument my_func, which is always the function on which the decorator is applied, ie.. in our case my_case == adder()and my_case == subtractor(). The inner function within the decorator takes arguments, which are the arguments passed to the functions that are being decorated. ie.. Any arguments passed to adder() and subtractor()are passed to inner_func(). The statement return 2 * my_func(a, b) returns the value of : 2 x adder(10, 20) 2 x subtractor(6, 1) Output: [code language=\u0026quot;bash\u0026quot;] # python decorators-2.py 60 10 [/code]\nInbuilt decorators such as @staticmethod and @classmethod will be discussed in an upcoming post.\nNOTE: To see how decorators are syntactically sugar coated, read Magic methods and Syntactic sugar in Python\n","link":"https://arvimal.github.io/posts/2016/05/decorators-object-oriented-programming/","section":"posts","tags":["classmethod","decorators","object-oriented-programming","programming","python","staticmethod"],"title":"Decorators - Object Oriented Programming"},{"body":"","link":"https://arvimal.github.io/tags/staticmethod/","section":"tags","tags":null,"title":"staticmethod"},{"body":"Ceph OSD daemons need to ensure that the neighbouring OSDs are functioning properly so that the cluster remains in a healthy state.\nFor this, each Ceph OSD process (ceph-osd) sends a heartbeat signal to the neighbouring OSDs. By default, the heartbeat signal is sent every 6 seconds [1], which is configurable of course.\nIf the heartbeat check from one OSD doesn't hear from the other within the set value for `osd_heartbeat_grace` [2], which is set to 20 seconds by default, the OSD that sends the heartbeat check reports the other OSD (the one that didn't respond within 20 seconds) as down, to the MONs. Once an OSD reports three times that the non-responding OSD is indeed `down`, the MON acknowledges it and mark the OSD as down.\nThe Monitor will update the Cluster map and send it over to the participating nodes in the cluster.\nWhen an OSD can't reach another OSD for a heartbeat, it reports the following in the OSD logs:\nosd.510 1497 heartbeat_check: no reply from osd.11 since back 2016-04-28 20:49:42.088802\nIn Ceph Jewel, the MONs require a minimum of two ceph OSDs report a specific OSD as down from two nodes which are in different CRUSH subtrees, in order to actually mark the OSD as down. These are controlled by the following tunables :\nFrom 'common/config_opts.h':\n[1] OPTION(mon_osd_min_down_reporters, OPT_INT, 2) // number of OSDs from different subtrees who need to report a down OSD for it to count\n[2] OPTION(mon_osd_reporter_subtree_level , OPT_STR, \u0026quot;host\u0026quot;) // in which level of parent bucket the reporters are counted\nImage Courtsey : Red Hat Ceph Storage 1.3.2 Configuration guide\n","link":"https://arvimal.github.io/posts/2016/05/ceph-osd-heartbeats/","section":"posts","tags":["ceph","monitors"],"title":"Ceph OSD heartbeats"},{"body":"","link":"https://arvimal.github.io/tags/monitors/","section":"tags","tags":null,"title":"monitors"},{"body":"Many a user wants to know if a Ceph cluster installation has been done to a specific suggested guideline.\nTechnologies like RAID is better avoided in Ceph due to an additional layer, which Ceph already takes care of.\nI've started writing a tool which can be run from the Admin node, and it aims to check various such points.\nThe code can be seen at https://github.com/arvimal/ceph_check\nThe work is slow, really slow, due to my daily work, procrastination, and what not, even though I intend to finish this fast.\n","link":"https://arvimal.github.io/posts/2016/05/ceph-check/","section":"posts","tags":null,"title":"`ceph-check` - A Ceph installation checker"},{"body":"","link":"https://arvimal.github.io/tags/big-o-notation/","section":"tags","tags":null,"title":"big-o-notation"},{"body":"Efficiency or Complexity is how well you're using your resources to get your code run.\nEfficiency can be calculated on the basis of how much time your code takes to run/execute.\nUnderstanding the efficiency of your code can help to reduce the complexity, thus improving the runtime efficiency further. Getting the same job done in less time and less system resources is always good.\nOnce you find the efficiency of your program, you can start to find ways for:\nReducing the complexity (or increase the efficiency) which will reduce the program run time, and hence free the computer resources in a proportional rate. Try to maintain a constant or reduced run time for a growing data set, which will help your program to fare well when the input size grows. In Computer Science, the `Big O` notation is used to indicate the effieciency or complexity of a program. It is denoted by 'O(n)', where 'n' is a mathematical function to denote the input. This is\nSome examples:\nO(n) O(n³) O(n log(n)) O(√n) O(O(n) + 1) or O(1)\nEfficiency can be measures on the best, average, and worst cases. For example, consider finding a specific alphabet from a list of all the alphabets jumbled up.\nThe worst case is your program running through all 26 iterations and finding the alphabet as the last value. The best case is when your program finds it in the first iteration itself. The average is when your program finds the alphabet somewhere around 12-15 iterations (ie.. half of the worst case scenario). Study of Data structures and Algorithms aim to study program complexities, and to reduce it as much as possible.\nAlgorithms are a series of well-defined steps you follow to solve a problem, whereas Data Structures are specific structures by which how you layout your data. Application of well-known algorithms in a program can help in reducing the run time.\nMore on Time complexity and the Big O notation can be read at:\nhttps://en.wikipedia.org/wiki/Time_complexity https://en.wikipedia.org/wiki/Big_O_notation\n","link":"https://arvimal.github.io/posts/2016/05/big-o-notation/","section":"posts","tags":["algorithms","big-o-notation","code-complexity","data-structures","on"],"title":"Code complexity - The Big O notation [O(n)]"},{"body":"","link":"https://arvimal.github.io/tags/code-complexity/","section":"tags","tags":null,"title":"code-complexity"},{"body":"Arrays are a commonly used data structure, and is one of the first a DS student looks into.\nIt is created as a collection of memory addresses which are contiguous in memory. These memory locations store data of a specific type depending on the array's type.\nAdvantages:\nArrays are easier to create since the size and type is mentioned at the creation time. Arrays have constant access/lookup time since the lookup is done by accessing the memory location as an offset from the base/first element. Hence the complexity will be O(1). Arrays are contiguous in memory, ie.. a 10 cell array can start at perhaps 0x0001 and end at 0x0010. Disadvantages:\nThe size of an array has to be defined at the time of its creation. This make the size static, and hence cannot be resized later. An array can only accomodate a specific data type. The type of data an array can store has to be defined at creation time. Hence, if an array is set to store integers, it can only store integers in each memory location. Since the size of an array is set at the time of creation, allocating an array may fail depending on the size of the array and the available memory on the machine. Inserting an element into an array can be expensive depending on the location. To insert an element at a particular position, for example 'n', the element already has to be moved to 'n + 1', the element at 'n + 1' to 'n + 2' etc.. Hence, if the position to which the element is written to is at the starting of the array, the operation will be expensive. But if the position is at the starting, it won't be. What is the lookup time in an array?\nThe elements in an array are continuguous to each other. The address of an element is looked up as an `offset` of the primary or base element. Hence, the lookup of any element in the array is constant and can be denoted by O(1).\nArrays in Python\nPython doesn't have a direct implementation of an Array. The one that closely resembles an array in python is a `list`.\nThe major differences between an array and a list are:\nThe size of lists are not static. It can be grown or shrinked using the `append` and `remove` methods. Arrays are static in size. lists can accomodate multiple data types, while arrays cannot. [code language=\u0026quot;python\u0026quot;] In [1]: mylist = []\nIn [2]: type(mylist) Out[2]: list\nIn [3]: mylist.append(\u0026quot;string\u0026quot;)\nIn [4]: mylist.append(1000)\nIn [5]: mylist Out[5]: ['string', 1000] [/code]\nTime complexity of Arrays\nIndexing - O(1) Insertion/Deletion at beginning - O(n) (If the array has space to shift the elements) Insertion/Deletion at the end - O(1) (If the array has space at the end) Deletion at the end - O(1) (Since it doesn't have to move any elements and reorder) Insertion at the middle - O(n) (Since it requires to move the elements to the right and reorder) Deletion at the middle - O(n) (Since it requires to delete the element and move the ones from the right to the left) The 'array' module\nPython comes with a module named 'array' which emulates the behavior of arrays.\n[code language=\u0026quot;python\u0026quot;] In [24]: import array\nIn [25]: myarray = array.array('i', [1,2,3,4])\nIn [26]: myarray Out[26]: array('i', [1, 2, 3, 4]) [/code]\n","link":"https://arvimal.github.io/posts/2016/05/data-structures-arrays/","section":"posts","tags":null,"title":"Data Structures - Arrays"},{"body":"","link":"https://arvimal.github.io/tags/data-structures/","section":"tags","tags":null,"title":"data-structures"},{"body":"To get a MON map or an OSD map of a specific epoch, use:\n# ceph osd getmap # ceph mon getmap The map can be forwarded to a file as following:\n# ceph osd getmap -o /tmp/ceph_osd_getmap.bin\nThis would be in a binary format, and hence will need to be dumped to a human-readable form.\n# osdmaptool --print /tmp/ceph-osd-getmap.bin\nThis will print the current OSD map, similar to the output of 'ceph osd dump'.\nWhere this command shines is when you can fetch maps from previous epochs, and pull information on specific placement groups in those epochs.\nFor example, I've had all the OSDs on one of my node down some time back (in a previous epoch). The ability to query a previous epoch gives the administrator the power to understand how exactly the cluster was at a specific time period.\n","link":"https://arvimal.github.io/posts/2016/05/ceph-mon-osd-map-at-epoch/","section":"posts","tags":null,"title":"How to get a Ceph MON/OSD map at a specific epoch?"},{"body":"","link":"https://arvimal.github.io/tags/on/","section":"tags","tags":null,"title":"on"},{"body":"This is a crude bash one-liner I did to get the details of all the RBD images, as well as the information on snapshots and clones created from them.\n[code language=\u0026quot;bash\u0026quot;] # for pool in `rados lspools`; do echo \u0026quot;POOL :\u0026quot; $pool; rbd ls -l $pool; echo \u0026quot;-----\u0026quot;; done [/code]\nThis will print an output similar to the following:\n[code language=\u0026quot;bash\u0026quot;] POOL : rbd NAME SIZE PARENT FMT PROT LOCK test_img 10240M 1 test_img2 1024M 2 test_img2@snap2 1024M 2 yes ----- POOL : .rgw.root ----- POOL : .rgw.control ----- POOL : .rgw ----- POOL : .rgw.gc ----- POOL : .users.uid ----- POOL : .users ----- POOL : .users.swift ----- POOL : .users.email ----- POOL : .rgw.buckets.index ----- POOL : images NAME SIZE PARENT FMT PROT LOCK clone1 1024M rbd/test_img2@snap2 2 ----- [/code]\n","link":"https://arvimal.github.io/posts/2015/10/list-ceph-pools-with-snapshots-and-rbd/","section":"posts","tags":null,"title":"List RBD images, snapshots, and clones in Ceph pools"},{"body":"","link":"https://arvimal.github.io/tags/enumerate/","section":"tags","tags":null,"title":"enumerate"},{"body":"","link":"https://arvimal.github.io/tags/range/","section":"tags","tags":null,"title":"range"},{"body":"The usual way to iterate over a range of numbers or a list in python, is to use range().\nExample 0:\n[code language=\u0026quot;python\u0026quot;] colors = [\u0026quot;yellow\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;black\u0026quot;]\nfor i in range(len(colors)): print(i, colors[i]) [/code]\nThis should output:\n[code language=\u0026quot;bash\u0026quot;] (0, 'yellow') (1, 'red') (2, 'blue') (3, 'white') (4, 'black') [/code]\nprint(), by default, returns a tuple. If we want to print it in a more presentable way, we’ll need to find the indice at which each value is, and print that as well. Re-write the code a bit, to achieve the desired output:\n[code language=\u0026quot;python\u0026quot;] colors = [\u0026quot;yellow\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;black\u0026quot;]\nfor i in range(len(colors)): color = colors[i] print(\u0026quot;%d: %s\u0026quot; % (i, color)) [/code]\nThis should print:\n[code language=\u0026quot;bash\u0026quot;] 0: yellow 1: red 2: blue 3: white 4: black [/code]\nWe can see that the above output starts with ‘0’ since python starts counting from ‘0’. To change that to ‘1’, we’ll need to tweak the print() statement.\n[code language=\u0026quot;python\u0026quot;] colors = [\u0026quot;yellow\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;black\u0026quot;]\nfor i in range(len(colors)): color = colors[i] print(\u0026quot;%d: %s\u0026quot; % (i + 1, color)) [/code]\nThis should print:\n[code language=\u0026quot;bash\u0026quot;] 1: yellow 2: red 3: blue 4: white 5: black [/code]\nEven though the above code snippet isn’t that complex, a much better way exists to do this. This is where the builtin function enumerate() comes in.\nenumerate() returns a tuple when passed an object which supports iteration, for example, a list. It also supports a second argument named 'start' which default to 0, and can be changed depending on where to start the order. We’ll check what 'start' is towards the end of this article.\n[code language=\u0026quot;python\u0026quot;] colors = [\u0026quot;yellow\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;black\u0026quot;] print(list(enumerate(colors))) [/code]\nThis returns a list of a tuples.\n[code language=\u0026quot;bash\u0026quot;] [(0, 'yellow'), (1, 'red'), (2, 'blue'), (3, 'white'), (4, 'black')] [/code]\nTo get to what we desire, modify it as:\n[code language=\u0026quot;python\u0026quot;] for i, color in enumerate(colors): print('%d: %s' % (i, color)) [/code]\nThis outputs:\n[code language=\u0026quot;bash\u0026quot;] 0: yellow 1: red 2: blue 3: white 4: black [/code]\nRemember that we talked about that enumerate() takes a second value named 'start' which defaults to ‘0’? Let’s check how that’ll help here.\nThe above output starts with ‘0’. 'start' can help to change that.\n[code language=\u0026quot;python\u0026quot;] for i, color in enumerate(colors, start=1): print('%d: %s' % (i, color)) [/code]\nThis should change the output as:\n[code language=\u0026quot;bash\u0026quot;] 1: yellow 2: red 3: blue 4: white 5: black [/code]\n","link":"https://arvimal.github.io/posts/2015/10/range-and-enumerate/","section":"posts","tags":["enumerate","programming","python","range"],"title":"range() and enumerate()"},{"body":"In certain cases, a Ceph cluster may move away from an HEALTHY state due to “unfound” objects.\nA “ceph -s” should show if you have any unfound objects. So, what are unfound objects? How does an object become “unfound”? This article tries to explain why/how “unfound” objects come into existence.\nLet’s look into the life cycle of a write to a pool.\nThe client contacts a Ceph monitor and fetches the CRUSH map, which includes: MON map OSD map PG map CRUSH map MDS map Once the client has the maps, the Ceph client-side algorithm breaks the data being written into objects (the object size depends on the client side configuration). Clients such as RBD and RGW uses a 4MB object size, but RADOS doesn’t actually have such a limitation.\nEach pool has a set of Placement Groups (PG) assigned to it at the time of creation, and the client always writes to a pool. Since the client has the maps which talks about the entire cluster, it knows the placement groups within the pool which it is writing to, and the OSDs assigned for each placement group. The client talks to the OSDs directly without going over any other path, such as a monitor.\nThe PG map will have the ACTING and UP OSD sets for each PG. To understand the ACTING set and UP set for the PGs, as well as a plethora of other information, use :\n[code language=\u0026quot;bash\u0026quot;] # ceph pg dump [/code]\nThe ACTING set is the current active set of OSDs that stores the replica sets for that particular PG. The UP set is the set of OSDs that are currently up and running. Usually, the ACTING set and UP set are the same. When an OSD in the ACTING set is not reachable, other OSDs wait for 5 minutes (which is configurable) for it to come back online (this is checked with a hearbeat).\nThe said OSD is removed out of the UP set when it is not accessible. If it doesn’t come back online within the configured period, the said OSD is marked out of the ACTING set, as well as the UP set. When it comes back, it is added back to the ACTING/UP set and a peering happens where the data is synced back.\nLet’s discuss the scenario where an “unfound” object came come into existence. Imagine a pool with a two replica configuration. A write that goes into the pool is split into objects and stored in the OSDs which are in the ACTIVE set of a PG.\nOne OSD in the ACTING set goes down. The write is done on the second OSD which is UP and ACTING. The first OSD which went down, came back up. The peering process started between the first OSD (that came back), and the second OSD (that serviced the write). Peering refers to the process of arriving at an understanding on the object states between the OSDs in an ACTING set, and sync up the metadata/data between them. Both the OSDs reach an understanding on which objects needs to be synced. The second OSD that had the objects ready to be synced, went down before the sync process starts or is in midway. In this situation, the first OSD knows about the objects that was written to the second OSD, but cannot probe it. The first OSD will try to probe possible locations for copies, provided there are more replicas. If the OSD is able to find other locations, the data will be synced up.\nBut in case there are no other copies, and the OSD with the only copy is not coming up anytime soon (perhaps a disk crash, file system corruption etc..) the only way is to either mark the object as “lost”, or revert it back to the previous version. Reverting to a previous version may not be possible for a new object, and in such cases the only way would be to mark it as “lost” or copy from a backup.\n1. For a new object without a previous version:\n[code language=\u0026quot;bash\u0026quot;] # ceph pg {pg.num} mark_unfound_lost delete [/code]\n2. For an object which is likely to have a previous version:\n[code language=\u0026quot;bash\u0026quot;] # ceph pg {pg.num} mark_unfound_lost revert [/code]\nNOTE: The upstream Ceph documentation has an excellent write-up about “unfound” objects here.\nI suggest reading the documentation prior taking any sort of action in a case where you see “unfound” objects in your cluster.\n","link":"https://arvimal.github.io/posts/2015/10/unfound-objects-in-ceph-cluster/","section":"posts","tags":null,"title":"Ceph and unfound objects"},{"body":"I recently came across a scenario where the objects in a RADOS pool used for an RBD block device doesn’t get removed, even if the files created through the mount point were removed.\nI had an RBD image from an RHCS1.3 cluster mapped to a RHEL7.1 client machine, with an XFS filesystem created on it, and mounted locally. Created a 5GB file, and I could see the objects being created in the rbd pool in the ceph cluster.\n1.RBD block device information\n[code language=\u0026quot;bash\u0026quot;] # rbd info rbd_img rbd image 'rbd_img': size 10240 MB in 2560 objects order 22 (4096 kB objects) block_name_prefix: rb.0.1fcbe.2ae8944a format: 1 [/code]\nAn XFS file system was created on this block device, and mounted at /test.\n2.Write a file onto the RBD mapped mount point. Used ‘dd’ to write a 5GB file.\n[code language=\u0026quot;bash\u0026quot;] # dd if=/dev/zero of=/mnt/rbd_image.img bs=1G count=5 5+0 records in 5+0 records out 5368709120 bytes (5.4 GB) copied, 8.28731 s, 648 MB/s [/code]\n3.Check the objects in the backend RBD pool\n[code language=\u0026quot;bash\u0026quot;] # rados -p rbd ls | wc -l \u0026lt; Total number of objects in the 'rbd' pool\u0026gt; [/code]\n4.Delete the file from the mount point.\n[code language=\u0026quot;bash\u0026quot;] # rm /test/rbd_image.img -f # ls /test/ --NO FILES LISTED-- [/code]\n5.List the objects in the RBD pool\n[code language=\u0026quot;bash\u0026quot;] # rados -p rbd ls | wc -l \u0026lt; Total number of objects in the 'rbd' pool \u0026gt; [/code]\nThe number of objects doesn’t go down as we expect, after the file deletion. It remains the same, wrt to step 3.\nWhy does this happen? This is due to the fact that traditional file systems do not delete the underlying data blocks even if the files are deleted.\nThe process of writing a file onto a file system involves several steps like finding free blocks and allocating them for the new file, creating an entry in the directory entry structure of the parent folder, setting the name and inode number in the directory entry structure, setting pointers from the inode to the data blocks allocated for the file etc..\nWhen data is written to the file, the data blocks are used to store the data. Additional information such as the file size, access times etc.. are updated in the inode after the writes.\nDeleting a file involves removing the pointers from the inode to the corresponding data blocks, and also clearing the name\u0026lt;-\u0026gt;inode mapping from the directory entry structure of the parent folder. But, the underlying data blocks are not cleared off, since that is a high I/O intensive operation. So, the data remains on the disk, even if the file is not present. A new write will make the allocator take these blocks for the new data, since they are marked as not-in-use.\nThis applies for the files created on an RBD device as well. The files created on top of the RBD-mapped mount point will ultimately be mapped to objects in the RADOS cluster. When the file is deleted from the mount point, since the entry is removed, it doesn’t show up in the mount point.\nBut, since the file system doesn’t clear off the underlying block device, the objects remain in the RADOS pool. These would be normally over-written when a new file is created via the mount point.\nBut this has a catch though. Since the pool contains the objects even if the files are deleted, it consumes space in the rados pool (even if they'll be overwritten). An administrator won't be able to get a clear understanding on the space usage, if the pool is used heavily, and multiple writes are coming in.\nIn order to clear up the underlying blocks, or actually remove them, we can rely on the TRIM support most modern disks offer. Read more about TRIM at Wikipedia.\nTRIM is a set of commands supported by HDD/SSDs which allow the operating systems to let the disk know about the locations which are not currently being used. Upon receiving a confirmation from the file system layer, the disk can go ahead and mark the blocks as not used.\nFor the TRIM commands to work, the disks and the file system has to have the support. All the modern file systems have built-in support for TRIM. Mount the file system with the 'discard' option, and you're good to go.\n[code language=\u0026quot;bash\u0026quot;] # mount -o discard /dev/rbd{X}{Y} /{mount-point} [/code]\n","link":"https://arvimal.github.io/posts/2015/10/rbd-object-remain-in-pool-after-deletion/","section":"posts","tags":["ceph","discard","fstrim","objects","rados","rados-block-device","rbd","trim"],"title":"Ceph Rados Block Device (RBD) and TRIM"},{"body":"","link":"https://arvimal.github.io/tags/discard/","section":"tags","tags":null,"title":"discard"},{"body":"","link":"https://arvimal.github.io/tags/fstrim/","section":"tags","tags":null,"title":"fstrim"},{"body":"","link":"https://arvimal.github.io/tags/rados-block-device/","section":"tags","tags":null,"title":"rados-block-device"},{"body":"","link":"https://arvimal.github.io/tags/rbd/","section":"tags","tags":null,"title":"rbd"},{"body":"","link":"https://arvimal.github.io/tags/trim/","section":"tags","tags":null,"title":"trim"},{"body":"Ceph supports custom rulesets via CRUSH, which can be used to sort hardware based on various features such as speed and other factors, set custom weights, and do a lot of other useful things.\nPools, or the buckets were the data is written to, can be created on the custom rulesets, hence positioning the pools on specific hardware as per the administrator's need.\nA large Ceph cluster may have lots of pools and rulesets specific for multiple use-cases. There may be times when we'd like to understand the pool to ruleset mapping.\nThe default CRUSH ruleset is named ‘replicated_ruleset’. The available CRUSH rulesets can be listed with:\n$ ceph osd crush rule ls\nOn a fresh cluster, or one without any custom rulesets, you’d find the following being printed to stdout.\n# ceph osd crush rule ls [ \u0026quot;replicated_ruleset\u0026quot; ]\nI’ve got a couple more on my cluster, and this is how it looks:\n# ceph osd crush rule ls [ \u0026quot;replicated_ruleset\u0026quot;, \u0026quot;replicated_ssd\u0026quot;, \u0026quot;erasure-code\u0026quot;]\nSince this article looks into the mapping of pools to CRUSH rulesets, it’d be good to add in how to list the pools, as a refresher.\n# ceph osd lspools\nOn my Ceph cluster, it turned out to be:\n# ceph osd lspools 0 data,1 metadata,2 rbd,21 .rgw,22 .rgw.root,23 .rgw.control,24 .rgw.gc,25 .users.uid,26 .users,27 .users.swift,28 test_pool,\nSince you have the pool name you’re interested in, let’s see how to map it to the ruleset. The command syntax is:\n# ceph osd pool get \u0026lt;pool_name\u0026gt; crush_ruleset\nI was interested to understand the ruleset on which the pool ‘test_pool’ was created. The command to list this was:\n# ceph osd pool get test_pool crush_ruleset crush_ruleset: 1\nPlease note that the rulesets are numbered from ‘0’, and hence ‘1’ would map to the CRUSH ruleset ‘replicated_ssd’.\nWe'll try to understand how a custom ruleset is created, in another article.\n","link":"https://arvimal.github.io/posts/2015/09/find-crush-ruleset-of-a-pool/","section":"posts","tags":null,"title":"Custom CRUSH rulesets and pools"},{"body":"","link":"https://arvimal.github.io/tags/osd/","section":"tags","tags":null,"title":"osd"},{"body":"In case you are trying to get the OSD ID and the corresponding node IP address mappings in a script-able format, use the following command:\n# ceph osd find This will print the OSD number, the IP address, the host name, and the default root in the CRUSH map, as a python dictionary.\n# ceph osd find 2 { \u0026quot;osd\u0026quot;: 2, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.112:6800\\/5311\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node4\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}}\nThe output is in json format, which has a key:value format. This can be parsed using awk/sed, or any programming languages that support json. All recent ones do.\nFor a listing of all the OSDs and related information, get the number of OSDs in the cluster, and then use that number to probe the OSDs.\n# for i in `seq 0 $(ceph osd stat | awk {'print $3'})`; do\nceph osd find $i; echo; done\nThis should output:\n{ \u0026quot;osd\u0026quot;: 0, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.244:6805\\/2579\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node3\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;ssd\u0026quot;}} { \u0026quot;osd\u0026quot;: 1, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.244:6800\\/955\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node3\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;ssd\u0026quot;}} { \u0026quot;osd\u0026quot;: 2, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.112:6800\\/5311\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node4\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 3, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.112:6805\\/5626\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node4\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 4, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.82:6800\\/4194\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node5\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 5, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.82:6805\\/4521\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node5\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 6, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.73:6801\\/5614\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node2\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;ssd\u0026quot;}} { \u0026quot;osd\u0026quot;: 7, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.73:6800\\/1719\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node2\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;ssd\u0026quot;}} { \u0026quot;osd\u0026quot;: 8, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.10:6805\\/5842\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node6\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 9, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.10:6800\\/4356\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node6\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 10, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.109:6800\\/4517\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node7\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}} { \u0026quot;osd\u0026quot;: 11, \u0026quot;ip\u0026quot;: \u0026quot;192.168.122.109:6805\\/4821\u0026quot;, \u0026quot;crush_location\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;node7\u0026quot;, \u0026quot;root\u0026quot;: \u0026quot;default\u0026quot;}}\n","link":"https://arvimal.github.io/posts/2015/09/listing-osd-nodes-scriptable/","section":"posts","tags":["ceph","osd"],"title":"OSD information in a scriptable format"},{"body":"The MON map is used by the monitors in a Ceph cluster, where they keep track of various attributes relevant to the working of the cluster.\nSimilar to the CRUSH map, a monitor map can be pulled out of the cluster, inspected, changed, and injected back to the monitors, manually. A frequent use-case is when the IP address of a monitor changes and the monitors cannot agree on a quorum.\nMonitors use the monitor map (monmap) to get the details of other monitors. So just changing the monitor address in 'ceph.conf' and pushing the configuration to all the nodes won't help to propagate the changes.\nIn most cases, starting the monitor with a wrong monitor map would make the monitors commit suicide, since they would find conflicting information about themself in the mon map due to the IP address change.\nThere are two methods to fix this problem, the first being adding enough new monitors, let them form a quorum, and remove the faulty monitors. This doesn't need any explanation. The second and more crude way, is to edit the monitor map directly, set the new IP address, and upload the monmap back to the monitors.\nThis article discusses the second method, ie.. how to edit the monmap, and re-inject it back. This can be done using the 'monmap' tool.\n1. As the first step, login to one of the monitors, and get the monitor map:\n# ceph mon getmap -o /tmp/monitor_map.bin\n2. Inspect what the monitor map contains:\n# monmaptool --print /tmp/monitor_map.bin\nAn example from my cluster : # monmaptool --print monmap\nmonmaptool: monmap file monmap epoch 1 fsid d978794d-5835-4ac3-8fe3-3855b18b9572 last_changed 0.000000 created 0.000000 0: 192.168.122.73:6789/0 mon.node2\n3. Remove the node which has the wrong IP address, referring it's hostname\n# monmaptool --rm node2 /tmp/monitor_map.bin\n4. Inspect the monitor map to see if the monitor is indeed removed.\n# monmaptool --print /tmp/monitor_map.bin\nmonmaptool: monmap file monmap epoch 1 fsid d978794d-5835-4ac3-8fe3-3855b18b9572 last_changed 0.000000 created 0.000000\n5. Add a new monitor (or the existing monitor with it's new IP)\n# monmaptool --add node3 192.168.122.76:6789 /tmp/monitor_map.bin\nmonmaptool: monmap file monmap monmaptool: writing epoch 1 to monmap (1 monitors)\n6. Check the monitor map to confirm the changes\n# monmaptool --print monmap\nmonmaptool: monmap file monmap epoch 1 fsid d978794d-5835-4ac3-8fe3-3855b18b9572 last_changed 0.000000 created 0.000000 0: 192.168.122.76:6789/0 mon.node3\n7. Make sure the mon processes are not running on the monitor nodes\n# service ceph stop mon\n8. Upload the changes\n# ceph-mon -i monitor_node --inject-monmap /tmp/mon_map.bin\n9. Start the mon process on each monitor\n# service ceph start mon\n10. Check if the cluster has taken in the changes.\n# ceph -s\n","link":"https://arvimal.github.io/posts/2015/09/view-change-inject-monitor-map/","section":"posts","tags":["ceph","monitors","monmaptool"],"title":"Monitor maps, how to edit them?"},{"body":"","link":"https://arvimal.github.io/tags/monmaptool/","section":"tags","tags":null,"title":"monmaptool"},{"body":"Recently, I had an incident where the OSDs were crashing at the time of startup. Obviously, the next step was to enable debug logs for the OSDs and understand where they were crashing.\nEnabled OSD debug logs dynamically by injecting it with:\n# ceph tell osd.* injectargs --debug-osd 20 --debug-ms 1\nNOTE: This command can be run from the MON nodes.\nOnce this was done, the OSDs were started manually (since it were crashing and not running) and watched out for the next crash. It crashed with the following logs :\n*read_log 107487'1 (0'0) modify f6b07b93/rbd_data.hash/head//12 by client.version date, time *osd/PGLog.cc: In function 'static bool PGLog::read_log(ObjectStore*, coll_t, hobject_t, const pg_info_t\u0026amp;, std::mapeversion_t, hobject_t\u0026amp;, PGLog::IndexedLog\u0026amp;, pg_missing_t\u0026amp;, std::ostringstream\u0026amp;, std::setstd::basic_stringchar *)' thread thread time date, time *osd/PGLog.cc: 809: FAILED assert(last_e.version.version e.version.version)ceph version version-details\n1: (PGLog::read_log(ObjectStore*, coll_t, hobject_t, pg_info_t const\u0026amp;, std::mapeversion_t, hobject_t, std::lesseversion_t, std::allocatorstd::paireversion_t const,hobject_t , PGLog::IndexedLog\u0026amp;, pg_missing_t\u0026amp;, std::basic_ostringstreamchar, std::char_traitschar, std::allocatorchar, std::setstd::string, std::lessstd:string, std::allocatorstd::string *)+0x13ee) [0x6efcae] 2: (PG::read_state(ObjectStore*, ceph::buffer::list\u0026amp;)+0x315) [0x7692f5] 3: (OSD::load_pgs()+0xfff) [0x639f8f] 4: (OSD::init()+0x7bd) [0x63c10d] 5: (main()+0x2613) [0x5ecd43] 6: (__libc_start_main()+0xf5) [0x7fdc338f9af5] 7: /usr/bin/ceph-osd() [0x5f0f69]\nThe above is a log snippet at which the OSD process was crashing. The ceph-osd process was reading through the log areas of each PG in the OSD, and once it reached the problematic PG it crashed due to failing an assert condition.\nChecking the source at 'osd/PGLog.cc', we see that this error is logged from 'PGLog::read_log'.\nvoid PGLog::read_log(ObjectStore *store, coll_t pg_coll, coll_t log_coll, ghobject_t log_oid, const pg_info_tinfo, mapeversion_t, hobject_tdivergent_priors, IndexedLoglog, pg_missing_tmissing, ostringstreamoss, setstring *log_keys_debug) { ... if (!log.log.empty()) { pg_log_entry_t last_e(log.log.back()); assert(last_e.version.version e.version.version); == The assert condition at which read_log is failing for a particular PG assert(last_e.version.epoch = e.version.epoch);\nIn order to make the OSD start, we needed to move this PG to a different location using the 'ceph_objectstore_tool' so that the ceph-osd can bypass the problematic PG. To understand the PG where it was crashing, we had to do some calculations based on the logs.\nThe 'read_log' line in the debug logs contain a hex value after the string \u0026quot;modify\u0026quot; and that is the hash of the PG number. The last number in that series is the pool id (12 in our case). The following python code will help to calculate the PG id based on the arguments passed to it.\nThis program accepts three arguments, the first being the hex value we talked about, the second being the pg_num of the pool, and the third one being the pool id.\n[code language=\u0026quot;python\u0026quot;]\n#!/usr/bin/env python # Calculate the PG ID from the object hash # vimal@redhat.com import sys\ndef pg_id_calc(*args): if any([len(args) == 0, len(args) \u0026gt; 3, len(args) \u0026lt; 3]): help() else: hash_hex = args[0] pg_num = int(args[1]) pool_id = int(args[2]) hash_dec = int(hash_hex, 16) id_dec = hash_dec % pg_num id = hex(id_dec) pg_id = str(pool_id) + \u0026quot;.\u0026quot; + str(id)[2:] print(\u0026quot;\\nThe PG ID is %s\\n\u0026quot; % pg_id)\ndef help(): print(\u0026quot;Usage:\u0026quot;) print(\u0026quot;This script expects the hash (in Hex), pg_num of the pool, and the pool id as arguments, in order\u0026quot;) print(\u0026quot;\\nExample:\u0026quot;) print(\u0026quot;./pg_id_calc.py 0x8e2fe5d7 2048 12\u0026quot;) sys.exit()\nif __name__ == '__main__': pg_id_calc(*sys.argv[1:])\n[/code]\nAn example of the program in action:\n# python pg_id_calc.py 0xf6b07b93 2048 12 The PG ID is 12.393\nOnce we get the PG ID, we can proceed using 'ceph_objectstore_tool' to move the PG to a different location altogether. More on how to use 'ceph_objectstore_tool' in an upcoming journal.\n","link":"https://arvimal.github.io/posts/2015/08/calculate-pg-id-from-ceph-osd-debug-logs/","section":"posts","tags":["ceph","pg","python"],"title":"Calculate a PG id from the hex values in Ceph OSD debug logs"},{"body":"","link":"https://arvimal.github.io/tags/pg/","section":"tags","tags":null,"title":"pg"},{"body":"Understanding the mapping of Pools and Placement Groups can be very useful while troubleshooting Ceph problems.\nA direct method is to dump information on the PGs via :\n# ceph pg dump\nThis command should output something like the following:\npg_stat objects mip degr unf bytes log disklog state 5.7a 0 0 0 0 0 0 0 active+clean\nThe output will have more information, and I've omitted it for the sake of explanation.\nThe first field is the PG ID, which are two values separated by a single dot (.). The left side value is the POOL ID, while the right side value is the actual PG number. It means that a specific PG can only be present under a specific pool, ie.. no PGs can be shared across pools. But please note that OSDs can be shared across multiple PGs.\nTo get the pools and associated numbers, use:\n# ceph osd lspools\n0 data,1 metadata,2 rbd,5 ssdtest,6 ec_pool,\nSo, the PG 5.7a belongs to the pool numbered '5', ie.. 'ssdtest', and the PG number is '7a'.\nThe output of 'ceph pg dump' also shows various important informations such as the Acting OSD set, the primary OSD, the last time the PG was reported, the state of the PG, the time at which a normal scrub as well as a deep-scrub was run etc..\n","link":"https://arvimal.github.io/posts/2015/08/map-pg-to-pool/","section":"posts","tags":["ceph","placement-groups","pool"],"title":"Mapping Placement Groups and Pools"},{"body":"","link":"https://arvimal.github.io/tags/placement-groups/","section":"tags","tags":null,"title":"placement-groups"},{"body":"","link":"https://arvimal.github.io/tags/pool/","section":"tags","tags":null,"title":"pool"},{"body":"In many cases, one would like to understand the journal disk a particular OSD is using. There are two methods to understand this:\na) This is the most direct method, and should give you details on the OSD disks and the corresponding journal disks.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph-disk list\n[/sourcecode]\nThis should output something like:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph-disk list /dev/sda : /dev/sda1 other, xfs, mounted on /boot /dev/sda2 other, LVM2_member /dev/sr0 other, unknown /dev/vda : /dev/vda1 ceph data, active, cluster ceph, osd.0, journal /dev/vda2 /dev/vda2 ceph journal, for /dev/vda1 /dev/vdb : /dev/vdb1 ceph data, active, cluster ceph, osd.1, journal /dev/vdc1 /dev/vdc : /dev/vdc1 ceph journal, for /dev/vdb1 [/sourcecode]\nb) The second method is cruder, and involves listing the OSD mount point on the file system.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ls -l /var/lib/ceph/osd/ceph-0/\ntotal 52 -rw-r--r--. 1 root root 191 Aug 3 18:02 activate.monmap -rw-r--r--. 1 root root 3 Aug 3 18:02 active -rw-r--r--. 1 root root 37 Aug 3 18:02 ceph_fsid drwxr-xr-x. 70 root root 4096 Aug 4 00:38 current -rw-r--r--. 1 root root 37 Aug 3 18:02 fsid lrwxrwxrwx. 1 root root 58 Aug 3 18:02 journal -\u0026gt; /dev/disk/by-partuuid/d9ebc4bd-7b5e-4e12-b909-0c72c4f58ee0 -rw-r--r--. 1 root root 37 Aug 3 18:02 journal_uuid -rw-------. 1 root root 56 Aug 3 18:02 keyring -rw-r--r--. 1 root root 21 Aug 3 18:02 magic -rw-r--r--. 1 root root 6 Aug 3 18:02 ready -rw-r--r--. 1 root root 4 Aug 3 18:02 store_version -rw-r--r--. 1 root root 42 Aug 3 18:02 superblock -rw-r--r--. 1 root root 0 Aug 5 13:09 sysvinit -rw-r--r--. 1 root root 2 Aug 3 18:02 whoami\n# ls -l /dev/disk/by-partuuid/d9ebc4bd-7b5e-4e12-b909-0c72c4f58ee0 lrwxrwxrwx. 1 root root 10 Aug 5 13:08 /dev/disk/by-partuuid/d9ebc4bd-7b5e-4e12-b909-0c72c4f58ee0 -\u0026gt; ../../vda2\n[/sourcecode]\nAs you can see, the file 'journal' is a symlink to the journal disk. The first method is much easier, but its always better to know how things are layered out underneath.\n","link":"https://arvimal.github.io/posts/2015/08/map-journal-disk-of-a-ceph-osd/","section":"posts","tags":null,"title":"How to identify the journal disk for a Ceph OSD?"},{"body":"","link":"https://arvimal.github.io/tags/calamari/","section":"tags","tags":null,"title":"calamari"},{"body":"'Calamari' is the monitoring interface for a Ceph cluster.\nThe Calamari interface password can be reset/changed using the 'calamari-ctl' command.\n# calamari-ctl change_password --password {password} {user-name}\ncalamari-ctl can also be used to add a user, as well as disable, enable, and rename the user account. A '--help' should print out all the available ones.\n# calamari-ctl --help\n","link":"https://arvimal.github.io/posts/2015/07/reset-calamari-interface-password/","section":"posts","tags":["calamari","ceph"],"title":"Resetting Calamari password"},{"body":"The Ceph monitor store growing to a big size is a common occurrence in a busy Ceph cluster.\nIf a 'ceph -s' takes considerable time to return information, one of the possibility is the monitor database being large.\nOther reasons included network lags between the client and the monitor, the monitor not responding properly due to the system load, firewall settings on the client or monitor etc..\nThe best way to deal with a large monitor database is to compact the monitor store. The monitor store is a leveldb store which stores key/value pairs.\nThere are two ways to compact a levelDB store, either on the fly or at the monitor process startup.\nTo compact the store dynamically, use :\n# ceph tell mon.[ID] compact\nTo compact the levelDB store every time the monitor process starts, add the following in /etc/ceph/ceph.conf under the [mon] section:\nmon compact on start = true\nThe second option would compact the levelDB store each and every time the monitor process starts.\nThe monitor database is stored at /var/lib/ceph/mon//store.db/ as files with the extension '.sst', which is the synonym for 'Sorted String Table'\nTo read more on levelDB, please refer:\nhttps://en.wikipedia.org/wiki/LevelDB\nhttp://leveldb.googlecode.com/svn/trunk/doc/impl.html\nhttp://google-opensource.blogspot.in/2011/07/leveldb-fast-persistent-key-value-store.html\n","link":"https://arvimal.github.io/posts/2015/07/compact-a-ceph-monitor-data-store/","section":"posts","tags":["ceph","leveldb","monitors"],"title":"Compacting a Ceph monitor store"},{"body":"","link":"https://arvimal.github.io/tags/leveldb/","section":"tags","tags":null,"title":"leveldb"},{"body":"","link":"https://arvimal.github.io/tags/scrubbing/","section":"tags","tags":null,"title":"scrubbing"},{"body":"Data Scrubbing is an error checking and correction method or routine check to ensure that the data on file systems are in pristine condition, and has no errors. Data integrity is of primary concern in today's conditions, given the humongous amounts of data being read and written daily.\nA simple example for a scrubbing, is a file system check done on file systems with tools like 'e2fsck' in EXT2/3/4, or 'xfs_repair' in XFS. Ceph also includes a daily scrubbing as well as weekly scrubbing, which we will talk about in detail in another article.\nThis feature is available on most hardware RAID controllers, backup tools, as well as softwares that emulate RAID such as MD-RAID.\nBtrfs is one of the file systems that can schedule a internal scrubbing automatically, to ensure that corruptions are detected and preventive measures taken automatically. Since Btrfs can maintain multiple copies of data, once it finds an error in the primary copy, it can check for a good copy (if mirroring is used) and replace it.\nWe will be looking more into scrubbing, especially how it is implemented in Ceph, and the various tunables, in an upcoming post.\n","link":"https://arvimal.github.io/posts/2015/07/what-is-data-scrubbing/","section":"posts","tags":["ceph","osd","scrubbing"],"title":"What is data scrubbing?"},{"body":"In a previous post, we saw how to dynamically change a tunable on a running Ceph cluster dynamically. Unfortunately, such a change is not permanent, and will revert back to the previous setting once ceph is restarted.\nRather than using the command 'ceph tell', I recently came upon another way to change configuration values.\nWe'll try changing the tunable 'mon_osd_full_ratio' once again.\n1. Get the current setting\n# ceph daemon osd.1 config get mon_osd_full_ratio { \u0026quot;mon_osd_full_ratio\u0026quot;: \u0026quot;0.75\u0026quot;}\n2. Change the configuration value using 'ceph daemon'.\n# ceph daemon osd.1 config set mon_osd_full_ratio 0.85 { \u0026quot;success\u0026quot;: \u0026quot;mon_osd_full_ratio = '0.85' \u0026quot;}\n3. Check if the change has been introduced.\n# ceph daemon osd.1 config get mon_osd_full_ratio { \u0026quot;mon_osd_full_ratio\u0026quot;: \u0026quot;0.85\u0026quot;}\n4. Restart the 'ceph' service\n# service ceph restart\n5. Check the status\n# ceph daemon osd.1 config get mon_osd_full_ratio { \u0026quot;mon_osd_full_ratio\u0026quot;: \u0026quot;0.75\u0026quot;}\nNOTE: Please note that the changes introduced with 'ceph tell' as well as 'ceph daemon' is not persistent across process restarts.\n","link":"https://arvimal.github.io/posts/2015/06/dynamically-change-ceph-configuration/","section":"posts","tags":["ceph"],"title":"Another method to dynamically change a Ceph configuration"},{"body":"You may have seen the 'noout' flag set in the output of 'ceph -s'. What does this actually mean?\nThis is a global flag for the cluster, which means that if an OSD is out, the said OSD is not marked out of the cluster and data balancing shouldn't start to maintain the replica count. By default, the monitors mark the OSDs out of the acting set if it is not reachable for 300 seconds, ie.. 5 minutes.\nTo know the default value set in your cluster, use:\n# ceph daemon /var/run/ceph/ceph-mon.*.asok config show | grep mon_osd_report_timeout\nWhen an OSD is marked as out, another OSD takes its place and data replication starts to that OSD depending on the number of replica counts each pool has.\nIf this flag (noout) is set, the monitor will not mark the OSDs out from the acting set. The PGs will be reporting an inconsistent state, but the OSD will still be in the acting set.\nThis can be helpful when we want to remove an OSD from the server, but don't want the data objects to be replicated over to another OSD.\nTo set the 'noout' flag, use:\n# ceph osd set noout\nOnce everything you've planned has been done/finished, you can reset it back using:\n# ceph osd unset noout\n","link":"https://arvimal.github.io/posts/2015/05/osds-noout-status/","section":"posts","tags":["ceph","noout","osd"],"title":"'noout' flag in Ceph"},{"body":"","link":"https://arvimal.github.io/tags/admin-socket/","section":"tags","tags":null,"title":"admin-socket"},{"body":"","link":"https://arvimal.github.io/tags/ceph-tell/","section":"tags","tags":null,"title":"ceph-tell"},{"body":"","link":"https://arvimal.github.io/tags/config-show/","section":"tags","tags":null,"title":"config-show"},{"body":"It is possible to change a particular configuration setting in a Ceph cluster dynamically, and I think it is a very neat and useful feature.\nImagine the case where you want to change the replica count of a particular PG from 3 to 4. How would you change this without restarting the Ceph cluster itself? That is where the 'ceph tell' command comes in.\nAs we saw in the previous post, you can get the list of configuration settings using the administrator socket, from either a monitor or an OSD node.\nTo change a configuration use:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph tell mon.* injectargs '--{tunable value_to_be_set}'\n[/sourcecode]\nFor example, to change the timeout value after which an OSD is out and down, can be changed with:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph tell mon.* injectargs '--mon_osd_report_timeout 400'\n[/sourcecode]\nBy default, it is 300 seconds, ie.. 5 minute\n","link":"https://arvimal.github.io/posts/2015/05/change-ceph-configurations-dynamically/","section":"posts","tags":["ceph","ceph-tell"],"title":"How to dynamically change a configuration value in a Ceph cluster?"},{"body":"In many cases we would like to get the active configurations from a Ceph node, either a monitor or an OSD node. A neat feature, I must say, is to probe the administrative socket file to get a listing of all the active configurations, be it on the OSD node or the monitor node.\nThis comes handy when we have changed a setting and wants to confirm if it had indeed changed or not.\nThe admin socket file exists for both the monitors and the OSD nodes. The monitor node will have a single admin socket file, while the OSD nodes will have an admin socket for each of the OSDs present on the node.\nListing of the admin socket on a monitor node [sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ls /var/run/ceph/ -l total 4 srwxr-xr-x. 1 root root 0 May 13 05:13 ceph-mon.hp-m300-2.asok -rw-r--r--. 1 root root 7 May 13 05:13 mon.hp-m300-2.pid [/sourcecode]\nListing of the admin sockets on an OSD node [sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ls -l /var/run/ceph/ total 20 srwxr-xr-x. 1 root root 0 May 8 02:42 ceph-osd.0.asok srwxr-xr-x. 1 root root 0 May 26 11:18 ceph-osd.2.asok srwxr-xr-x. 1 root root 0 May 26 11:18 ceph-osd.3.asok srwxr-xr-x. 1 root root 0 May 8 02:42 ceph-osd.4.asok srwxr-xr-x. 1 root root 0 May 26 11:18 ceph-osd.5.asok -rw-r--r--. 1 root root 8 May 8 02:42 osd.0.pid -rw-r--r--. 1 root root 8 May 26 11:18 osd.2.pid -rw-r--r--. 1 root root 8 May 26 11:18 osd.3.pid -rw-r--r--. 1 root root 8 May 8 02:42 osd.4.pid -rw-r--r--. 1 root root 8 May 26 11:18 osd.5.pid [/sourcecode]\nFor example, consider that we have changed the 'mon_osd_full_ratio' value, and need to confirm that the cluster has picked up the change.\nWe can get a listing of the active configured settings and grep out the setting we are interested in.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon /var/run/ceph/ceph-mon.*.asok config show\n[/sourcecode]\nThe above command prints out a listing of all the active configurations and their current values. We can easily grep out 'mon_osd_full_ratio' from this list.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon /var/run/ceph/ceph-mon.*.asok config show | grep mon_osd_full_ratio\n[/sourcecode]\nOn my test cluster, this printed out '0.75' which is the default setting. The cluster should print out 'near full' warnings once any OSD has reached 75% of its size.\nThis can be checked by probing the OSD admin socket as well.\nNOTE: In case you are probing a particular OSD, please make sure to use the OSD admin socket on the node in which the OSD is. In order to locate the OSD and the node it is on, use :\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph osd tree\n[/sourcecode]\nExample: We try probing the OSD admin socket on its node, for 'mon_osd_full_ratio' as we did on the monitor. It should return the same value.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon /var/run/ceph/ceph-osd.5.asok config show | grep mon_osd_full_ratio\n[/sourcecode]\nNOTE: Another command exists which should print the same configuration settings, but only for OSDs.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon osd.5 config show\n[/sourcecode]\nA drawback worth mentioning, this should be executed on the node on which the OSD is present. To find that the OSD to node mapping, use 'ceph osd tree'.\n","link":"https://arvimal.github.io/posts/2015/05/get-a-list-of-all-configurations-ceph-cluster/","section":"posts","tags":["admin-socket","ceph","config-show"],"title":"How to fetch the entire list of tunables along with the values for a Ceph cluster node?"},{"body":"","link":"https://arvimal.github.io/tags/noout/","section":"tags","tags":null,"title":"noout"},{"body":"","link":"https://arvimal.github.io/tags/crush/","section":"tags","tags":null,"title":"crush"},{"body":"","link":"https://arvimal.github.io/tags/crush-map/","section":"tags","tags":null,"title":"crush-map"},{"body":"","link":"https://arvimal.github.io/tags/fill-ratio/","section":"tags","tags":null,"title":"fill-ratio"},{"body":"There could be many scenarios where you'd need to change the percentage of space usage on a Ceph OSD. One such use case would be when your OSD space is about to hit the hard limit, and is constantly sending you warnings.\nFor some reason or other, you may need to extend the threshold limit for some time. In such a case, you don't need to change/add the configuration in ceph.conf and push it across. Rather you can do it while the cluster is online, via command mode.\nThe 'ceph tell' is a very useful command in the sense the administrator don't need to stop/start the OSDs, MONs etc.. after a configuration change. In our case, we are looking to set the 'mon_osd_full_ratio' to 98%. We can do it by using:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph tell mon.* injectargs \u0026quot;--mon_osd_full_ratio .98\u0026quot;\n[/sourcecode]\nIn an earlier post (https://goo.gl/xjXOoI) we had seen how to get all the configurable options from a monitor. If I understand correct, almost all the configuration values can be changed online by injecting the values using 'ceph tell'.\n","link":"https://arvimal.github.io/posts/2015/05/how-to-change-ceph-osd-filling-ratio/","section":"posts","tags":["ceph","fill-ratio","osd"],"title":"How to change the filling ratio for a Ceph OSD?"},{"body":"I'm still studying Ceph, and recently faced a scenario in which one of my Ceph nodes went down due to hardware failure. Even though my data was safe due to the replication factor, I was not able to remove the node from the cluster.\nI could remove the OSDs on the node, but I didn't find a way to remove the node being listed in 'ceph osd tree'. I ended up editing the CRUSH map by hand, to remove the host, and uploaded it back. This worked as expected. Following are the steps I did to achieve this.\na) This was the state just after the node went down:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph osd tree\n# id weight type name up/down reweight -10 .08997 root default -20 .01999 host hp-m300-5 00 .009995 osd.0 up 1 40 .009995 osd.4 up 1 -30 .009995 host hp-m300-9 10 .009995 osd.1 down 0 -40 .05998 host hp-m300-4 20 .04999 osd.2 up 1 30 .009995 osd.3 up 1\n[/sourcecode]\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph -w\ncluster 62a6a880-fb65-490c-bc98-d689b4d1a3cb health HEALTH_WARN 64 pgs degraded; 64 pgs stuck unclean; recovery 261/785 objects degraded (33.248%) monmap e1: 1 mons at {hp-m300-4=10.65.200.88:6789/0}, election epoch 1, quorum 0 hp-m300-4 osdmap e130: 5 osds: 4 up, 4 in pgmap v8465: 196 pgs, 4 pools, 1001 MB data, 262 objects 7672 MB used, 74192 MB / 81865 MB avail 261/785 objects degraded (33.248%) 64 active+degraded 132 active+clean [/sourcecode]\nI started with marking the OSDs on the node out, and removing them. Note that I don't need to stop the OSD (osd.1) since the node carrying osd.1 is down and not accessible.\nb) If not, you would've to stop the OSD using:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # sudo service osd stop osd.1 [/sourcecode]\nc) Mark the OSD out, this is not ideally needed in this case since the node is already out.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph osd out osd.1 [/sourcecode]\nd) Remove the OSD from the CRUSH map, so that it does not receive any data. You can also get the crushmap, de-compile it, remove the OSD, re-compile, and upload it back.\nRemove item id 1 with the name 'osd.1' from the CRUSH map.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph osd crush remove osd.1 [/sourcecode]\ne) Remove the OSD authentication key\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph auth del osd.1 [/sourcecode]\nf) At this stage, I had to remove the OSD host from the listing but was not able to find a way to do so. The 'ceph-deploy' didn't have any tools to do this, other than 'purge', and 'uninstall'. Since the node was not f) accessible, these won't work anyways. A 'ceph-deploy purge' failed with the following errors, which is expected since the node is not accessible.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph-deploy purge hp-m300-9\n[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [ceph_deploy.cli][INFO ] Invoked (1.5.22-rc1): /usr/bin/ceph-deploy purge hp-m300-9 [ceph_deploy.install][INFO ] note that some dependencies *will not* be removed because they can cause issues with qemu-kvm [ceph_deploy.install][INFO ] like: librbd1 and librados2 [ceph_deploy.install][DEBUG ] Purging from cluster ceph hosts hp-m300-9 [ceph_deploy.install][DEBUG ] Detecting platform for host hp-m300-9 ... ssh: connect to host hp-m300-9 port 22: No route to host [ceph_deploy][ERROR ] RuntimeError: connecting to host: hp-m300-9 resulted in errors: HostNotFound hp-m300-9\n[/sourcecode]\nI ended up fetching the CRUSH map, removing the OSD host from it, and uploading it back.\ng) Get the CRUSH map\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph osd getcrushmap -o /tmp/crushmap [/sourcecode]\nh) De-compile the CRUSH map\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # crushtool -d /tmp/crushmap -o crush_map [/sourcecode]\ni) I had to remove the entries pertaining to the host-to-be-removed from the following sections:\na) devices b) types c) And from the 'root' default section as well.\nj) Once I had the entries removed, I went ahead compiling the map, and inserted it back.\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # crushtool -c crush_map -o /tmp/crushmap # ceph osd setcrushmap -i /tmp/crushmap [/sourcecode]\nk) A 'ceph osd tree' looks much cleaner now :)\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;] # ceph osd tree\n# id weight type name up/down reweight -1 0.07999 root default -2 0.01999 host hp-m300-5 0 0.009995 osd.0 down 0 4 0.009995 osd.4 down 0 -4 0.06 host hp-m300-4 2 0.04999 osd.2 up 1 3 0.009995 osd.3 up 1 [/sourcecode]\nThere may be a more direct method to remove the OSD host from the listing. I'm not aware of anything relevant, based on my limited knowledge. Perhaps I'll come across something as I progress with Ceph. Comments welcome.\n","link":"https://arvimal.github.io/posts/2015/05/remove-a-host-from-ceph-cluster/","section":"posts","tags":["ceph","crush","crush-map","osd"],"title":"How to remove a host from a Ceph cluster?"},{"body":"","link":"https://arvimal.github.io/tags/admin_socket/","section":"tags","tags":null,"title":"admin_socket"},{"body":"","link":"https://arvimal.github.io/tags/ceph-admin-socket/","section":"tags","tags":null,"title":"ceph-admin-socket"},{"body":"","link":"https://arvimal.github.io/tags/ceph-conf/","section":"tags","tags":null,"title":"ceph-conf"},{"body":"It can be really helpful to have a single command to list all the configuration settings in a monitor node, in a Ceph cluster.\nThis is possible by interacting directly with the monitor's unix socket file. This can be found under /var/run/ceph/. By default, the admin socket for the monitor will be in the path /var/run/ceph/ceph-mon..asok.\nThe default location can vary in case you have defined it to be a different one, at the time of the installation. To know the actual socket path, use the following command:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph-conf --name mon.$(hostname -s) --show-config-value admin_socket\n[/sourcecode]\nThis should print the location of the admin socket. In most cases, it should be something like /var/run/ceph/ceph-mon.$(hostname -s).asok\nOnce you have the monitor admin socket, use that location to show the various configuration settings with:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon /var/run/ceph/ceph-mon.*.asok config show\n[/sourcecode]\nThe output would be long, and won't fit in a single screen. You can either pipe it to 'less' or grep for a specific value in case you know what you are looking for.\nFor example, if I need to look at the ratio at which the OSD would be considered full, I'll be using:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# ceph daemon /var/run/ceph/ceph-mon.*.asok config show | grep mon_osd_full_ratio\n[/sourcecode]\n","link":"https://arvimal.github.io/posts/2015/05/list-ceph-cluster-configurations/","section":"posts","tags":["admin_socket","ceph","ceph-admin-socket","ceph-conf","monitors","mons"],"title":"How to list all the configuration settings in a Ceph cluster monitor?"},{"body":"","link":"https://arvimal.github.io/tags/mons/","section":"tags","tags":null,"title":"mons"},{"body":"","link":"https://arvimal.github.io/tags/cachefilesd/","section":"tags","tags":null,"title":"cachefilesd"},{"body":"","link":"https://arvimal.github.io/tags/cachefs/","section":"tags","tags":null,"title":"cachefs"},{"body":"","link":"https://arvimal.github.io/tags/fscache/","section":"tags","tags":null,"title":"fscache"},{"body":"The 'cachefilesd' kernel module will create two directories at the location specified in /etc/cachefilesd.conf. By default it's /var/cache/fscache/.\n[root@montypython ~]# lsmod |grep -i cache cachefiles 40871 1 fscache 62354 3 nfs,cachefiles,nfsv4\nThose are /var/cache/fscache/cache and /var/cache/fscache/graveyard.\nThe cache structure is maintained inside '/var/cache/fscache/cache/', while anything that is retired or culled is moved to 'graveyard'. The 'cachefilesd' daemon monitors 'graveyard' using 'dnotify' and will delete anything that is in there.\nWe'll try an example. Consider an NFS share mounted with fscache support. The share contains the following files, with some random text.\n# ls /vol1 files1.txt files2.txt files3.txt files4.txt\na) Configure 'cachefiles' by editing '/etc/cachefilesd.conf', and start the 'cachefilesd' daemon.\n# systemctl start cachefilesd\nb) Mount the NFS share on the client with the 'fsc' mount option, to enable 'fscache' support.\n# sudo mount localhost:/vol1 /vol1-backup/ -o fsc\nd) Access the data from the mount point, and fscache will create the backed caching index at the location specified in /etc/cachefilesd.conf. By default, its /var/cache/fscache/\ne) Once the files are accessed on the client side, fscache builds an index as following:\nNOTE: The index structure is dependent on the netfs (NFS in our case). The netfs driver can structure the cache index as it seems fit.\nExplanation of the caching structure:\n# tree /var/cache/fscache/ /var/cache/fscache/cache/ └── @4a └── I03nfs ├── @22 │ └── Jo00000008400000000000000000000000400 │ └── @59 │ └── J110000000000000000w080000000000000000000000 │ ├── @53 │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ ├── @5e │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ ├── @61 │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ ├── @62 │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ ├── @70 │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ ├── @7c │ │ └── EE0g00sgwB-90600000000ww000000000000000 │ └── @e8 │ └── EE0g00sgwB-90600000000ww0000000000000000 └── @42 └── Jc000000000000EggDj00 └── @0a\na) The 'cache' directory under /var/cache/fscache/ is a special index and can be seen as the root of the entire cache index structure.\nb) Data objects (actual cached files) are represented as files if they have no children, or folders if they have. If represented as a directory, data objects will have a file inside named 'data' which holds the data.\nc) The 'cachefiles' kernel module represents :\ni) 'index' objects as 'directories', starting with either 'I' or 'J'.\nii) Data objects are represented with filenames, beginning with 'D' or 'E'.\niii) Special objects are similar to data objects, and start with 'S' or 'T'.\nIn general, any object would be represented as a folder, if that object has children.\ng) In the directory hierarchy, immediately between the parent object and its child object, are directories named with *hash values* of the immediate child object keys, starting with an '@'.\nThe child objects are placed inside this directory.These child objects would be folders, if it has child objects, or files if its the cached data itself. This can go on till the end of the path and reaches the file where the cached data is.\nRepresentation of the object indexes (For NFS, in this case)\nINDEX INDEX INDEX DATA FILES ========= ========== ================================= ================ cache/@4a/I03nfs/@30/Ji000000000000000--fHg8hi8400 cache/@4a/I03nfs/@30/Ji000000000000000--fHg8hi8400/@75/Es0g000w...DB1ry cache/@4a/I03nfs/@30/Ji000000000000000--fHg8hi8400/@75/Es0g000w...N22ry cache/@4a/I03nfs/@30/Ji000000000000000--fHg8hi8400/@75/Es0g000w...FP1ry\n","link":"https://arvimal.github.io/posts/2014/11/structure-of-cached-content-in-fscache/","section":"posts","tags":["cachefilesd","cachefs","fscache"],"title":"FSCache and the on-disk structure of the cached data"},{"body":"","link":"https://arvimal.github.io/tags/fs-cache/","section":"tags","tags":null,"title":"fs-cache"},{"body":"FS-Cache and CacheFS. Are there any differences between these two? Initially, I thought both were same. But no, it's not.\nCacheFS is the backend implementation which caches the data onto the disk and mainpulates it, while FS-Cache is an interface which talks to CacheFS.\nSo why do we need two levels here?\nFS-Cache was introduced as an API or front-end for CacheFS, which can be used by any file system driver. The file system driver talks with the FS-Cache API which inturn talks with CacheFS in the back-end. Hence, FS-Cache acts as a common interface for the file system drivers without the need to understand the backend CacheFS complexities, and how its implemented.\nThe only drawback is the additional code that needs to go into each file system driver which needs to use FS-Cache. ie.. Every file system driver that needs to talk with FS-Cache, has to be patched with the support to do so. Moreover, the cache structure differs slightly between file systems using it, and thus lacks a standard. This unfortunately, prevents FS-Cache from being used by every network filesystem out there.\nThe data flow would be as:\nVFS \u0026lt;-\u0026gt; File system driver (NFS/CIFS etc..) \u0026lt;-\u0026gt; FS-Cache \u0026lt;-\u0026gt; CacheFS \u0026lt;-\u0026gt; Cached data\nCacheFS need not cache every file in its entirety, it can also cache files partially. This partial caching mechanism is possible since FS-Cache caches 'pages' rather than an entire file. Pages are smaller fixed-size segments of data, and these are cached depending on how much the files are read initially.\nFS-Cache does not require an open file to be loaded in the cache, prior being accessed. This is a nice feature as far as I understand, and the reasons are:\na) Not every open file in the remote file system can be loaded into cache, due to size limits. In such a case, only certain parts (pages) may be loaded. And the rest of the file should be accessed normally over the network.\nb) The cache won't necessarily be large enough to hold all the open files on the remote system.\nc) Even if the cache is not populated properly, the file should be accessible. ie.. the cache should be able to be bypassed totally.\nThis hopefully clears the differences between FS-Cache and CacheFS.\n","link":"https://arvimal.github.io/posts/2014/09/fscache-and-cachefs-differences/","section":"posts","tags":["cachefs","fs-cache"],"title":"FS-Cache and CacheFS, what are the differences?"},{"body":"I would be working on enabling FS-Cache support in the FUSE kernel module, as part of my under graduate project.\nNiels De Vos, from Red Hat Engineering, would act as my mentor and guide throughout this project. He would also be presenting this idea in the 'Linux Plumbers Conference' being held in Germany, October 2014.\nMore details on the the talk can be seen at http://www.linuxplumbersconf.org/2014/ocw/sessions/2247\nThis feature has got quite a few requests from the FOSS world, and I'm glad I could work on this. For now, I'm trying to get a hold on FS-Cache, how it works with other file systems, and trying to build FUSE with some customizations. Ultimately, it would be the FUSE module were the code additions would go, not FS-Cache.\nI'll try to keep this blog updated, so that I have a journal to refer later.\n","link":"https://arvimal.github.io/posts/2014/09/fscache-and-fuse/","section":"posts","tags":["cachefilesd","fs-cache","fuse"],"title":"FS-Cache and FUSE"},{"body":"","link":"https://arvimal.github.io/tags/fuse/","section":"tags","tags":null,"title":"fuse"},{"body":"I've been trying to create a minimal docker image for RHEL versions, for one of my projects. The following were the steps I followed:\na) Installed a RHEL6.5 server with 'Minimal Installation'.\nb) Registered it to the local satellite.\nc) Created a tar-ball of the filesystem with the command below:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# tar --numeric-owner --exclude=/proc --exclude=/sys --exclude=/mnt --exclude=/var/cache\n--exclude=/usr/share/doc --exclude=/tmp --exclude=/var/log -zcvf /mnt/rhel6.5-base.tar.gz /\n[/sourcecode]\nd) Load the tar.gz image using 'docker load' (as per the man page of 'docker load')\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# docker load -i rhel6.5-base.tar.gz\n[/sourcecode]\nThis is where it erred with the message:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n2014/08/16 20:37:42 Error: open /tmp/docker-import-123456789/repo/bin/json: no such file or directory\n[/sourcecode]\nAfter a bit of searching and testing, I found that 'docker load -i' doesn't work as expected. The workaround is to cat and pipe the tar.gz file, as shown below:\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# cat rhel6.5-base.tar.gz | docker import - rhel6/6.5\n[/sourcecode]\nThis ends up with the image showing up in 'docker images'\n[sourcecode language=\u0026quot;bash\u0026quot; gutter=\u0026quot;false\u0026quot;]\n# docker images\nREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE rhel6/6.1 latest 32b4b345454a About a minute ago 1.251 GB\n[/sourcecode]\nUpdate: 'docker load -i ' would only work if the image is created as a layered docker image. If the is a tar ball created from a root filesystem, you would need to use 'cat | docker import '\n","link":"https://arvimal.github.io/posts/2014/08/error-open-tmpdocker/","section":"posts","tags":null,"title":"\"Error: open /tmp/docker-import-123456789/repo/bin/json: no such file or directory\""},{"body":"","link":"https://arvimal.github.io/tags/anaconda/","section":"tags","tags":null,"title":"anaconda"},{"body":"","link":"https://arvimal.github.io/tags/installation/","section":"tags","tags":null,"title":"installation"},{"body":"","link":"https://arvimal.github.io/tags/lsusb/","section":"tags","tags":null,"title":"lsusb"},{"body":"**T**he binary '/sbin/lsusb' in a chroot-ed environment have problems running properly. I have not checked this in a manually created chroot environment or using tools like 'mock'.\nThe scenario is as following :\nWe were trying to check the output of 'lsusb' in the %post section of a kickstart installation. I had specified 'noreboot' in the kickstart file so the machine will wait for the user to manually reboot the machine. This helps to check the logs and the situation of the machine just after the installation finishes.\nAfter the installation and prior to the reboot, i checked in the second available terminal (Alt + F2) created by anaconda and was astonished to see that the command 'lsusb' does not give us the required output but an error that '/usr/share/hwdata/usb.ids' is not accessible or found.\nBy default, i think only the 'installation' ie.. the %post section starts in a 'chroot' mode and the terminal available is not chroot-ed. So we will have to use '/mnt/sysimage/sbin/lsusb'. This didn't work as expected since the 'lsusb' binary needs to check the file '/usr/share/hwdata/usb.ids' and won't be able to find it.\nSo I did a chroot from the second terminal and did an /sbin/lsusb, since /sbin in not in the 'PATH' by default. That too, didn't work out. But this time it didn't even complain anything. Just nothing at all, no output. Last time, at-least it complained it could not find something. So how do we go forward now ??? Here comes 'strace' to the rescue !!!\nstrace is of-course a really nice tool to know what system calls are made and lots of internal stuff a binary will do while being executed. But 'strace' is not installed by default on a RHEL5 machine, which is the case here. As most of you would know, anaconda creates a virtual file system which consists of most of the folders found under a linux main /. The location where the OS is installed is mounted under /mnt/sysimage.\nSince we already have an ISO from where we have booted the machine from (DVD/CD), we are free to mount it on the filesystem, which is what we did. :\n1 # mkdir /mnt/source 2 # mount -t iso9660 /dev/hdc /mnt/source 3 # cd /mnt/source/Server/ In case you want to know how the DVD/CD drive is detected, all you need to do is execute 'dmesg' in the available terminal. ie.. after pressing 'Alt + Ctrl + F2'.\nSo we went forward and mounted the DVD to /mnt/source and changed the directory to /mnt/source/Server where all the rpm packages reside. Installed the package 'strace' using an 'rpm -ivh'. Please note that we need to use '--root /mnt/sysimage' as an option since we are installing the package to our newly installed file system which is at /mnt/sysimage. If this is not used, the installer will try to install the package to the virtual environment created in the memory.\n1# cd /mnt/source/Server 2# rpm -ivh strace -fxvttT rpm --root /mnt/sysimage 3# cd 4# chroot /mnt/sysimage This will make /mnt/sysimage as the working root, ie.. where our installation was done. OK.. now for the 'strace' stuff.\n1# strace -fxvto strace.log -s 1024 /sbin/lsusb The strace output will be saved to 'strace.log' which we can open up in a text editor of our choice. Opening it in 'vi', shows a lot of stuff such as the command run, the default language, location of libraries loaded, the environment variables etc.. In this case we would only need to be interested in the last parts, ie.. to know where the binary failed :\n115:16:17 open(\u0026#34;/dev/bus/usb\u0026#34;, O\\_RDONLY|O\\_NONBLOCK|O\\_DIRECTORY) = -1 ENOENT (No such file or directory) = 03067 215:16:17 open(\u0026#34;/proc/bus/usb\u0026#34;, O\\_RDONLY|O\\_NONBLOCK|O\\_DIRECTORY) = 33067 315:16:17 fstat(3, {st\\_dev=makedev(0, 3), st\\_ino=4026532146, st\\_mode=S\\_IFDIR|0555, st\\_nlink=2, st\\_uid=0, st\\_gid=0, st\\_blksize=4096, st\\_blocks=0, st\\_size=0, st\\_atime=2009/09/25-15:16:17, st\\_mtime=2009/09/25-15:16:17, st\\_ctime=2009/09/25-15:16:17}) = 03067 15:16:17 fcntl(3, F\\_SETFD, FD\\_CLOEXEC) = 03067 15:16:17 getdents(3, {{d\\_ino=4026532146, d\\_off=1, d\\_reclen=24, d\\_name=\u0026#34;.\u0026#34;} {d\\_ino=4026531879, d\\_off=2, d\\_reclen=24, d\\_name=\u0026#34;..\u0026#34;}}, 4096) = 483067 415:16:17 getdents(3, {}, 4096) = 03067 15:16:17 close(3) = 03067 15:16:17 exit\\_group(1) = ? The above trace output shows how the 'lsusb' binary proceeded at its last time and where it failed. We can see that it went to open '/dev/bus/usb', only to find that the said location does not exist. We can understand that it is a directory from the call\n1open(\u0026#34;/dev/bus/usb\u0026#34;, O\\_RDONLY|O\\_NONBLOCK|O\\_DIRECTORY) Ok,, fine.. so what does it do next ?\nAs the next step, it tries to open '/proc/bus/usb' and it is present, which we know since there are no 'No such file or directory' errors. Going further, the binary goes on to do a 'stat' on '/proc/bus/usb'. After doing an 'fstat', it goes to check the file descriptor using 'fcntl' and further goes to list the directory contents using 'getdents'.\nThis is where we find the interesting output :\n1getdents(3, {{d\\_ino=4026532146, d\\_off=1, d\\_reclen=24, d\\_name=\u0026#34;.\u0026#34;} {d\\_ino=4026531879, d\\_off=2, d\\_reclen=24, d\\_name=\u0026#34;..\u0026#34;}}, 4096) = 48 As you can see in the above trace, it returns '.' and '..', which means there are nothing in /proc/bus/usb. So what we do understand is 'lsusb' refers /dev/bus/usb and /proc/bus/usb for its outputs.. If it was not able to find anything, strace would have given us an error which obviously would have made life much easier.\nAnd that's how '/sbin/lsusb' failed silently.. Isn't strace a nice tool ??\nOkay, those who want to know why is this so... 'lsusb' needs either /mnt/sysimage/proc/bus/usb or /mnt/sysimage/dev/bus/usb display contents to work properly. Anaconda is not mounting /mnt/sysimage/proc/bus/usb with the 'usbfs' file system in the limited installation environment and hence 'lsusb' fails...\nAnd we have a fix for that which goes into yuminstall.py in the anaconda source :\n1try: 2 isys.mount(\u0026#34;/proc/bus/usb\u0026#34;, anaconda.rootPath + \u0026#34;/proc/bus/usb\u0026#34;, \u0026#34;usbfs\u0026#34;) 3except Exception, e: 4 log.error(\u0026#34;error mounting usbfs: %s\u0026#34; %(e,)) This piece of python code, tries mounting /proc/bus/usb on /mnt/sysimage/proc/bus/usb as 'usbfs. If its not possible, the code excepts an Exception error and reports \u0026quot;error mounting 'usbfs'.\n","link":"https://arvimal.github.io/posts/2010/12/lsusb-and-chroot-in-anaconda/","section":"posts","tags":["anaconda","installation","lsusb","rhel","strace","usb"],"title":"lsusb and chroot in anaconda.. Is usbfs mounted in anaconda %post installation ?"},{"body":"","link":"https://arvimal.github.io/tags/rhel/","section":"tags","tags":null,"title":"rhel"},{"body":"","link":"https://arvimal.github.io/tags/strace/","section":"tags","tags":null,"title":"strace"},{"body":"","link":"https://arvimal.github.io/tags/usb/","section":"tags","tags":null,"title":"usb"},{"body":"What is device-mapper ?\nDevice mapper is a modular driver for the linux kernel 2.6. It can be said as a framework which helps to create or map logical sectors of a pseudo block device to an underlying physical block device. So what device-mapper do is keep a table of mappings which equate the logical block devices to the physical block devices.\nApplications such as LVM2, EVMS, software raid aka dmraid, multipathing, block encryption mechanisms such as cryptsetup etc... use device-mapper to work. All these applications excluding EVMS use the libdevmapper library to communicate with device-mapper.\nThe applications communicate with device-mapper's API to create the mapping. Due to this feature, device-mapper does not need to know what LVM or dmraid is, how it works, what LVM metadata is, etc... It is upto the application to create the pseudo devices pointing to the physical volumes using one of device-mapper's targets and then update the mapper table.\nThe device-mapper mapping table :\nThe mapping table used by device-mapper doesn't take too much space and is a list created using a 'btree'. A btree or a 'Binary Search Tree' is a data-structure from which data can be added, removed or queried.\nIn order to know more on what a btree is and the concept behind it, read :\nhttp://en.wikipedia.org/wiki/Binary_search_tree\nhttp://en.wikipedia.org/wiki/B-tree\nTypes of device-mapper targets :\nApplications which use device-mapper actually use one or more of its target methods to achieve their purpose. Targets can be said as a method or type of mapping used by device-mapper. The general mapping targets are :\na) Linear - Used by linear logical volumes, ie.. the default data layout method used by LVM2.\nb) Striped - Used by striped logical volumes as well as software RAID0.\nc) Mirror - Used by software RAID1 and LVM mirroring.\nd) Crypt - Used by disk encryption utilties.\ne) Snapshot - Used to take online snapshots of block devices, an example is LVM snapshot.\nf) Multipath - Used by device-mapper-multipath.\ng) RAID45 - Software raid using device-mapper, ie.. dmraid\nh) Error - Sectors of the pseudo device mapped with this target causes the I/O to fail.\nThere are a few more mappings such as 'flaky' which is not used much.\nI'll write on how device-mapper works in LVM, in the next post...\n","link":"https://arvimal.github.io/posts/2010/12/device-mapper-and-applications/","section":"posts","tags":null,"title":"Device Mapper and applications"},{"body":"In case anyone out there gets an error message like \u0026quot;Aborting. Failed to activate new LV to wipe the start of it.\u0026quot; while doing an 'lvcreate', check (/etc/lvm/lvm.conf) once more.\nMost probably, a 'volume_list' would have been defined in there, which in turns want you to specify the 'volume_list' tag specified along with the lvcreate command.\nExcerpt from /etc/lvm/lvm.conf:\n# If volume_list is defined, each LV is only activated if there is a # match against the list. # vgname and vgname/lvname are matched exactly. # @tag matches any tag set in the LV or VG. # @* matches if any tag defined on the host is also set in the LV or VG # # volume_list = [ vg1, vg2/lvol1, @tag1, @* ] volume_list = [ VG01, @foo.com ]\nIn this case, you will have to use the 'lvcreate' command as follows, which will create the logical volume properly.\n# lvcreate --addtag @foo.com ... following-options\n","link":"https://arvimal.github.io/posts/2009/11/lvcreate-fails-with-error/","section":"posts","tags":null,"title":"lvcreate fails with the error \"Aborting. Failed to activate new LV to wipe the start of it.\". Why ??"},{"body":"From the output of the command 'lspci -n' (The number after the colon, here '1679' from the below snip)\n0a:04.0 0200: 14e4:1679 (rev a3) Subsystem: 103c:703c Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- Status: Cap+ 66MHz+ UDF- FastB2B+ ParErr- DEVSEL=medium Latency: 64 (16000ns min), Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 138 Region 0: Memory at fdef0000 (64-bit, non-prefetchable) [size=64K] Region 2: Memory at fdee0000 (64-bit, non-prefetchable) [size=64K]\nIMPORTANT: -------------------\nIn the above line \u0026quot;14e4:1679\u0026quot;, '14e4' is the UID of the manufacturer and '1679' is the card model or hardware ID.\nThe actual way to proceed is to open the pci.ids file ('/usr/share/hwdata/pci.ids' and '/lib/modules/`uname -r`/modules.pcimap') and check for the manufacturer UID, like '14e4' which is the 'Broadcom Corporation'. The file /lib/modules/`uname -r`/modules.pcimap would be more reliable since it is from the modules of the loaded kernel.\nUnder that, check the card model, like '1679' which is 'NetXtreme BCM5715S Gigabit Ethernet'.\nUnder that you can also have subdivisions, so in order to pin-point a particular card you will have to use the 'Subsystem' value from 'lspci'.\nIn this example, 'Subsystem' is 103c:703c, which turns out to be 'NC326i PCIe Dual Port Gigabit Server Adapter'\n","link":"https://arvimal.github.io/posts/2008/07/map-pci-devices-in-linux/","section":"posts","tags":null,"title":"How to map PCI devices in Linux ?"},{"body":"","link":"https://arvimal.github.io/tags/boot-loader-checker/","section":"tags","tags":null,"title":"boot-loader-checker"},{"body":"A bash code snippet that helps to check if the installed bootloader is Grub or LILO.\n[code language=\u0026quot;bash\u0026quot;] #!/bin/bash\nA=`mount | awk '{print $1}' | grep -n /dev/ | grep \u0026quot;1:\u0026quot; | cut -f2 -d \u0026quot;:\u0026quot; | cut -c 1-8` B=`mount | awk '{print $1}' | grep -n /dev/ | grep \u0026quot;1:\u0026quot; | cut -f2 -d \u0026quot;:\u0026quot;`\necho ; echo -e \u0026quot; / mounted on $B \\n\u0026quot;; dd if=$A bs=512 count=1 2\u0026gt;\u0026amp;1 | grep GRUB \u0026gt; /dev/null; if [ $? = 0 ] ; then echo -e \u0026quot;The installed bootloader is GRUB.\\n\u0026quot; ; fi\ndd if=$A bs=512 count=1 2\u0026gt;\u0026amp;1 | grep LILO \u0026gt; /dev/null; if [ $? = 0 ] ; then echo -e \u0026quot;The installed bootloader is LILO.\\n\u0026quot; ; fi [/code]\n","link":"https://arvimal.github.io/posts/2008/02/bootloader-checker/","section":"posts","tags":["boot-loader-checker","grub","lilo"],"title":"Bootloader checker"},{"body":"Adding Swap Space:\nSometimes it is necessary to add more swap space after installation. For example, you may upgrade the amount of RAM in your system from 64 MB to 128 MB, but there is only 128 MB of swap space. It might be advantageous to increase the amount of swap space to 256 MB if you perform memory-intense operations or run applications that require a large amount of memory.\nYou have two options: add a swap partition or add a swap file. It is recommended that you add a swap partition, but sometimes that is not easy if you do not have any free space available.\nTo add a swap partition (assuming /dev/hdb2 is the swap partition you want to add):\n1) The hard drive can not be in use (partitions can not be mounted, and swap space can not be enabled). The easiest way to achieve this it to boot your system in rescue mode. Refer to Chapter 8 for instructions on booting into rescue mode. When prompted to mount the filesystem, select Skip. Alternately, if the drive does not contain any partitions in use, you can unmount them and turn off all the swap space on the hard drive with the swapoff command.\n2) Create the swap partition using parted or fdisk. Using parted is easier than fdisk; thus, only parted will be explained. To create a swap partition with 'parted:'. At a shell prompt as root, type the command parted /dev/hdb, where /dev/hdb is the device name for the hard drive with free space. At the (parted) prompt, type print to view the existing partitions and the amount of free space. The start and end values are in megabytes. Determine how much free space is on the hard drive and how much you want to allocate for a new swap partition. At the (parted) prompt, type mkpartfs part-type linux-swap start end, where part-type is one of primary, extended, or logical, start is the starting point of the partition, and end is the end point of the partition.\nWarning Warning _________________________\nChanges take place immediately; be careful when you type.\nExit parted by typing quit.\nNow that you have the swap partition, use the command mkswap to setup the swap partition. At a shell prompt as root, type the following: # mkswap /dev/hdb2\nTo enable the swap partition immediately, type the following command: # swapon /dev/hdb2\nTo enable it at boot time, edit /etc/fstab to include: /dev/hdb2 swap swap defaults 0 0\nThe next time the system boots, it will enable the new swap partition.\nAfter adding the new swap partition and enabling it, make sure it is enabled by viewing the output of the command cat /proc/swaps or free. To add a swap file: -------------------------- 1. Determine the size of the new swap file and multiple by 1024 to determine the block size. For example, the block size of a 64 MB swap file is 65536.\n2. At a shell prompt as root, type the following command with count being equal to the desired block size:\n# dd if=/dev/zero of=/swapfile bs=1024 count=65536\n3. Setup the swap file with the command:\n# mkswap /swapfile\n4. To enable the swap file immediately but not automatically at boot time:\n# swapon /swapfile\n5. To enable it at boot time, edit /etc/fstab to include:\n/swapfile swap swap defaults 0 0\nThe next time the system boots, it will enable the new swap file.\n6. After adding the new swap file and enabling it, make sure it is enabled by viewing the output of the command cat /proc/swaps or free.\n","link":"https://arvimal.github.io/posts/2008/02/creating-swap-space-in-linux/","section":"posts","tags":["swap-space"],"title":"Creating a SWAP space in Linux"},{"body":"","link":"https://arvimal.github.io/tags/file-counter/","section":"tags","tags":null,"title":"file-counter"},{"body":"","link":"https://arvimal.github.io/tags/grub/","section":"tags","tags":null,"title":"grub"},{"body":"","link":"https://arvimal.github.io/tags/lilo/","section":"tags","tags":null,"title":"lilo"},{"body":"Most of the scripts presented in this journal have been created while learning bash and having nothing much to do...\nI think its usual to get crazy ideas and work trying to implement them, especially while learning any type of coding. This 'File Counter' script came as such a crazy idea. It was working at the time of its creation, but have not checked it recently.. should work..\nThis script counts the entire number of files irrespective the folders under the main directory you specify for this script to work on. ie.. It recursively counts the files under a directory tree.\n[code language=\u0026quot;bash\u0026quot;] #!/bin/bash\n# Counts the number of files recursively inside a directory # # echo ; clear echo -e \u0026quot;Please enter the directory location where you want the files to be counted...\\n\u0026quot; ; echo\nread dir ; echo ; if [ ! -d $dir ] ; then echo -e \u0026quot;The location you specified doesn't exist.\\n\u0026quot; ; exit 0; else cd $dir ; echo -e \u0026quot;Please wait for the files to be counted.....\\n\u0026quot; ; echo ; fi\nX=`ls -l | wc -l` Y=`ls -l | grep ^d | awk '{print $9}'` B=`ls -l $Y | awk '{print $9}' | grep . | wc -l ` A=`expr $X + $B`\necho -e \u0026quot;There are a total of $A files inside the directory $dir...\\n\u0026quot;\nC=`ls -Rl | grep -v ./ | grep -v total | grep . | awk '{print $8}'`\necho -e \u0026quot;Do you want to scan the directory for the file types?\\n\u0026quot; echo -e \u0026quot;Y/N\\n\u0026quot; ; read choice; if [ $choice = Y ] ; then cd $dir ; file $C | awk '{print $1,\u0026quot;=======\u0026gt;\u0026gt;\u0026quot;, $2}' \u0026gt; $HOME/Filetype.txt;echo -e \u0026quot;Output saved in file Filetype.txt.\\n\u0026quot; elif [ $choice = N ] ; then echo -e \u0026quot;Thankyou $USER, Take care....\\n\u0026quot; else echo ; echo -e \u0026quot;Invalid choice buddy...\\n\u0026quot; ; echo -e \u0026quot;Exiting.....Bye..\\n\u0026quot; ; fi [/code]\n","link":"https://arvimal.github.io/posts/2008/02/file-counter/","section":"posts","tags":["file-counter"],"title":"Recursive file counter in bash"},{"body":"","link":"https://arvimal.github.io/tags/swap-space/","section":"tags","tags":null,"title":"swap-space"},{"body":"This is an extension or a rebuild of the previous chkrootkit install script, just used functions so its somewhat simplified.... ( Or is it ..? :) )\n[code language=\u0026quot;bash\u0026quot;]\n#!/bin/bash\nDOWNLOAD_LOCATION='/root/Downloads' CHKROOTKIT_WGET='ftp://ftp.pangeia.com.br/pub/seg/pac/chkrootkit.tar.gz' RESULT_FILE='/root/Server-Test.txt'\nclear;echo chkrootkit-install () {\nwhile true; do echo -e \u0026quot;@@@@@@@@@@@@@@@@@@ CHK-ROOTKIT INSTALL/CHECK SCRIPT @@@@@@@@@@@@@@@@@@@@\\n\u0026quot; echo -e \u0026quot;Do you want to download and compile CHK-ROOTKIT [yes/no] ? : \\c\u0026quot; | tee -a $RESULT_FILE; read answer; echo $answer \u0026gt;\u0026gt; $RESULT_FILE;\ncase $answer in yes|YES) echo if [ ! -e $DOWNLOAD_LOCATION ]; then echo -e \u0026quot;$DOWNLOAD_LOCATION does not exist, creating.......\\n\u0026quot;;sleep 1s mkdir -p $DOWNLOAD_LOCATION; fi rm -rf $DOWNLOAD_LOCATION/chkrootkit* \u0026gt; /dev/null; echo -e \u0026quot;Downloading CHK-ROOTKIT....\\n\u0026quot; | tee -a $RESULT_FILE;sleep 1s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; wget --progress=dot $CHKROOTKIT_WGET; if [ $? -eq 0 ] ; then echo -e \u0026quot;Download finished..\\n\u0026quot;; else echo -e \u0026quot;Sorry...Download Failed..!!!\\n\u0026quot;;exit;fi;echo echo -e \u0026quot;Unpacking and compiling CHK-ROOTKIT..........\\n\u0026quot;;sleep 2s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; tar -xvf chkrootkit*; mv $DOWNLOAD_LOCATION/chkrootkit*gz $DOWNLOAD_LOCATION/1-chkrootkit.tar.gz;sleep 2s cd $DOWNLOAD_LOCATION/chkrootki* \u0026amp;\u0026amp; make sense \u0026gt; /dev/null; if [ $? -eq 0 ] ; then echo -e \u0026quot;CHK-ROOTKIT compiled successfully..\\n\u0026quot;| tee -a $RESULT_FILE; break else echo -e \u0026quot;CHK-ROOTKIT compilation failed, Quiting....\\n\u0026quot; | tee -a $RESULT_FILE; exit fi ;; no|NO) echo echo -e \u0026quot;Ok..As you wish....Aborting.\\n\u0026quot;|tee -a $RESULT_FILE; exit ;; *) echo echo -e \u0026quot;Please enter either 'yes' OR 'no'..: \\c\u0026quot; ;; esac done }\nchkrootkit-run () { if [ -d $DOWNLOAD_LOCATION/chkrootki* ]; then while true; do echo -e \u0026quot;Do you want to run CHK-ROOTKIT now [yes/no] ? : \\c\u0026quot; | tee -a $RESULT_FILE; read reply echo $reply \u0026gt;\u0026gt; $RESULT_FILE;\ncase $reply in yes|YES) echo echo -e \u0026quot;Starting CHK-ROOTKIT....\\n\u0026quot; | tee -a $RESULT_FILE;sleep 2s;echo echo -e \u0026quot;----------------CHK-ROOTKIT SCAN RESULT-----------------\\n\u0026quot; $DOWNLOAD_LOCATION/chkrootk*/chkrootkit | tee -a $RESULT_FILE;sleep 1s echo;echo -e \u0026quot;CHK-ROOTKIT check finished......\\n\u0026quot;;echo exit ;; no|NO) echo echo -e \u0026quot;DON'T FORGET TO RUN CHK-ROOTKIT PERIODICALLY.\\n\u0026quot; exit ;; *) echo echo -e \u0026quot;Please enter either 'yes' OR 'no'..: \\c\u0026quot; ;; esac done\nelse echo -e \u0026quot;Chkrootkit not found in $DOWNLOAD_LOCATION, exiting..\\n\u0026quot; fi\n}\nchkrootkit-install \u0026amp;\u0026amp; chkrootkit-run; echo -e \u0026quot;The result is saved in $RESULT_FILE for reference.\\n\u0026quot; [/code]\n","link":"https://arvimal.github.io/posts/2008/02/chkrootkit-installer-with-functions/","section":"posts","tags":["functions"],"title":"CHKROOTKIT install script (with functions)"},{"body":"This bash script does a sanity check for the DNS domains defined inside /var/named.\n[code language=\u0026quot;bash\u0026quot;] #!/bin/bash A=`ls -l /var/named/*.db | awk '{print $9}' | cut -f4 -d \u0026quot;/\u0026quot; | sed 's/.db$//'` #domain names\nfor i in $A; do named-checkzone $i /var/named/$i.db;done [/code]\n","link":"https://arvimal.github.io/posts/2008/02/dns-zone-file-sanity-check/","section":"posts","tags":null,"title":"DNS Zone file sanity check"},{"body":"","link":"https://arvimal.github.io/tags/functions/","section":"tags","tags":null,"title":"functions"},{"body":"This is a bash script which automates the installation of Nagios. There are more things to do such as setup of service monitoring, but that's for another time.\n[code language=\u0026quot;bash\u0026quot;] #!/bin/bash DOWNLOAD_LOCATION='/root/Downloads/' NAGIOS_URL='http://jaist.dl.sourceforge.net/sourceforge/nagios/nagios-2.9.tar.gz' APACHE_CONF='/etc/httpd/conf/httpd.conf' NAGIOS_PLUGIN='http://nchc.dl.sourceforge.net/sourceforge/nagiosplug/nagios-plugins-1.4.8.tar.gz' NAGIOSHOME='/usr/local/nagios' DATE=`date +%d-%b-%Y` FILE='/root/Nagios.txt'\n################################# # [1] Installing nagios # ################################# nagios_download () { clear\nif [ `id -u` -ne 0 ]; then echo -e \u0026quot;You are executing the script as $USER\\n\u0026quot; echo -e \u0026quot;You must be root to execute this script..\\n\u0026quot;; echo -e \u0026quot;Sorry...Exiting..\\n\u0026quot;;exit 111; else if [ ! -e /root/Nagios.txt ]; then touch /root/Nagios.txt; else mv /root/Nagios.txt /root/Nagios-$DATE.txt; touch /root/Nagios.txt; fi\necho -e \u0026quot; [@@@@@@@@@@@@@@@@@@@@@@@@@ NAGIOS INSTALL SCRIPT @@@@@@@@@@@@@@@@@@@@@@@@@]\\n\u0026quot;;sleep 1s echo -e \u0026quot; ...Welcome...\\n\u0026quot;|tee -a $FILE;sleep 1s echo \u0026quot;[Starting the Nagios Installation Process :-]\u0026quot;|tee -a $FILE; echo \u0026quot;---------------------------------------------\u0026quot;|tee -a $FILE;echo;sleep 1s fi\nif [ ! -e $DOWNLOAD_LOCATION ]; then echo \u0026quot;$DOWNLOAD_LOCATION does not exist, creating.......\u0026quot;|tee -a $FILE;sleep 1s mkdir -pv $DOWNLOAD_LOCATION;echo fi\necho \u0026quot;[Downloading the nagios tar-ball to $DOWNLOAD_LOCATION :-]\u0026quot;|tee -a $FILE; echo \u0026quot;--------------------------------------------------------\u0026quot;|tee -a $FILE;echo;sleep 1s\ncd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; wget --progress=dot $NAGIOS_URL;echo echo -e \u0026quot;Extracting the archive....\\n\u0026quot;|tee -a $FILE;sleep 1s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; tar -zxf nagios*gz \u0026amp;\u0026amp; mv nagios*gz Nagios-$DATE.tar.gz;echo }\nnagios_usercheck () { echo \u0026quot;[Checking the existence of user/group 'nagios' :-]\u0026quot;|tee -a $FILE; echo \u0026quot;--------------------------------------------------\u0026quot;|tee -a $FILE;\ngrep -q nagios /etc/group \u0026gt; /dev/null if [ $? = 0 ];then echo \u0026quot;Group 'nagios' exist\u0026quot;|tee -a $FILE; else echo \u0026quot;Adding group 'nagios'\u0026quot;|tee -a $FILE; /usr/sbin/groupadd nagios fi\ngrep -q nagios /etc/passwd \u0026gt; /dev/null if [ $? = 0 ];then echo \u0026quot;User 'nagios' exists\u0026quot;|tee -a $FILE; else echo \u0026quot;Adding user 'nagios'\u0026quot;|tee -a $FILE; /usr/sbin/useradd -d $NAGIOSHOME -g nagios -s /bin/false -m nagios fi;echo\necho \u0026quot;[Checking the existence of user/group 'nagcmd' :-]\u0026quot;|tee -a $FILE; echo \u0026quot;--------------------------------------------------\u0026quot;|tee -a $FILE;\ngrep -q nagcmd /etc/group; if [ $? = 0 ];then echo \u0026quot;Group 'nagcmd' exists\u0026quot;|tee -a $FILE; else echo \u0026quot;Adding group 'nagcmd'\u0026quot;|tee -a $FILE; /usr/sbin/groupadd nagcmd; fi\ngrep -q nagcmd /etc/passwd; if [ $? = 0 ];then echo \u0026quot;User 'nagcmd' exists\u0026quot;|tee -a $FILE; else echo \u0026quot;Adding user 'nagcmd'\u0026quot;|tee -a $FILE; /usr/sbin/useradd -g nagcmd -s /bin/false -m nagcmd; fi; echo }\nnagios_previouscheck () { echo \u0026quot;[Checking for previous installations :-]\u0026quot;|tee -a $FILE echo \u0026quot;----------------------------------------\u0026quot;|tee -a $FILE;sleep 1s\nif [ -d /usr/local/nagios ]; then echo \u0026quot;Installation directory '/usr/local/nagios/' already exist.\u0026quot;|tee -a $FILE echo \u0026quot;Moving '/usr/local/nagios/' to '/usr/local/Nagios-$DATE.back'\u0026quot;|tee -a $FILE mv -v /usr/local/nagios /usr/local/Nagios-$DATE.back;echo echo \u0026quot;Creating the Installation Directory for Nagios [/usr/local/nagios/]\u0026quot;|tee -a $FILE mkdir -pv /usr/local/nagios;echo else echo \u0026quot;Nagios installation not found at the default location of $NAGIOSHOME\u0026quot;; echo \u0026quot;Creating the Installation Directory for Nagios [/usr/local/nagios/]\u0026quot;|tee -a $FILE mkdir -pv /usr/local/nagios;echo fi }\nnagios_ownership () { echo \u0026quot;[Setting appropriate ownership on the installation directory]\u0026quot;|tee -a $FILE echo \u0026quot;-------------------------------------------------------------\u0026quot; chown -v nagios.nagios /usr/local/nagios;echo;sleep 1s\necho \u0026quot;[Checking the Web-Server user/group :-]\u0026quot;|tee -a $FILE echo \u0026quot;---------------------------------------\u0026quot;|tee -a $FILE;sleep 1s\necho \u0026quot;Web-Server User : `grep \u0026quot;^User\u0026quot; $APACHE_CONF|head -n1|awk '{print $2}'`\u0026quot;|tee -a $FILE echo \u0026quot;Web-Server Group : `grep \u0026quot;^Group\u0026quot; $APACHE_CONF|head -n1|awk '{print $2}'`\u0026quot;|tee -a $FILE;echo;sleep 1s\necho \u0026quot;[Adding the Web-Server/Nagios user to the 'nagcmd' group]\u0026quot;|tee -a $FILE; echo \u0026quot;---------------------------------------------------------\u0026quot; /usr/sbin/usermod -G nagcmd `grep \u0026quot;^User\u0026quot; $APACHE_CONF|head -n1|awk '{print $2}'` \u0026amp;\u0026amp; \\ echo \u0026quot;Added the user `grep \u0026quot;^User\u0026quot; $APACHE_CONF|head -n1|awk '{print $2}'` to the 'nagcmd' group.\u0026quot;|tee -a $FILE sleep 1s /usr/sbin/usermod -G nagcmd nagios \u0026amp;\u0026amp; echo -e \u0026quot;Added the user 'nagios' to the 'nagcmd' group.\\n\u0026quot;|tee -a $FILE;sleep 1s echo }\nnagios_configure () { echo \u0026quot;[Starting the Nagios 'configure' script :-]\u0026quot;|tee -a $FILE; echo \u0026quot;-------------------------------------------\u0026quot;|tee -a $FILE;sleep 4s\ncd $DOWNLOAD_LOCATION/nagios* \u0026amp;\u0026amp; ./configure --with-command-group=nagcmd \u0026amp;\u0026amp; make all \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; make install-config \u0026amp;\u0026amp; make install-init \u0026amp;\u0026amp; make install-commandmode echo }\n################################# # [2] Installing Nagios Plugins # #################################\nnagios_plugins () { sleep 4s echo -e \u0026quot; [@@@@@@@@@@@@@@@@@@@@@@@@@ NAGIOS PLUGIN SETUP @@@@@@@@@@@@@@@@@@@@@@@@@]\\n\u0026quot;|tee -a $FILE;sleep 2s\necho \u0026quot;[Downloading the 'nagios-plugins' tarball :-]\u0026quot;|tee -a $FILE; echo \u0026quot;---------------------------------------------\u0026quot;;sleep 3s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; wget --progress=dot $NAGIOS_PLUGIN;echo echo \u0026quot;[Extracting the plugins archive :-]\u0026quot;|tee -a $FILE; echo \u0026quot;-----------------------------------\u0026quot;;sleep 1s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; tar -zxf nagios-plugins*gz \u0026amp;\u0026amp; mv nagios-plugins*gz Nagios-plugins-$DATE.tar.gz;echo echo \u0026quot;[Configuring and compiling nagios-plugins :-]\u0026quot;|tee -a $FILE; echo \u0026quot;---------------------------------------------\u0026quot;|tee -a $FILE;sleep 1s cd $DOWNLOAD_LOCATION \u0026amp;\u0026amp; cd nagios-plugins* \u0026amp;\u0026amp; ./configure \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; echo \u0026amp;\u0026amp; echo -e \u0026quot;[Nagios Plugin Setup Finished.]\\n\u0026quot; } echo;echo;sleep 3s\n################################# # [3] Configuring Nagios # ################################# nagios_conf_files () { echo \u0026quot;[Creating the minimal configuration files :-]\u0026quot;; echo \u0026quot;---------------------------------------------\u0026quot;;sleep 2s cp -apv $NAGIOSHOME/etc/nagios.cfg-sample $NAGIOSHOME/etc/nagios.cfg cp -apv $NAGIOSHOME/etc/commands.cfg-sample $NAGIOSHOME/etc/commands.cfg cp -apv $NAGIOSHOME/etc/resource.cfg-sample $NAGIOSHOME/etc/resource.cfg cp -apv $NAGIOSHOME/etc/localhost.cfg-sample $NAGIOSHOME/etc/localhost.cfg cp -apv $NAGIOSHOME/etc/cgi.cfg-sample $NAGIOSHOME/etc/cgi.cfg;echo\necho \u0026quot;[Setting administrative rights for 'nagiosadmin']\u0026quot; echo \u0026quot;-------------------------------------------------\u0026quot;;sleep 2s;echo echo \u0026quot;\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/cgi.cfg echo -e \u0026quot;#Setting administrative rights for 'nagiosadmin'\\n\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/cgi.cfg\necho \u0026quot;authorized_for_system_information=nagiosadmin authorized_for_configuration_information=nagiosadmin authorized_for_system_commands=nagiosadmin authorized_for_all_services=nagiosadmin authorized_for_all_hosts=nagiosadmin authorized_for_all_service_commands=nagiosadmin authorized_for_all_host_commands=nagiosadmin\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/cgi.cfg\necho \u0026quot;[Creating additional configuration files :-]\u0026quot;; echo \u0026quot;--------------------------------------------\u0026quot;;sleep 2s touch $NAGIOSHOME/etc/hosts.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/hosts.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/hosts.cfg\u0026quot;;fi touch $NAGIOSHOME/etc/hostgroups.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/hostgroups.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/hostgroups.cfg\u0026quot;;fi touch $NAGIOSHOME/etc/contacts.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/contacts.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/contacts.cfg\u0026quot;;fi touch $NAGIOSHOME/etc/contactgroups.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/contactgroups.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/contactgroups.cfg\u0026quot;;fi touch $NAGIOSHOME/etc/services.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/services.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/services.cfg\u0026quot;;fi touch $NAGIOSHOME/etc/timeperiods.cfg; if [ $? -eq 0 ];then echo \u0026quot;Created $NAGIOSHOME/etc/timeperiods.cfg\u0026quot;;else echo \u0026quot;Failed creating $NAGIOSHOME/etc/timeperiods.cfg\u0026quot;;fi; echo\necho \u0026quot;[Changing the ownership of newly created files :-]\u0026quot;; echo \u0026quot;--------------------------------------------------\u0026quot;;sleep 2s chown -Rv nagios.nagios $NAGIOSHOME/etc/* echo\necho \u0026quot;\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/nagios.cfg echo \u0026quot;[Setting config: file paths in $NAGIOSHOME/etc/nagios.cfg :-]\u0026quot;; echo \u0026quot;------------------------------------------------------------------\u0026quot;;echo;sleep 2s echo -e \u0026quot;#Setting configuration file paths.\\n\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/nagios.cfg echo \u0026quot;cfg_file=/usr/local/nagios/etc/hosts.cfg cfg_file=/usr/local/nagios/etc/hostgroups.cfg cfg_file=/usr/local/nagios/etc/services.cfg cfg_file=/usr/local/nagios/etc/contacts.cfg cfg_file=/usr/local/nagios/etc/contactgroups.cfg cfg_file=/usr/local/nagios/etc/timeperiods.cfg\u0026quot; \u0026gt;\u0026gt; $NAGIOSHOME/etc/nagios.cfg\necho echo \u0026quot;[Running the Nagios Syntax Check :-]\u0026quot;; echo \u0026quot;------------------------------------\u0026quot;;sleep 1s $NAGIOSHOME/bin/nagios -v $NAGIOSHOME/etc/nagios.cfg;echo }\n################################# # [4] Setting Up Apache # #################################\nnagios_apache () { echo \u0026quot;[Setting up Apache Web-Interface :-]\u0026quot; echo \u0026quot;------------------------------------\u0026quot;\ngrep -q \u0026quot;### Nagios Script Alias ###\u0026quot; $APACHE_CONF;\nif [ $? -eq 0 ];then echo -e \u0026quot;ScriptAlias for nagios already exists in $APACHE_CONF\\n\u0026quot; /etc/init.d/httpd restart \u0026gt; /dev/null else\necho \u0026quot;\u0026quot; \u0026gt;\u0026gt; $APACHE_CONF echo -e \u0026quot;### Nagios Script Alias ###\\n\u0026quot; \u0026gt;\u0026gt; $APACHE_CONF;\necho -e \u0026quot;ScriptAlias /nagios/cgi-bin /usr/local/nagios/sbin \\n\nOptions ExecCGI AllowOverride None Order allow,deny Allow from all AuthName \\\u0026quot;Nagios Access\\\u0026quot; AuthType Basic AuthUserFile /usr/local/nagios/etc/htpasswd.users Require valid-user \\n\u0026quot; \u0026gt;\u0026gt; $APACHE_CONF\necho -e \u0026quot;Alias /nagios /usr/local/nagios/share \\n\nOptions None AllowOverride None Order allow,deny Allow from all AuthName \\\u0026quot;Nagios Access\\\u0026quot; AuthType Basic AuthUserFile /usr/local/nagios/etc/htpasswd.users Require valid-user \\n\u0026quot; \u0026gt;\u0026gt; $APACHE_CONF\necho \u0026quot;Added the needed Alias configurations in $APACHE_CONF\u0026quot;\necho -e \u0026quot;Restarting the Web-Server...please wait..\\n\u0026quot; /etc/init.d/httpd restart; fi }\nnagios_htpasswd () { echo \u0026quot;[Creating the login credentials for the nagios URL :-]\u0026quot; echo \u0026quot;------------------------------------------------------\u0026quot;; echo \u0026quot;Username : nagiosadmin\u0026quot; htpasswd -c $NAGIOSHOME/etc/htpasswd.users nagiosadmin;echo echo -e \u0026quot;Login to the Nagios Interface is now restricted to user 'nagiosadmin'.\\n\u0026quot; }\nnagios_download \u0026amp;\u0026amp; nagios_usercheck \u0026amp;\u0026amp; nagios_previouscheck \u0026amp;\u0026amp; nagios_ownership \u0026amp;\u0026amp; nagios_configure \u0026amp;\u0026amp; nagios_plugins \u0026amp;\u0026amp; nagios_conf_files \u0026amp;\u0026amp; nagios_apache \u0026amp;\u0026amp; nagios_htpasswd [/code]\n","link":"https://arvimal.github.io/posts/2008/02/nagios-installer-script/","section":"posts","tags":["nagios-installation"],"title":"Nagios Installation Script"},{"body":"","link":"https://arvimal.github.io/tags/nagios-installation/","section":"tags","tags":null,"title":"nagios-installation"},{"body":"The bash environment variable 'RANDOM' is a pseudo-random number generator built in bash, and it can generate random numbers in the range of 0 - 32767.\nUsing the command `echo $RANDOM`, we can generate a random number. Building a random number generator which emits a sequence of random numbers is pretty easy.\n[code language=\u0026quot;bash\u0026quot;] #!/bin/bash for i in `seq 1 10`: do echo $RANDOM; sleep 1s; done [/code]\nThe 'seq' or the 'sequential' can be used to generate a sequence of numbers.\n","link":"https://arvimal.github.io/posts/2008/02/bash-script-for-generating-random-number/","section":"posts","tags":["bash","random-number-generator"],"title":"A random number generator in Bash"},{"body":"","link":"https://arvimal.github.io/tags/bash/","section":"tags","tags":null,"title":"bash"},{"body":"Some time back, I had to implement a password encryption section in one of my bash programs. It seemed easy to use a C snippet rather than doing it in bash. This was something I got after searching a while.\n[code language=\u0026quot;C\u0026quot;]\n#include stdlib.h #include unistd.h #include stdio.h #include crack.h #define DICTIONARY /usr/lib/cracklib_dict\nint main(int argc, char *argv[]) {\nchar *password; char *problem;\nint status = 0; printf(\\nEnter an empty password or Ctrl-D to quit.\\n); while ((password = getpass(\\nPassword: )) != NULL *password ) { if ((problem = FascistCheck(password, DICTIONARY)) != NULL) { printf(Bad password: %s.\\n, problem); status = 1; } else { printf(Good password!\\n); } } exit(status); } [/code]\nCompile the code using the GNU C compiler.\n# gcc filename.c -lcrack -o cracktest'\n","link":"https://arvimal.github.io/posts/2008/02/password-encryptor-in-c/","section":"posts","tags":["password-encrypt"],"title":"Password Encryptor in C"},{"body":"","link":"https://arvimal.github.io/tags/password-encrypt/","section":"tags","tags":null,"title":"password-encrypt"},{"body":"","link":"https://arvimal.github.io/tags/random-number-generator/","section":"tags","tags":null,"title":"random-number-generator"},{"body":"","link":"https://arvimal.github.io/tags/runaway-process/","section":"tags","tags":null,"title":"runaway-process"},{"body":"","link":"https://arvimal.github.io/tags/zombie/","section":"tags","tags":null,"title":"zombie"},{"body":"Why can't I kill a process with the signal 9?\nA process can be sleeping in kernel code. Usually that's because of faulty hardware or a badly written driver- or maybe a little of both. A device that isn't set to the interrupt the driver thinks it is can cause this, for example- the driver is waiting for something its never going to get. The process doesn't ignore your signal- it just never gets it.\nA zombie process doesn't react to signals because it's not really a process at all- it's just what's left over after it died. What's supposed to happen is that its parent process was to issue a \u0026quot;wait()\u0026quot; to collect the information about its exit. If the parent doesn't (programming error or just bad programming), you get a zombie. The zombie will go away if its parent dies- it will be \u0026quot;adopted\u0026quot; by init which will do the wait()- so if you see one hanging about, check its parent; if it is init, it will be gone soon, if not the only recourse is to kill the parent..which you may or may not want to do.\nFinally, a process that is being traced (by a debugger, for example) won't react to the KILL either then you do a ps, processes that have a status of Z are called \u0026quot;zombies\u0026quot;. When people see a zombie process, the first thing they try to do is to kill the zombie, using kill or (horrors!) kill -9. This won't work, however: you can't kill a zombie, it's already dead.\nWhen a process has already terminated (\u0026quot;died\u0026quot;) by receiving a signal to do so, it can stick around for a bit to finish up a few last tasks. These include closing open files and shutting down any allocated resources (memory, swap space, that sort of thing). These \u0026quot;housekeeping\u0026quot; tasks are supposed to happen very quickly. Once they're completed, the final thing that a process has to do before dying is to report its exit status to its parent. This is generally where things go wrong.\nEach process is assigned a unique Process ID (PID). Each process also has an associated parent process ID (PPID), which identifies the process that spawned it (or PPID of 1, meaning that the process has been inherited bythe init process, if the parent has already terminated). While the parent is still running, it can remember the PID's of all the children it has spawned. These PID's can not be re-used by other (new) processes until the parent knows that the child process is done.\nWhen a child terminates and has completed its housekeeping tasks, it sends a one-byte status code to its parent. If this status code never gets sent, the PID is kept alive (in \u0026quot;zombie\u0026quot; status) in order to reserve its PID ... the parent is waiting for the status code, and until it gets it, it doesn't want any new processes to try and reuse that PID number for themselves.\nTo get rid of a zombie, you can try killing its parent, which will temporarily orphan the zombie. The init process will inherent the zombie, and this might allow the process to finish terminating since the init process is always in a wait() state (ready to receive exit status reports of children).\nGenerally, though, zombies clean themselves up. Whatever the process was waiting for eventually occurs and the process can report its exit status to its parent and all is well.\nIf a zombie is already owned by init, though, and it's still sticking around (like zombies are wont to do), then the process is almost certainly stuck in a device driver close routine, and will likely remain that way forever. You can reboot to clear out the zombies, but fixing the device driver is the only permanent solution. Killing the parent (init in this case) is highly unrecommended, since init is an extremely important process to keeping your system running..\n","link":"https://arvimal.github.io/posts/2008/01/zombie-processes/","section":"posts","tags":["runaway-process","zombie"],"title":"Zombie processes"},{"body":"","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/00-boot-process/","section":"docs","tags":null,"title":""},{"body":"The Linux Boot process 1. Power up the machine\nThe Boot process starts when a user powers up the machine.\n2. Power supply starts up, and regulates itself into the operating voltage.\nThis may take less than a millisecond.\n3. The Power supply system sends the PowerGood signal to the Motherboard.\nThe ATX specification defines the Power-Good signal as a +5-volt (V) signal generated in the power supply when it has passed its internal self-tests and the output voltages have sthbilized.\nThe Power Good signal (power-good) prevents a computer from attempting to operate on improper voltages and damage itself by alerting it to an improper power supply.\n4. The Motherboard starts the Processor, once it receives the Power Good signal.\n5. The Processor resets its internal registers, and fill it with pre-defined information.\n80386 series and later series set the following registers and corresponding data. 1 IP (16 Bit register) - 0xfff0 2 CS selector (16 Bit register) - 0xf000 3 CS base (16 Bit register) - 0xffff0000 6. The Processor starts in Real Mode.\nReal mode is characterised by a 20-bit segmented memory address space (giving exactly 1 MiB of addressable memory). This gives it unlimited direct software access to all addressable memory, the I/O addresses, and hardware. Real mode provides no support for memory protection, multitasking, or code privilege levels. Thus, all x86 CPUs start in Real mode with no memory protection, fixed 64 KiB segments, and only 20-bit (1024 KiB = 1 MiB) addressing. 7. The x86 CPU adds both theCS SelectorandCS Baseregister contents and expects to find the first instruction after reset, there.\nAll the registers, while in 8086, were 16-bit registers. This meant that only 64KiB addresses could be addressed in a single go. The CS (Code Segment) registers had two types (Selector and Base) each 16 bits long. These together (16 bits + 16 bits) were able to address 32 bit address locations. Hence, the 8086 and any x86 CPUs were able to address approximately 4GB of memory. Before starting up, the x86 CPU had cleared its registers and set it to the following values 1 IP (16 Bit register) - 0xfff0 2 CS selector (16 Bit register) - 0xf000 3 CS base (16 Bit register) - 0xffff0000 Adding CS Selector and CS Base values gives 0xfffffff0, which is 4 GB - 16 Bytes.\n1In [4]: hex(0xffff0000 + 0xfff0) 2Out[4]: \u0026#39;0xfffffff0\u0026#39; This address is called the Reset vector. The reset vector is the default location a central processing unit will go to find the first instruction it will execute after a reset. The reset vector is a pointer or address, where the CPU should always begin as soon as it is able to execute instructions.\nThe address contains a jump instruction, which points to the BIOS entry point in a Read-Only Memory chip (ROM) on the Motherboard. The BIOS is initialised and it starts up.\n8. BIOS starts\nOnce the BIOS starts, it does the Power-On Self Test and verifies all hardware. Information on the bootable disk or boot order is maintained in the BIOS. If the boot device is a disk, the BIOS tries to find a boot sector. An HDD sector is 512 Bytes. On HDDs partitioned with MBR partitioning tables, the first 446 Bytes of the first sector contains the BootStrap code. On systems using GRUB, the first stage of GRUB is located here, and is the Bootstrap code. NOTE: BIOS/UEFI cannot directly go ahead and read a disk, unless it has some way of addressing them. Almost all HDD manufacturers provide disk hardware that enable BIOS to utilise them, and access the HDD sectors through LBA (Logical Block Addressing). This is comparatively slow, but helps the BIOS to read the disks and pass control over to a Boot Loader.\n9. BIOS hands over control to the Boot Sector code (aka Master Boot Code) (GRUB Stage1)\nBIOS loads the first sector (Sector #0 of 512B) of the bootable disk into RAM. It reads the Bootstrap code (boot.img, in case of GRUB) residing within the first 446 Bytes. The control is passed on to the Bootstrap code (boot.img) (GRUB Stage1), and executes in memory. 10. GRUB starts\nOnce BIOS reads the first sector of the bootable disk via LBA addressing method, the Boot Strap code is called and executed (GRUB Stage1).\nStage 1 : (boot.img in MBR BootStrap code area, ie.. Sector #0)\nboot.img is stored in the master boot record (MBR) or optionally in any of the volume boot records (VBRs), and addresses the next stage by an LBA48 address (thus, the 1024-cylinder limitation of GRUB legacy is avoided). The Stage1 is configured (automatically) to load the first sector of core.img (core.img = Stage 1.5) Stage 1.5: (core.img - Sector #1 to #62) (Can contain drivers to access partitions with Filesystems, for Grub)\ncore.img is by default written to the sectors between the MBR and the first partition, when these sectors are free and available. For legacy reasons, the first partition of a hard drive does not begin at sector #1 (counting begins with 0) but starts at sector #63. This leaves 62 sectors of empty space not part of any partition or file system, and therefore not prone to any problems related with it. Once executed, core.img will load its configuration file and any other modules needed, particularly file system drivers; at installation time, it is generated from diskboot.img and configured to load the stage 2 by its file path. Stage 2: (In /boot/grub/)\nGRUB uses the filesystem drivers to access the filesystem partitions, and reads grub.conf. Files belonging to Stage 2 are all in /boot/grub, which is a subdirectory of the /boot directory This includes the configuration file grub.cfg, the kernels (vmlinuz), and the initrd files etc.. The GRUB menu as per grub.conf is shown and user selects a kernel to boot from. 11. GRUB loads the selected/default kernel loads, and initrd.\nGRUB reads the entry for the kernel selected (by the user or default kernel), and loads the kernel mentioned with directive linux16 to memory. The kernel takes into consideration the kernel parameters set for vmlinuz, and acts accordingly. NOTE: Some info on grub.conf and its parameters.\nThe location where GRUB searches for the kernel and initrd, is set with the parameter set root='hd0, msdos1'. This is the GRUB root, or the location where GRUB intends to find the kernel and initrd. The search parameter in grub.conf sets the way the GRUB root should be checked, and the disk UUID it should check. This filesystem is where GRUB expects to find the kernel and initrd. The search keyword follows with the vmlinuz path, and initrd path. A vmlinuz and kernel parameters example: 1`/vmlinuz-3.10.0-693.el7.x86_64 root=/dev/mapper/rhel_dell--r430--19-root ro crashkernel=auto rd.lvm.lv=rhel_dell-r430-19/root rd.lvm.lv=rhel_dell-r430-19/swap rhgb quiet LANG=en_US.UTF-8` 2`initrd16 /initramfs-3.10.0-693.el7.x86_64.img` Note that the kernel parameters mention ro (read-only). This is normal, and it instructs the kernel to read the root filesystem as read-only so that the filesystem checker can run its checks safely. After the filesystem check, the root filesystem will be mounted as read-write. If the kernel comes upon any parameters that it doesn't understand, it saves it and passes it to init (or systemd), in order to process later. If the vmlinuz path starts with a slash ('/') as in /vmlinuz-3.10.0-693.el7.x86_64, it means that the /boot/ partition is different than the root partition ('/'). If /boot/ was on the same partition as root ('/'), the entry would have been /boot/vmlinuz-3.10.0.... Grub (not the kernel) loads both the Kernel and the initrd file, as listed in grub.conf. Initrd contains the necessary drivers for the kernel, to access the connected devices as well as form a virtual filesystem in memory. With a virtual filesystem running in memory, the kernel initializes /sbin/init (which was part of the initrd file). 12. init or systemd starts\nThe kernel looks for an init binary in the following locations: /sbin/init /etc/init /bin/init /bin/sh NOTE: If the directive init=\u0026lt;path\u0026gt; is passed to grub via grub.conf (or editing at boot time),Grub loads that specific binary as the first process. Else, it looks for an init binary at the locations above.\n/sbin/init starts On systemd machines, /sbin/init is usually a symlink to /usr/lib/systemd/systemd. init reads /etc/inittab for run levels, and go to the specific runlevel locations at /etc/init.d/ to start the scripts marked to startup in that level. On Systemd machines, Systemd looks for the targets it has to reach (/usr/lib/systemd/system/default.target), and starts the units for it. By default, Systemd is configured to reach the multi-user target, and starts the services for it, and presents the login prompt. 13. mgetty, systemd-getty-generator, login, and PAM\nOn SystemV machines with older init, init loads mgetty or agetty.\nagetty takes control of the login binary It presents a login prompt to the user, in the virtual console. The user login credentials are passed to PAM settings in /etc/pam.d/ PAM checks /etc/passwd, and /etc/shadow for user info. If the user info is correct, the shell set in /etc/passwd is spawned. If not, login terminates and control is passed back to agetty. agetty takes control over login and presents the user with a prompt. On Systemd machines, systemd loads systemd-getty-generator.\nsystemd-getty-generator takes control over the login binary. The rest are similar to the sequence above. Notes 1. History of Real Mode\nThe 80286 series of processors introduced the Protected Mode of operation. Real Mode was the operational mode available before Protected Mode emerged in 80826. Protected Mode enabled features such as virtual memory, paging etc.., and these were not available in Real Mode mode of operation. Backward compatibility is a design decision in x86 series, hence it was a requirement to get any software written for processor series before 80286 to be able to run on any x86 series. The existing system software which were written for Real Mode would have to be re-written to use the Protected Mode. Hence, to maintain backward compatibility with all previous series as well as for using the existing system software, all x86 processors from 80286 till the latest x86 64-bit processors (those using Protected mode), start in Real Mode. The Processor switches from Real Mode to Protected Mode after the system software sets up a few descriptor tables and enables the Protection Enable (PE) bit in the control register 0 (CR0). 2. Why was the change to Protected mode required?\nThe Intel 8086, the predecessor to the 80286, was originally designed with a 20-bit address bus for its memory. This allowed the processor to access 220 bytes of memory, equivalent to 1 megabyte. At the time, 1 MB of memory was considered a relatively large amount of memory, so the designers of the IBM Personal Computer reserved the first 640 kilobytes for use by applications and the operating system, and the remaining 384 kilobytes for the BIOS and memory for add-on devices. As the cost of memory decreased and memory use increased, the 1 MB limitation became a significant problem. Intel intended to solve this limitation along with others with the release of the 286, through the Protected Mode. 3. How does Real mode address memory?\nReal Mode was the only mode available in the series prior 80286, ie.. 8086. This series had 20-bit address buses capable of addressing 1MiB of Memory, but had only 16-bit CPU registers that could load upto 64KiB of memory at a time. This meant that, even though the bus had the width to accomodate a larger bit size and access the memory, the Processor registers were not big enough to load the data in a single go. Hence, 8086 processors used a method known as Memory Segmentation. In 8086, Memory segmenatation worked by creating 64KiB chunks of the 1MiB data space, and loading it as required. 4. 80826 series provides memory protection compared to 8086, what is it?\nMemory segmentation is the process of dividing the system memory into sections. 8086 series used this technique to address a memory of 1MiB when its registers were only capable of storing 64KiB. In a system that uses memory segmentation, a reference to the memory location would include a value that points to a segment and an offset. This enables the processor to read the entire segment. The Memory Management Unit is responsible for mapping the segments to the actual locations in RAM, as well as checking the access permissions for that specific memory location. The Memory Segmentation used by 8086 did not provide any protection. ie. it didn't have a mechanism to prevent access to specific memory segments. Any software running on these processors can access any memory segments as it chose, even if those were not in use by the said system software. The lack of Memory protection in 8086 prevented features such as Virtual Memory from being realized. 80826 came with the Protected Mode of operation which brought in memory protection and features such as virtual memory, paging etc. As said earlier, due to backward compatibility, 80286 still started up in Real mode even though it came with Protected Mode. 5. Master Boot Record\nA master boot record (MBR) is a special type of boot sector at the very beginning of a partitioned storage device. The MBR holds the information on how the partitions are organized on that medium. The organization of the partition table in the MBR limits the maximum addressable storage space of a disk to 2 TiB (232 × 512 bytes) The first 446 Bytes of the sector of an MBR partitioned disk, contains the Bootstrap code. The next four 16 Bytes contains the four partition entries. Hence the limit of four primary partitions. The final two bytes contain the Boot signature, which denotes the disk is bootable and acts as an indicator that the sector is ending here. Thus, Total size =446 + (4 x16) + 2 = 512 Bytes\nNOTE: GPT (Guid Partition Table) is a replacement to MBR. Some of the differences between MBR and GPT are:\nMBR uses 32-bit addresses, hence is limited to read upto 2TiB of disk space (2**32 - 1)\nGPT uses 64-bit addresses and can address larger disks.\nMBR uses the Cylinder-Head-Sector (CHS) mode for disk access, which is not always correct due to outer cylinders being large than inner ones and thus the number of sectors per cylinder being different.\nGPT uses Logical-Block-Address (LBA) mode which is more accurate than GPT.\nGPT still maintains the MBR structure in Sector #0 to maintain backward compatibility. ie.. in LBA #0.\nGPT header is in LBA #1, the Partition table is at LBA #2, and the filesystem starts from LBA #34.\n6. Why does GRUB have multiple stages?\nGRUB has multiple stages, Stage 1 being in the Bootstrap section of the first sector of MBR formatted bootable disk. The Bootstrap code has only a space of around 446 Bytes. This is enough for simple bootloaders, but not so for bootloaders that support Menu-drive selection, supports multiple filesystems etc. Hence, the first stage of Grub exists in the Bootstrap code area, and the remaining at multiple locations such as the sectors between Sector #0 and Filesystem partition, as well as the Active partition. Although every MBR formatted HDD contains an MBR, the master boot code is used only if the disk contains the active, primary partition. 7. Difference between GRUB1 (Legacy) and GRUB2\nGRUB1 works only on x86 and x86_64 architecture. GRUB2 works on multiple architectures including SPARC and PowerPC. GRUB1 supported only MBR and BIOS, while GRUB2 supports MBR, GPT, EFI, BIOS, OpenFirmware etc.. GRUB1 supported boot from normal filesystems, while GRUB2 supports reading LVM, RAID etc.. GRUB1 could only read a few filesystems such as EXT, XFS, JFS, FAT, ReiserFS etc.., while GRUB2 supports additional FS such as Apple FS, NTFS etc. 8. Difference between MBR and GPT partition methods\nMBR (also called msdos partitions) uses 32-bits to store Block (LBA) addresses. For HDDs with 512 byte sectors, the MBR partition table entries allow a single partition upto 2TB. GPT (Guid Partition Table) use logical block addressing (LBA) in place of the historical cylinder-head-sector (CHS) addressing. On a system using GPT, the MBR is still maintained for backward compatibility. The protective MBR is contained in LBA 0, the GPT header is in LBA 1, and the GPT header has a pointer to the partition table, or Partition Entry Array, typically LBA 2. The UEFI specification stipulates that a minimum of 16,384 bytes, regardless of sector size, be allocated for the Partition Entry Array. On a disk having 512-byte sectors, a partition entry array size of 16,384 bytes and the minimum size of 128 bytes for each partition entry, LBA 34 is the first usable sector on the disk. 9. Difference between BIOS and EFI firmware systems\n10. Troubleshooting GRUB\nPress e from GRUB menu, to enter the GRUB configuration and edit it.\nCheck the GRUB root where GRUB checks for the UUID, at the set root=hd\u0026lt;X\u0026gt;, \u0026lt;type\u0026gt; parameter. The type would be usually msdos for MBR partitions and gpt for GPT partitions.\nPress Ctrl + C to access the GRUB command prompt.\nls and ls -l (for more details) to list the partitions on the disks, on the machine. Update/Edit grub.cfg\nAny changes to grub.cfg won't be permanent. Hence, don't directly edit it. Add changes in /etc/default/grub Run grub2-mkconfig \u0026gt; /etc/grub2.cfg to update the changes to grub2.cfg. GRUB 2 works as:\n/etc/default/grub contains customizations /etc/grub.d/ scripts contain GRUB menu information and operating system boot scripts. When the command grub2-mkconfig \u0026gt; /etc/grub2.cfg is run, it reads the contents of the grub file and the grub.d scripts and creates the grub.cfg file. Appendix https://en.wikipedia.org/wiki/Power_good_signal https://en.wikipedia.org/wiki/Real_mode https://en.wikipedia.org/wiki/Protected_mode https://en.wikipedia.org/wiki/Memory_segmentation https://en.wikipedia.org/wiki/Master_boot_record https://technet.microsoft.com/en-us/library/cc976786.aspx date created: 13-11-2022, Sunday, 04:18 PM Arch boot process https://wiki.archlinux.org/index.php/Arch_boot_process#Boot_loader\nSince each OS or vendor can maintain its own files within the EFI system partition without affecting the other, multi-booting using UEFI is just a matter of launching a different EFI application corresponding to the particular operating system's boot loader. This removes the need for relying on chain loading mechanisms of one boot loader to load another OS.\nSee also Dual boot with Windows.\nA boot loader is a piece of software started by the firmware (BIOS or UEFI). It is responsible for loading the kernel with the wanted kernel parameters, and initial RAM disk based on configuration files. In the case of UEFI, the kernel itself can be directly launched by the UEFI using the EFI boot stub. A separate boot loader or boot manager can still be used for the purpose of editing kernel parameters before booting.\nWarning: A boot loader must be able to access the kernel and initramfs image(s), otherwise the system will not boot. Thus, in a typical setup, it must support accessing /boot. That means it must have support for everything starting from the block devices, stacked block devices (LVM, RAID, dm-crypt, LUKS, etc) and ending with the file system on which the kernel(s) and initramfs image(s) reside.\nA boot manager. It can only launch other EFI applications, for example, Linux kernel images built with CONFIG_EFI_STUB=y and Windows bootmgfw.efi. The kernel is the core of an operating system. It functions on a low level (kernelspace) interacting between the hardware of the machine and the programs which use the hardware to run. The kernel temporarily stops programs to run other programs in the meantime, which is known as preemption. This creates the illusion of many tasks being executed simultaneously, even on single-core CPUs. The kernel uses the CPU scheduler to decide which program takes priority at any given moment.\ninitramfs After the boot loader loads the kernel and possible initramfs files and executes the kernel, the kernel unpacks the initramfs (initial RAM filesystem) archives into the (then empty) rootfs (initial root filesystem, specifically a ramfs or tmpfs). The first extracted initramfs is the one embedded in the kernel binary during the kernel build, then possible external initramfs files are extracted. Thus files in the external initramfs overwrite files with the same name in the embedded initramfs. The kernel then executes /init (in the rootfs) as the first process. The early userspace starts.\nArch Linux uses an empty archive for the builtin initramfs (which is the default when building Linux). See mkinitcpio for more and Arch-specific info about the external initramfs.\nThe purpose of the initramfs is to bootstrap the system to the point where it can access the root filesystem (see FHS for details). This means that any modules that are required for devices like IDE, SCSI, SATA, USB/FW (if booting from an external drive) must be loadable from the initramfs if not built into the kernel; once the proper modules are loaded (either explicitly via a program or script, or implicitly via udev), the boot process continues. For this reason, the initramfs only needs to contain the modules necessary to access the root filesystem; it does not need to contain every module one would ever want to use. The majority of modules will be loaded later on by udev, during the init process.\nAt the final stage of early userspace, the real root is mounted, and then replaces the initial root filesystem. /sbin/init is executed, replacing the /init process. Arch uses systemd as the default init.\ninit calls getty once for each virtual terminal (typically six of them), which initializes each tty and asks for a username and password. Once the username and password are provided, getty checks them against /etc/passwd and /etc/shadow, then calls login. Alternatively, getty may start a display manager if one is present on the system.\nA display manager can be configured to replace the getty login prompt on a tty.\nIn order to automatically initialize a display manager after booting, it is necessary to manually enable the service unit through systemd. For more information on enabling and starting service units, see systemd#Using units.\nThe login program begins a session for the user by setting environment variables and starting the user's shell, based on /etc/passwd.\nThe login program displays the contents of /etc/motd (message of the day) after a successful login, just before it executes the login shell. It is a good place to display your Terms of Service to remind users of your local policies or anything you wish to tell them.\nOnce the user's shell is started, it will typically run a runtime configuration file, such as bashrc, before presenting a prompt to the user. If the account is configured to Start X at login, the runtime configuration file will call startx or xinit.\nxinit runs the user's xinitrc runtime configuration file, which normally starts a window manager. When the user is finished and exits the window manager, xinit, startx, the shell, and login will terminate in that order, returning to getty.\ndate created: 12-11-2022, Saturday, 08:55 PM All modern personal computer operating systems support GPT. Some, including macOS and Microsoft Windows on the x86 architecture, support booting from GPT partitions only on systems with EFI firmware, but FreeBSD and most Linux distributions can boot from GPT partitions on systems with either the BIOS or the EFI firmware interface.\nThe Master Boot Record (MBR) partitioning scheme, widely used since the early 1980s, imposed limitations for use of modern hardware. The available size for block addresses and related information is limited to 32 bits. For hard disks with 512‑byte sectors, the MBR partition table entries allow a maximum size of 2 TiB (2³² × 512‑bytes) or 2.20 TB (2.20 × 10¹² bytes).[1]\nIn the late 1990s, Intel developed a new partition table format as part of what eventually became the Unified Extensible Firmware Interface (UEFI). The GUID Partition Table is specified in chapter 5 of the UEFI 2.8 specification.[2] GPT uses 64 bits for logical block addresses, allowing a maximum disk size of 264 sectors. For disks with 512‑byte sectors, the maximum size is 8 ZiB (264 × 512‑bytes) or 9.44 ZB (9.44 × 10²¹ bytes).[1] For disks with 4,096‑byte sectors the maximum size is 64 ZiB (264 × 4,096‑bytes) or 75.6 ZB (75.6 × 10²¹ bytes).\nIn 2010, hard-disk manufacturers introduced drives with 4,096‑byte sectors (Advanced Format).[3] For compatibility with legacy hardware and software, those drives include an emulation technology (512e) that presents 512‑byte sectors to the entity accessing the hard drive, despite their underlying 4,096‑byte physical sectors.[4]\nLike MBR, GPTs use logical block addressing (LBA) in place of the historical cylinder-head-sector (CHS) addressing. The protective MBR is stored at LBA 0, and the GPT header is in LBA 1. The GPT header has a pointer to the partition table (Partition Entry Array), which is typically at LBA 2. Each entry on the partition table has a size of 128 bytes. The UEFI specification stipulates that a minimum of 16,384 bytes, regardless of sector size, are allocated for the Partition Entry Array.[5] Thus, on a disk with 512-byte sectors, at least 32 sectors are used for the Partition Entry Array, and the first usable block is at LBA 34 or higher, while on a 4,096-byte sectors disk, at least 4 sectors are used for the Partition Entry Array, and the first usable block is at LBA 6 or higher.\nFor limited backward compatibility, the space of the legacy Master Boot Record (MBR) is still reserved in the GPT specification, but it is now used in a way that prevents MBR-based disk utilities from misrecognizing and possibly overwriting GPT disks. This is referred to as a protective MBR.[6]\nA single partition of type EEh, encompassing the entire GPT drive (where \u0026quot;entire\u0026quot; actually means as much of the drive as can be represented in an MBR), is indicated and identifies it as GPT. Operating systems and tools which cannot read GPT disks will generally recognize the disk as containing one partition of unknown type and no empty space, and will typically refuse to modify the disk unless the user explicitly requests and confirms the deletion of this partition. This minimizes accidental erasures.[6] Furthermore, GPT-aware OSes may check the protective MBR and if the enclosed partition type is not of type EEh or if there are multiple partitions defined on the target device, the OS may refuse to manipulate the partition table.[7]\nIf the actual size of the disk exceeds the maximum partition size representable using the legacy 32-bit LBA entries in the MBR partition table, the recorded size of this partition is clipped at the maximum, thereby ignoring the rest of the disk. This amounts to a maximum reported size of 2 TiB, assuming a disk with 512 bytes per sector (see 512e). It would result in 16 TiB with 4 KiB sectors (4Kn), but since many older operating systems and tools are hard coded for a sector size of 512 bytes or are limited to 32-bit calculations, exceeding the 2 TiB limit could cause compatibility problems.[6]\nIn operating systems that support GPT-based boot through BIOS services rather than EFI, the first sector may also still be used to store the first stage of the bootloader code, but modified to recognize GPT partitions. The bootloader in the MBR must not assume a sector size of 512 bytes.[6]\nThe partition table header defines the usable blocks on the disk. It also defines the number and size of the partition entries that make up the partition table (offsets 80 and 84 in the table).[2]: 119 After the header, the Partition Entry Array describes partitions, using a minimum size of 128 bytes for each entry block.[8] The starting location of the array on disk, and the size of each entry, are given in the GPT header. The first 16 bytes of each entry designate the partition type's globally unique identifier (GUID). For example, the GUID for an EFI system partition is C12A7328-F81F-11D2-BA4B-00A0C93EC93B. The second 16 bytes are a GUID unique to the partition. Then follow the starting and ending 64 bit LBAs, partition attributes, and the 36 character (max.) Unicode partition name. As is the nature and purpose of GUIDs and as per RFC 4122, no central registry is needed to ensure the uniqueness of the GUID partition type designators.[9][2]: 2200 The 64-bit partition table attributes are shared between 48-bit common attributes for all partition types, and 16-bit type-specific attributes:\nWindows 7 and earlier do not support UEFI on 32-bit platforms, and therefore do not allow booting from GPT partitions.[27]\nEach partition has a \u0026quot;partition type GUID\u0026quot; that identifies the type of the partition and therefore partitions of the same type will all have the same \u0026quot;partition type GUID\u0026quot;. Each partition also has a \u0026quot;partition unique GUID\u0026quot; as a separate entry, which as the name implies is a unique id for each partition.\nHow to know if I'm booting using UEFI? https://unix.stackexchange.com/questions/148356/how-to-know-if-im-booting-using-uefi\nFirst method:\nOk, I booted up my UEFI box to check. First clue, near the top of dmesg. This shouldn't appear if you're booted via BIOS:\n1[ 0.000000] efi: EFI v2.31 by American Megatrends 2[ 0.000000] efi: ACPI=0xd8769000 ACPI 2.0=0xd8769000 SMBIOS=0xd96d4a98 3[ 0.000000] efi: mem00: type=6, attr=0x800000000000000f, range=[0x0000000000000000-0x0000000000001000) (0MB) 4⋮ Second method:\n1$ sudo efibootmgr 2BootCurrent: 0000 3Timeout: 0 seconds 4BootOrder: 0000 5Boot0000* debian If you are not, then the following should appear:\n1$ sudo efibootmgr 2 3EFI variables are not supported on this system. Note that you'll have to have the efibootmgr package installed. You can also attempt to list the EFI variables:\n1$ efivar -l 2... over 100 lines of output ... Third method:\nCheck if you have a /boot/efi:\n1$ df -h --local | grep /boot 2/dev/sda2 229M 31M 187M 14% /boot 3/dev/sda1 120M 250K 119M 1% /boot/efi Inside that partition should be the files that UEFI executes to boot.\nIf using any of these methods the relevant entries doesn't appear, is very likely you are not using UEFI.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/00-linux-booting/","section":"docs","tags":null,"title":""},{"body":"Check if Your Computer Uses UEFI or BIOS [Both in Linux and Windows] https://itsfoss.com/check-uefi-or-bios/\nBrief: A quick tutorial to tell you if your system uses the modern UEFI or the legacy BIOS. Instructions for both Windows and Linux have been provided.\nWhen you are trying to dual boot Linux with Windows, you would want to know if you have UEFI or BIOS boot mode on your system. It helps you decide in partition making for installing Linux.\nI am not going to discuss what is BIOS here. However, I would like to tell you a few advantages of UEFI over BIOS.\nUEFI or Unified Extensible Firmware Interface was designed to overcome some of the limitations of BIOS. It added the ability to use larger than 2 TB disks and had a CPU independent architecture and drivers. With a modular design, it supported remote diagnostics and repairing even with no operating system installed and a flexible without-OS environment including networking capability.\nAdvantage of UEFI over BIOS UEFI is faster in initializing your hardware. Offer Secure Boot which means everything you load before an OS is loaded has to be signed. This gives your system an added layer of protection from running malware. BIOS do not support a partition of over 2TB. Most importantly, if you are dual booting it’s always advisable to install both the OS in the same booting mode. ![[/uefi-or-bios.png]]\nIf you are trying to find out whether your system runs UEFI or BIOS, it’s not that difficult. Let me start with Windows first and afterward, we’ll see how to check UEFI or BIOS on Linux systems.\nCheck if you are using UEFI or BIOS on Windows On Windows, “System Information” in Start panel and under BIOS Mode, you can find the boot mode. If it says Legacy, your system has BIOS. If it says UEFI, well it’s UEFI.\n![[/BIOS.png]]\nAlternative: If you using Windows 10, you can check whether you are using UEFI or BIOS by opening File Explorer and navigating to C:\\Windows\\Panther. Open file setupact.log and search for the below string.\n1Detected boot environment I would advise opening this file in notepad++, since its a huge text file and notepad may hang (at least it did for me with 6GB RAM).\nYou will find a couple of lines which will give you the information.\n1BIOS Check if you are using UEFI or BIOS on Linux The easiest way to find out if you are running UEFI or BIOS is to look for a folder /sys/firmware/efi. The folder will be missing if your system is using BIOS.\n![[/uefi-bios.png]]\n/sys/firmware/efi exists means system uses UEFI\nAlternative: The other method is to install a package called efibootmgr.\nOn Debian and Ubuntu based distributions, you can install the efibootmgr package using the command below:\n1sudo apt install efibootmgr Once done, type the below command:\n1# sudo efibootmgr If your system supports UEFI, it will output different variables. If not you will see a message saying EFI variables are not supported.\n![[Check if Your Computer Uses UEFI or BIOS [Both in 62b9bd99b5c74fafaca6cf6238995dc2 bootmanager.jpg]]\nFinal Words Finding whether your system is using UEFI or BIOS is easy. On one hand, features like faster and secure boot provide an upper hand to UEFI, there is not much that should bother you if you are using BIOS – unless you are planning to use a 2TB hard disk to boot.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/check-if-your-computer-uses-uefi-or-bios/","section":"docs","tags":null,"title":""},{"body":"How To Boot into Single-User Mode in CentOS 8 / RHEL 8 | ITzGeek https://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-boot-into-single-user-mode-in-rhel-8.html\nSingle-User mode is one of the user run levels in the Linux operating system. It is used for doing the administrative task such as recovering the file system and the lost root password etc.\nIn single-user mode, the services won’t start, and none of the users are allowed to log in except root. Also, the system would not prompt for login, which means you do not need a password to get root access.\nHere, we will see how to boot into a single-user mode in CentOS 8 / RHEL 8.\n1.Interrupt Boot While the system boots, you might see the splash screen like below. The system waits for 5 seconds before booting the operating system. Here, press any key to interrupt the autoboot.\nInterrupt Boot\n2. Choose Kernel It would display the list of kernels and operating systems you have it on the machine. If you are booting into Single-User mode to reset root password or other administrative tasks, you can choose the latest kernel. Whereas, if you have problem with the latest kernel and want to fix the kernel issue, choose the previous kernel.\nTo go into single-user mode, select the kernel and press e edit arguments of the kernel.\nSelect Kernel\n3. Edit Kernel Parameters Now, you should see the information about the selected operating system like hard disk, root partition, location of the kernel, crash kernel, and initrd (Initial ram disk).\nGo to the line that starts with linux using up and down arrow then delete the ro argument.\nKernel Parameter\n4. Boot into Single-User Mode Add this rw init=/sysroot/bin/sh in the line. Once done, press Ctrl+x.\nBoot into Single-User Mode\n5. Single-User Mode Now, you should be in shell prompt with root privileges.\nSingle-User Mode in RHEL 8\nNow, mount root file system with chroot command.\n1chroot /sysroot Mount Root File System\nYou can now troubleshoot your system or can do maintenance of your system. The single-user mode is often used to reset the lost root password in CentOS 8 / RHEL 8.\nOnce you complete the activities, exit from the chroot.\n1exit Then, reboot the system to boot into the default run level.\n1reboot Conclusion That’s all. You have learned how to boot into a single-user mode in CentOS 8 / RHEL 8. Please share your feedback in the comments section.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/how-to-boot-into-single-user-mode-in-centos-8-rhel/","section":"docs","tags":null,"title":""},{"body":"How to Recover or Rescue Corrupted Grub Boot Loader in CentOS 7 https://www.tecmint.com/recover-or-rescue-corrupted-grub-boot-loader-in-centos-7/\nIn this tutorial we’ll cover the process of rescuing a corrupted boot loader in CentOS 7 or Red Hat Enterprise Linux 7 and recover the a forgotten root password.\nThe GRUB boot loader can sometimes be damaged, compromised or deleted in CentOS due to various issues, such as hardware or software related failures or sometimes can be replaced by other operating systems, in case of dual-booting. A corrupted Grub boot loader makes a CentOS/RHEL system unable to boot and transfer the control further to Linux kernel.\nThe Grub boot loader stage one is installed on the first 448 bytes at the beginning of every hard disk, in an area typically known as the Master Boot Record (MBR).\nRead Also: How to Rescue, Repair and Recover Grub Boot Loader in Ubuntu\nThe MBR maximum size is 512 byes long. If from some reason the first 448 bytes are overwritten, the CentOS or Red Hat Enterprise Linux cannot be loaded unless you boot the machine with a CentOS ISO image in rescue mode or using other boot loading methods and reinstall the MBR GRUB boot loader.\nRequirements Recover GRUB Boot Loader in CentOS 7 1. On the first step, download the latest version of CentOS 7 ISO image and burn it to a DVD or create a bootable USB stick. Place the bootable image into your machine appropriate drive and reboot the machine.\nWhile the BIOS performs the POSTs tests, press a special key (Esc, F2, F11, F12, Del depending on the motherboard instructions) in order to enter BIOS settings and modify the boot sequence so that the bootable DVD/USB image is booted first at machine start-up, as illustrated in the below image.\nSystem Boot Menu\n![[/System-Boot-menu.png]]\n2. After the CentOS 7 bootable media has been detected, the first screen will appear in your machine monitor output. From the first menu choose the Troubleshooting option and press [enter] key to continue.\nSelect CentOS 7 Troubleshooting\n![[/Select-CentOS-7-Troubleshooting.png]]\n3. On the next screen choose Rescue a CentOS system option and press [enter] key to move further. A new screen will appear with the message ‘Press the Enter key to begin the installation process’. Here, just press [enter] key again to load the CentOS system to memory.\nRescue CentOS 7 System\n![[/Rescue-CentOS-7-System.png]]\nRescue CentOS 7Process\n![[/Rescue-Process.png]]\n4. After the installer software loads into your machine RAM, the rescue environment prompt will appear on your screen. On this prompt type 1 in order to Continue with the system recovery process, as illustrated in the below image.\nCentOS 7 Rescue Prompt\n![[/CentOS-7-Rescue-Prompt.png]]\n5. On the next prompt the rescue program will inform you that your system has been mounted under /mnt/sysimage directory. Here, as the rescue program suggests, type chroot /mnt/sysimage in order to change Linux tree hierarchy from the ISO image to the mounted root partition under your disk.\nMount CentOS 7 Image\n![[How to Recover or Rescue Corrupted Grub Boot Loade 220b40896c5a45f8825bb7e84abe3a2b Mount-CentOS-7-Image.jpg]]\n6. Next, identify your machine hard drive by issuing the below command in the rescue prompt.\n1# ls /dev/sd* In case your machine uses an underlying old physical RAID controller, the disks will have other names, such as /dev/cciss. Also, in case your CentOS system is installed under a virtual machine, the hard disks can be named /dev/vda or /dev/xvda.\nHowever, after you’ve identified your machine hard disk, you can start installing the GRUB boot loader by issuing the below commands.\n1# ls /sbin | grep grub2 # Identify GRUB installation command 2# /sbin/grub2-install /dev/sda # Install the boot loader in the boot partition of the first hard disk Install Grub Boot Loader in CentOS 7\n![[/Install-Grub-Boot-Loader-in-CentOS-7.png]]\n7. After the GRUB2 boot loader is successfully installed in your hard disk MBR area, type exit to return to the CentOS boot ISO image tree and reboot the machine by typing init 6 in the console, as illustrated in the below screenshot.\nExit CentOS 7 Grub Prompt\n![[/Exit-Grub-Prompt.png]]\n8. After machine restart, you should, first, enter BIOS settings and change the boot order menu (place the hard disk with the installed MBR boot loader on the first position in boot menu order).\nSave BIOS settings and, again, reboot the machine to apply the new boot order. After reboot the machine should start directly into the GRUB menu, as shown in the below image.\nCentOS 7 Grub Menu\n![[/CentOS-7-Grub-menu.png]]\nCongratulations! You’ve successfully repaired your CentOS 7 system damaged GRUB boot loader. Be aware that sometimes, after restoring the GRUB boot loader, the machine will restart once or twice in order to apply the new grub configuration.\nRecover Root Password in CentOS 7 9. If you’ve forgotten the root password and you cannot log in to CentOS 7 system, you can basically reset (blank) the password by booting the CentOS 7 ISO DVD image in recovery mode and follow the same steps as shown above, until you reach step 6. While you’re chrooted into your CentOS installation file system, issue the following command in order to edit Linux accounts password file.\n1# vi /etc/shadow In shadow file, identify the root password line (usually is the first line), enter vi edit mode by pressing the i key and delete the entire string in between the first colon “:” and the second colon ”:”, as illustrated in the below screenshot.\nRoot Encrypted Password\n![[/Root-Password-Info.png]]\nDelete Root Encrypted Password\n![[/Delete-Encrypted-Root-Password.png]]\nAfter you finish, save the file by pressing the following keys in this order Esc -\u0026gt; : -\u0026gt; wq!\n10. Finally, exit the chrooted console and type init 6 to reboot the machine. After reboot, login to your CentOS system with the root account, which has no password configured now, and setup a new password for root user by executing the passwd command, as illustrated in the below screenshot.\nSet New Root Password in CentOS 7\n![[/Set-New-Root-Password-in-CentOS-7.png]]\nThat’s all! Booting a physical machine or a VM with a CentOS 7 DVD ISO image in recovery mode can help system administrators to perform various troubleshooting tasks for a broken system, such as recovering data or the ones described in the tutorial.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/how-to-recover-or-rescue-corrupted-grub-boot-loade/","section":"docs","tags":null,"title":""},{"body":"InitRAMFS, Dracut, and the Dracut Emergency Shell - Fedora Magazine https://fedoramagazine.org/initramfs-dracut-and-the-dracut-emergency-shell/\n![[/dracut.png]]\nThe Linux startup process goes through several stages before reaching the final graphical or multi-user target. The initramfs stage occurs just before the root file system is mounted. Dracut is a tool that is used to manage the initramfs. The dracut emergency shell is an interactive mode that can be initiated while the initramfs is loaded.\nThis article will show how to use the dracut command to modify the initramfs. Some basic troubleshooting commands that can be run from the dracut emergency shell will also be demonstrated.\nThe InitRAMFS Initramfs stands for Initial Random-Access Memory File System. On modern Linux systems, it is typically stored in a file under the /boot directory. The kernel version for which it was built will be included in the file name. A new initramfs is generated every time a new kernel is installed.\n![[InitRAMFS, Dracut, and the Dracut Emergency Shell e1f8cda9a2b84624a517666ab6234935 boot.jpg]]\nA Linux Boot Directory\nBy default, Fedora keeps the previous two versions of the kernel and its associated initramfs. This default can be changed by modifying the value of the installonly_limit setting the /etc/dnf/dnf.conf file.\nYou can use the lsinitrd command to list the contents of your initramfs archive:\n![[InitRAMFS, Dracut, and the Dracut Emergency Shell e1f8cda9a2b84624a517666ab6234935 lsinitrd.jpg]]\nThe LsInitRD Command\nThe above screenshot shows that my initramfs archive contains the nouveau GPU driver. The modinfo command tells me that the nouveau driver supports several models of NVIDIA video cards. The lspci command shows that there is an NVIDIA GeForce video card in my computer’s PCI slot. There are also several basic Unix commands included in the archive such as cat and cp.\nBy default, the initramfs archive only includes the drivers that are needed for your specific computer. This allows the archive to be smaller and decreases the time that it takes for your computer to boot.\nThe Dracut Command The dracut command can be used to modify the contents of your initramfs. For example, if you are going to move your hard drive to a new computer, you might want to temporarily include all drivers in the initramfs to be sure that the operating system can load on the new computer. To do so, you would run the following command:\nThe force parameter tells dracut that it is OK to overwrite the existing initramfs archive. The no-hostonly parameter overrides the default behavior of including only drivers that are germane to the currently-running computer and causes dracut to instead include all drivers in the initramfs.\nBy default dracut operates on the initramfs for the currently-running kernel. You can use the uname command to display which version of the Linux kernel you are currently running:\nOnce you have your hard drive installed and running in your new computer, you can re-run the dracut command to regenerate the initramfs with only the drivers that are needed for the new computer:\nThere are also parameters to add arbitrary drivers, dracut modules, and files to the initramfs archive. You can also create configuration files for dracut and save them under the /etc/dracut.conf.d directory so that your customizations will be automatically applied to all new initramfs archives that are generated when new kernels are installed. As always, check the man page for the details that are specific to the version of dracut you have installed on your computer:\nThe Dracut Emergency Shell ![[InitRAMFS, Dracut, and the Dracut Emergency Shell e1f8cda9a2b84624a517666ab6234935 dracut-shell.jpg]]\nThe Dracut Emergency Shell\nSometimes something goes wrong during the initramfs stage of your computer’s boot process. When this happens, you will see “Entering emergency mode” printed to the screen followed by a shell prompt. This gives you a chance to try and fix things up manually and continue the boot process.\nAs a somewhat contrived example, let’s suppose that I accidentally deleted an important kernel parameter in my boot loader configuration:\nThe next time I reboot my computer, it will seem to hang for several minutes while it is trying to find the root partition and eventually give up and drop to an emergency shell.\nFrom the emergency shell, I can enter journalctl and then use the Space key to page down though the startup logs. Near the end of the log I see a warning that reads “/dev/mapper/fedora-root does not exist”. I can then use the ls command to find out what does exist:\nHmm, the fedora-root LVM volume appears to be missing. Let’s see what I can find with the lvm command:\nlvm lvscan ACTIVE '/dev/fedora/swap' [3.85 GiB] inherit inactive '/dev/fedora/home' [22.85 GiB] inherit inactive '/dev/fedora/root' [46.80 GiB] inherit Ah ha! There’s my root partition. It’s just inactive. All I need to do is activate it and exit the emergency shell to continue the boot process:\n![[InitRAMFS, Dracut, and the Dracut Emergency Shell e1f8cda9a2b84624a517666ab6234935 fedora-login.jpg]]\nThe Fedora Login Screen\nThe above example only demonstrates the basic concept. You can check the troubleshooting section of the dracut guide for a few more examples.\nIt is possible to access the dracut emergency shell manually by adding the rd.break parameter to your kernel command line. This can be useful if you need to access your files before any system services have been started.\nCheck the dracut.kernel man page for details about what kernel options your version of dracut supports:\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/initramfs-dracut-and-the-dracut-emergency-shell-/","section":"docs","tags":null,"title":""},{"body":"The fundamentals of network booting https://networkboot.org/fundamentals/\nWhat is network booting? Network booting, or booting from LAN as it is also called, is a process which allows a computer to start up and load an operating system or other program directly from the network without any locally attached storage device, like a floppy, CDROM, USB stick or hard drive.\nOn Intel architecture computers this is made possible with the PXE standard. PXE extends the features of the BIOS so that it can run software directly from the network. PXE support is now so common that you can expect it to be present in any reasonably modern computer that comes with an Ethernet jack (commonly known as RJ45).\nThis fact alone makes it possible to boot an Intel-based computer from the network without having to burn an EEPROM on your network card, like you had to do in the past.\nOther relevant protocols All of these network protocols deal with how to access storage over they network in different ways.\nAoE - for block devices (non-routable, local network only) The BIOS boot process When your computer powers on and starts running your operating system, it goes through a series of operations before it actually starts your operating system. Your operating system is a very sophisticated boot program that takes total control over your computer. But a boot program can also be a fairly simple program, like a memory diagnostics program, a hardware stability checker, or even a simple game like Pong or Tetris.\nPower On When you put power on your computer and press the On button on the case. Initialize hardware The BIOS performs an inventory of all the components in the computer, such as the CPU, memory chips, extension cards, storage controllers, etc. Run self-tests All of the components discovered goes through a self-test procedure, to ensure they are operating properly. If any of the components fail, and that component is required for basic operation, your computer will usually make a series of beeps and stop functioning. When all problems have been fixed the BIOS will move on to the next step in the process, which is to discover additional option ROMs. Computer stopped If your computer ends up in this state, it will either hang forever, or it will turn itself off. This depends on how it entered this state, and how your BIOS is configured to react when it reaches this state. During this activity, your BIOS will discover all of the extensions available. BIOS extensions are usually included in the firmware of your BIOS or burned into an EEPROM or flash chip on one of your add-on cards. During booting you can normally notice this as your IDE, SATA, SCSI or other controllers finding the devices that are attached to them. For network cards, this is usually when you see the prompt that lets you specify what kind of boot protocol it should support (like PXE or RPL). Option ROMs should usually not do anything fancy at this point, except initialize hardware, run self-tests and set up boot service (BBS) entry points. Once all extensions have been allowed to run and add their boot service entry points, control goes back to the BIOS. At this point all the add-on cards and internal services of the BIOS have been initialized and are ready to do work. All of the boot service entry points are ordered according to the configuration specified in the BIOS. It is quite common that the user is given a choice of which boot service to try first by pressing a hotkey. F12 is a common key to start a boot service offered by a network card, but this varies among manufacturers. Once the first boot service has been selected, either manually or automatically, control moves to the next step. During this stage, the program indicated by the boot service entry point is started. At this point, control passes to the boot service program, which starts its discovery process for a boot program. Boot service performs discovery for boot program Different boot services go about looking for the boot program in different ways. A floppy controller will read the first sector of the floppy and get ready to start that piece of code. A hard-drive (HDD) controller will usually read the master boot record (MBR) of the first attached HDD and designate that as the boot program. A network card using the PXE standard will perform a DHCP request to find out its IP address and location of boot program. If a location is advertised, a TFTP request is performed to fetch the boot program, commonly referred to as a network boot program (NBP). If the boot service was unable to find a valid boot program, the boot service will exit and control returns back to the BIOS, which will try the next boot service. If a boot program was successfully found, control will be handed over to it. Remove first boot service or put at bottom of list The BIOS needs to cycle to the next boot service in its list. Whether the BIOS discards the current boot service or adds it back at the end of the list varies between BIOS vendors. Both methods have pros and cons. The next step is to figure out if there are any more boot services to try out. More boot services available? If there are more boot services available, the next one in line will be started. If there are no more boot services the computer will halt and perform its halt operation. Start boot program At this point the boot program is in full control of the computer, and it will start doing whatever it is supposed to do. If the boot program detects a problem or wishes to, it can return back to the BIOS. This is not a very common thing to do for a boot program, as a lot of BIOSes have buggy implementations for getting control back. The more common method is just to display a message and hang, or reboot instantly. Since the boot program has full control over the computer it can make use of all the other devices the BIOS has detected to perform whatever action it needs to. Boot program running The final part a boot program normally does, is to hand over control to an operating system kernel. A boot program that performs this kind of action is usually called a boot loader. Common boot loaders for Linux systems are grub and syslinux. Before the boot loader does this, it will usually also fetch additional data from a storage device, e.g. drivers and configuration files. Any program code required to operate the hardware must be in main memory at this point, or you will be unable to access the hardware. This requirement is usually implemented using ramdisks, so that the kernel can be kept modular and flexible. In Linux they are called initial ramdisks (initrds), in Solaris they go by the name boot archives, and in recent Windows versions they are called wim files. The operating system kernel will then perform a complete discovery of the hardware attached to the system (again) and start doing whatever it is programmed to do. At this point, because another piece of code (the kernel) is in direct control of the hardware, it would be very unwise to switch control back to the BIOS, as hardware state has been modified under its feet.\nDownload diagram source code\nHow iPXE extends the network boot process iPXE is a sophisticated boot program that is capable of extending the traditional PXE network boot process in several ways. It can be flashed as an add-on card's option ROM, or it can be loaded as a network boot program (NBP) from an existing PXE option ROM via TFTP (this is called chainloading). It is also possible to include it as an option ROM inside your BIOS or load it from any local storage media, like floppy, USB, CD or HDD.\nDepending on how iPXE is configured, it can load additional boot programs from several different sources in addition to TFTP. The most common way is to use HTTP to load additional content using a standard web server. If your web server supports range requests, you can also use it to boot floppies and CD images (ISOs) directly from the web server. FTP can also be used in the same way. There is even support for encrypted transmission with HTTPS. It is possible to configure it to only allow execution of programs that have been signed. If you combine this with ROM-burning you can have a network boot loader that will load only trusted code.\nOne of the most interesting features iPXE enables, is to boot a computer without an iSCSI host bus adapter from an iSCSI volume. This is possible, because iPXE implements a full-featured software-based iSCSI initiator. It even supports CHAP authentication! For operating systems that support it, you can also use AoE (ATA Over Ethernet) in addition to iSCSI.\nThe final feature that makes iPXE so impressive, is that it also has a very advanced scripting language and text-based menu system. These features enable you to make dynamic boot environments without the need to know a server-side scripting language like PHP, Perl or Python.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/the-fundamentals-of-network-booting/","section":"docs","tags":null,"title":""},{"body":"The Kernel Newbie Corner: \u0026quot;initrd\u0026quot; and \u0026quot;initramfs\u0026quot;-What's Up With That? - Linux.com https://www.linux.com/tutorials/kernel-newbie-corner-initrd-and-initramfs-whats/\nThis week, I’m not going to write a formal column so much as just free associate a bit regarding an exchange we had recently on the Kernel Newbies mailing list regarding the ideas of initrd and initramfs, and what they’re for and, most importantly, how they differ. And that’s where we might get deliberately vague since different people use the terminology differently, so I’ll present my view of the terms and the way I use them, whereupon you’re free to disagree vehemently.\n(The archive of all previous “Kernel Newbie Corner” articles can be found here.)\nThis is ongoing content from the Linux Foundation training program. If you want more content, please consider signing up for one of these classes.\nSo… What Are They? If we can be a little sloppy for a minute or two, both of those concepts refer to a simple idea — that of an “early userspace” root filesystem that can be used to get at least the minimum functionality loaded in order to let the boot process continue. There’s a lengthy explanation in the kernel source tree in the file Documentation/filesystems/ramfs-rootfs-initramfs.txt, but I’ll try to simplify that just a bit.\nIn a nutshell, when your bootloader (GRUB?) loads your Linux kernel, it is of course the kernel’s job to finish the boot process. But to do so, it might require particular drivers to be able to work with, say, hardware RAID controllers, or a network, and so on. And depending on where those critically important drivers are, the kernel might not have the ability to load them; hence, the creation of a preliminary root file system that would contain just enough in the way of loadable modules to give the kernel access to the rest of the hardware.\nQuite simply, it’s the bootloader’s job to pass control to the kernel, hand it the “initrd” (initial ram disk), let the kernel mount it and get what it needs, whereupon the kernel can toss the initrd and replace it with the real root filesystem. With me so far?\nSo Tell Me About the “initrd” Almost everyone is familiar with the use of an initrd file, since most of you have undoubtedly seen one or more of them sitting in your /boot directory. If you’re using the GRUB bootloader, you identify which initrd image matches which kernel in your GRUB configuration file thusly:\n1title Fedora (2.6.31) 2root (hd0,0) 3kernel /vmlinuz-2.6.31 ro root=/dev/mapper/f11-root nomodeset rhgb quiet initrd /initrd-2.6.31.img That “stanza” tells GRUB which initrd file to hand to each kernel at boot time. Simple enough. But what’s in that initrd file? I’m glad you asked.\nOnce upon a time, those files were compressed filesystem image files, most likely ext2-format filesystems. This meant that, to see their contents (and who hasn’t wanted to peek inside them?), you would have to first gunzip them (easy), then mount them somewhere, which was not so easy without being root, which meant that regular users were denied the fun of poking around inside those files to get a better understanding of the early boot process. But things have changed.\nNowadays, those files are almost certainly cpio-format files, which means they are perusable by regular users. Well, OK, not really since they’re read-protected so, sadly, you still have to be root for that part. But assuming you can get read access to one of those files, you could:\n1# gunzip -c /boot/initrd-2.6.31.img \u0026gt; /tmp/my_initrd $ cpio -it \u0026lt; /tmp/my_initrd [examine contents] lib lib/udev lib/udev/console_init lib/firmware lib/firmware/radeon lib/firmware/radeon/RV730_me.bin ... snip ... lib/modules lib/modules/2.6.31 lib/modules/2.6.31/radeon.ko lib/modules/2.6.31/modules.isapnpmap ... and so on and so on ... $ cd [somewhere] [in preparation for unloading] $ cpio -i \u0026lt; /tmp/my_initrd [unload] And now that you’ve unloaded your initrd file, you can peruse its root file system-like contents at your leisure to get a better understanding of the early part of the boot process, before the real root file system comes into play.\nBut wait. There’s more.\nWhere did that initrd file come from? Typically, when you install a new kernel, you’ll get a matching initrd file automatically, but you can always build one manually using the mkinitrd command. I’m not going to get into horrendous detail with this command. If you truly want to play with it, feel free. Create a new initrd file or two, then pull it apart to see what’s inside.\nBut here’s where things get just a bit more interesting.\nOK, So What’s the “initramfs” Thingy? And here’s where we might part ways regarding terminology. I will always refer to the above file as the “initrd” file since, in my opinion, the “initramfs” early root file system is something quite different.\nQuite simply, the “initramfs” (initial RAM file system) is what I call an even earlier potential root file system that you can build into the kernel image itself. And because of its location (internal to the kernel), it will (if it exists) take precedence. So how do you add an internal root file system to your kernel image itself?\nAssuming you’re building your own kernel, you need to select the following configuration option, defined in the kernel source tree in the init/Kconfig file:\n1config BLK_DEV_INITRD bool \u0026#34;Initial RAM filesystem and RAM disk (initramfs/initrd) support\u0026#34; depends on BROKEN || !FRV help The initial RAM filesystem is a ramfs which is loaded by the boot loader (loadlin or lilo) and that is mounted as root before the normal boot procedure. It is typically used to load modules needed to mount the \u0026#34;real\u0026#34; root file system, etc. See \u0026lt;file:Documentation/initrd.txt\u0026gt; for details. If RAM disk support (BLK_DEV_RAM) is also included, this also enables initial RAM disk (initrd) support and adds 15 Kbytes (more on some other architectures) to the kernel size. If unsure say Y. And based on what you read above, you should notice that this is the single option that selects support for both types of early root file systems. There is no (apparent) way to select support for only one or the other, and I’ve occasionally wondered if there would be any value in extending the configuration to allow that. In any event, the way it stands, you either get support for both or neither.\nSo How Do I Identify What I Want in My “initramfs”? Easy. If you look again in init/Kconfig right under the text you see above, you’ll see:\n1if BLK_DEV_INITRD source \u0026#34;usr/Kconfig\u0026#34; endif which means that that single selection brings the entire top-level kernel usr directory into play, which represents everything you need to build your early userspace initramfs content that will be embedded in the kernel.\nTake a look at the configuration options in usr/Kconfig, which includes how to specify what you want in your initramfs:\n1config INITRAMFS_SOURCE string \u0026#34;Initramfs source file(s)\u0026#34; default \u0026#34;\u0026#34; help This can be either a single cpio archive with a .cpio suffix or a space-separated list of directories and files for building the initramfs image. A cpio archive should contain a filesystem archive to be used as an initramfs image. Directories should contain a filesystem layout to be included in the initramfs image. Files should contain entries according to the format described by the \u0026#34;usr/gen_init_cpio\u0026#34; program in the kernel tree. When multiple directories and files are specified then the initramfs image will be the aggregate of all of them. See \u0026lt;file:Documentation/early-userspace/README\u0026gt; for more details. If you are not sure, leave it blank. In short, you can build (another) cpio-format image file that represents what you want in your initramfs, and just mention it during your kernel configuration process. After that, you can build your kernel, at which point the final cpio-format file that was used for your initramfs will be sitting in the generated file usr/initramfs_data.cpio, and you can use the same extraction commands from early on to examine its contents as well.\nBut What if I Don’t Give any initramfs Contents? Even if you select initrd/initramfs support, there’s nothing that demands that you have to whip up a cpio-format file to be used to build your kernel initramfs. But even if you don’t, you’ll still have one — it just won’t be very exciting.\nIf you examine the kernel shell script scripts/gen_initramfs_list.sh, you can examine just how that cpio-format initramfs file is created. And buried in there somewhere is the definition of the “default” initramfs if you choose not to specify any contents:\n1default_initramfs() { cat \u0026lt;\u0026lt;-EOF \u0026gt;\u0026gt; ${output} # This is a very simple, default initramfs dir /dev 0755 0 0 nod /dev/console 0600 0 0 c 5 1 dir /root 0700 0 0 # file /kinit usr/kinit/kinit 0755 0 0 # slink /init kinit 0755 0 0 EOF } The above should be self-explanatory — your default initramfs will contain all of two objects — a /root directory and a /dev/console special device file. That’s not terribly exciting, which means that if you don’t design a usable initramfs for your kernel, you’d better have a practical initrd file to pick up the slack.\nAnything Else? Plenty, and the comments section is open for discussion. As a final observation, if you really want to see the code for the early boot process, that’s all in the top-level init directory, where you can see source files whose names clearly reflect that they’re doing something with mounts and root file systems and initrds and so on.\nPerhaps the most interesting observation is this snippet from the Makefile in that directory, which shows what happens depending on whether you even select support for initrd/initramfs;\n1ifneq ($(CONFIG_BLK_DEV_INITRD),y) obj-y += noinitramfs.o else obj-$(CONFIG_BLK_DEV_INITRD) += initramfs.o endif Obviously, depending on your selection, only one of two source files will be compiled into your kernel image. You can follow the more involved of the two — initramfs.c — to see how the kernel uses that initramfs image, but it’s at least as educational to see what happens if the kernel has no such support whatsoever. Consider the code from noinitramfs.c:\n1/* * Create a simple rootfs that is similar to the default initramfs */ static int __init default_rootfs(void) { int err; err = sys_mkdir(\u0026#34;/dev\u0026#34;, 0755); if (err \u0026lt; 0) goto out; err = sys_mknod((const char __user *) \u0026#34;/dev/console\u0026#34;, S_IFCHR | S_IRUSR | S_IWUSR, new_encode_dev(MKDEV(5, 1))); if (err \u0026lt; 0) goto out; err = sys_mkdir(\u0026#34;/root\u0026#34;, 0700); if (err \u0026lt; 0) goto out; return 0; out: printk(KERN_WARNING \u0026#34;Failed to create a rootfsn\u0026#34;); return err; } In other words, even if you don’t select initramfs support, you’re still going to get one built manually at boot time. Cute, no?\nAt this point, I’ll open up the comments section so feel free to discuss, debate or just plain argue. There is, in fact, quite a bit more that can be written about the entire early userspace process, and I’ll take a couple days to decide if I want to follow this up with a Part Two, if there’s sufficient interest.\n","link":"https://arvimal.github.io/docs/linux-booting/00-boot-process/the-kernel-newbie-corner-initrd-and-initramfs/","section":"docs","tags":null,"title":""},{"body":"Linux on your laptop: A closer look at EFI boot options https://www.zdnet.com/article/linux-on-your-laptop-a-closer-look-at-efi-boot-options/\nFor some time now I have gotten a slow but steady volume of requests that I write about UEFI firmware and EFI boot relative to installing and maintaining Linux. As a result of a casual comment I made in a recent post about installing Linux on a new laptop, the volume has gone up considerably.\nSo in this post I will review and explain some of what I consider to be the most important points about UEFI firmware and Linux systems. I intend for this to be a relatively short post, but once I get started you never know... so you might want to get a cup of coffee before starting to read.\nFirst, the specific aspect of UEFI firmware that I am concerned with here is the boot sequence, and how to use it with Linux. There is a lot more to UEFI (EFI) than that, but I will not be addressing any of that here.\nSEE: 20 quick tips to make Linux networking easier (free PDF)\nWhat I am going to look at is how the boot sequence differs from the previous standard, and how it should be configured and managed for a Linux installation. I am likely to use the terms \u0026quot;EFI\u0026quot; and \u0026quot;UEFI\u0026quot; interchangeably in this post; that is certainly not correct in general, but for purposes of what I am writing they both mean more or less the same thing.\nBefore EFI, the standard boot process for virtually all PC systems was called \u0026quot;MBR\u0026quot;, for Master Boot Record; today you are likely to hear it referred to as \u0026quot;Legacy Boot\u0026quot;. This process depended on using the first physical block on a disk to hold some information needed to boot the computer (thus the name Master Boot Record); specifically, it held the disk address at which the actual bootloader could be found, and the partition table that defined the layout of the disk. Using this information, the PC firmware could find and execute the bootloader, which would then bring up the computer and run the operating system.\nThis system had a number of rather obvious weaknesses and shortcomings. One of the biggest was that you could only have one bootable object on each physical disk drive (at least as far as the firmware boot was concerned). Another was that if that first sector on the disk became corrupted somehow, you were in deep trouble.\nOver time, as part of the Extensible Firmware Interface, a new approach to boot configuration was developed. Rather than storing critical boot configuration information in a single \u0026quot;magic\u0026quot; location, EFI uses a dedicated \u0026quot;EFI boot partition\u0026quot; on the desk. This is a completely normal, standard disk partition, the same as which may be used to hold the operating system or system recovery data.\nThe only requirement is that it be FAT formatted, and it should have the boot and esp partition flags set (esp stands for EFI System Partition). The specific data and programs necessary for booting is then kept in directories on this partition, typically in directories named to indicate what they are for. So if you have a Windows system, you would typically find directories called 'Boot' and 'Microsoft', and perhaps one named for the manufacturer of the hardware, such as HP. If you have a Linux system, you would find directories called opensuse, debian, ubuntu, or any number of others depending on what particular Linux distribution you are using.\nIt should be obvious from the description so far that it is perfectly possible with the EFI boot configuration to have multiple boot objects on a single disk drive.\nBefore going any further, I should make it clear that if you install Linux as the only operating system on a PC, it is not necessary to know all of this configuration information in detail. The installer should take care of setting all of this up, including creating the EFI boot partition (or using an existing EFI boot partition), and further configuring the system boot list so that whatever system you install becomes the default boot target.\nIf you were to take a brand new computer with UEFI firmware, and load it from scratch with any of the current major Linux distributions, it would all be set up, configured, and working just as it is when you purchase a new computer preloaded with Windows (or when you load a computer from scratch with Windows). It is only when you want to have more than one bootable operating system – especially when you want to have both Linux and Windows on the same computer – that things may become more complicated.\nThe problems that arise with such \u0026quot;multiboot\u0026quot; systems are generally related to getting the boot priority list defined correctly.\nWhen you buy a new computer with Windows, this list typically includes the Windows bootloader on the primary disk, and then perhaps some other peripheral devices such as USB, network interfaces and such. When you install Linux alongside Windows on such a computer, the installer will add the necessary information to the EFI boot partition, but if the boot priority list is not changed, then when the system is rebooted after installation it will simply boot Windows again, and you are likely to think that the installation didn't work.\nThere are several ways to modify this boot priority list, but exactly which ones are available and whether or how they work depends on the firmware of the system you are using, and this is where things can get really messy. There are just about as many different UEFI firmware implementations as there are PC manufacturers, and the manufacturers have shown a great deal of creativity in the details of this firmware.\nFirst, in the simplest case, there is a software utility included with Linux called efibootmgr that can be used to modify, add or delete the boot priority list. If this utility works properly, and the changes it makes are permanent on the system, then you would have no other problems to deal with, and after installing it would boot Linux and you would be happy. Unfortunately, while this is sometimes the case it is frequently not. The most common reason for this is that changes made by software utilities are not actually permanently stored by the system BIOS, so when the computer is rebooted the boot priority list is restored to whatever it was before, which generally means that Windows gets booted again.\nThe other common way of modifying the boot priority list is via the computer BIOS configuration program. The details of how to do this are different for every manufacturer, but the general procedure is approximately the same. First you have to press the BIOS configuration key (usually F2, but not always, unfortunately) during system power-on (POST). Then choose the Boot item from the BIOS configuration menu, which should get you to a list of boot targets presented in priority order. Then you need to modify that list; sometimes this can be done directly in that screen, via the usual F5/F6 up/down key process, and sometimes you need to proceed one level deeper to be able to do that. I wish I could give more specific and detailed information about this, but it really is different on every system (sometimes even on different systems produced by the same manufacturer), so you just need to proceed carefully and figure out the steps as you go.\nI have seen a few rare cases of systems where neither of these methods works, or at least they don't seem to be permanent, and the system keeps reverting to booting Windows. Again, there are two ways to proceed in this case. The first is by simply pressing the \u0026quot;boot selection\u0026quot; key during POST (power-on). Exactly which key this is varies, I have seen it be F12, F9, Esc, and probably one or two others. Whichever key it turns out to be, when you hit it during POST you should get a list of bootable objects defined in the EFI boot priority list, so assuming your Linux installation worked you should see it listed there. I have known of people who were satisfied with this solution, and would just use the computer this way and have to press boot select each time they wanted to boot Linux.\nThe alternative is to actually modify the files in the EFI boot partition, so that the (unchangeable) Windows boot procedure would actually boot Linux. This involves overwriting the Windows file bootmgfw.efi with the Linux file grubx64.efi. I have done this, especially in the early days of EFI boot, and it works, but I strongly advise you to be extremely careful if you try it, and make sure that you keep a copy of the original bootmgfw.efi file. Finally, just as a final (depressing) warning, I have also seen systems where this seemed to work, at least for a while, but then at some unpredictable point the boot process seemed to notice that something had changed and it restored bootmgfw.efi to its original state – thus losing the Linux boot configuration again. Sigh.\nSo, that's the basics of EFI boot, and how it can be configured. But there are some important variations possible, and some caveats to be aware of.\nAt the beginning of the description, I said that when you install Linux it will add the necessary boot information to an existing EFI boot partition alongside any existing configuration of Windows or other Linux distributions. In fact you may have more than one EFI boot partition on a disk, so you might choose to create a new (additional) EFI boot partition, and use that for your Linux installation. Some Linux distributions (notably Fedora and its derivatives) do this by default, while others give you the option of doing it, and will simply add to the first existing EFI boot partition if you don't do so. A few distributions (notably Ubuntu and its derivatives) don't give you a choice, they just install to the first EFI boot partition. This is probably ok, unless... (read on)\nAs I mentioned at the beginning, most Linux distributions use a unique name, usually derived from the name of the distribution, for their EFI boot directory. Unfortunately not all of them do; in particular, Linux Mint and a few other Ubuntu derivates still use the name ubuntu for the boot directory. This is not a problem, unless you try to install two distributions which both use the same name for that directory; then the second installation will overwrite the first, and you will end up only being able to boot one of them. In this case you are basically forced to use a separate EFI boot partition for at least one of them, which is what I did with my new HP laptop, which kicked off all the latest excitement that led to this article.\nThe last thing to mention here is that the Linux utility for creating the EFI boot configuration has been improved quite a bit over the past few years. It no longer requires a long and complex sequence of command line options to specify the configuration, it is able to create a functional minimum configuration entirely on its own. So if something happens and your boot data gets corrupted or destroyed, you can recreate it, in the correct location, by simply running \u0026quot;grub-install /dev/xxx\u0026quot; (or grub2-install, depending on the distribution), where the xxx is replaced by your primary disk name, generally sda.\nThis covers the general overview of EFI booting, and how to configure (or coax) it into working for Linux/Windows dual boot (or multi-boot). Please note that one thing I did not talk about here are \u0026quot;boot fix\u0026quot; utilities, which claim to create or repair such a configuration for you. There are a few simple reasons for this; first, I don't like them, because I don't like things in general that supposedly offer a \u0026quot;magic fix\u0026quot; to a difficult problem; second, because as can be seen from the post, the details of EFI boot configuration are still changing, and a \u0026quot;magic utility\u0026quot; which works today may well not work tomorrow, or which works for one distribution or for dual boot, might not work for another distribution or for multi-boot (more than two boot objects). I think it is much more advisable to actually take the time to understand what you are doing if you are this deep into system administration, so that you know what to change, how to change it, and how to fix it if something goes wrong. Call me old-fashioned.\nOh, one last thing. There is also a utility package available called rEFInd that will help you set up and manage EFI boot configuration. I have used it, and it works (or did when I last used it several years ago), so if you are struggling and can't get anything to work, that might be worth a try. I don't consider it to be a \u0026quot;magic utility\u0026quot;, because you can see everything that it does, and the accompanying documentation explains it all. Basically it tries to install itself as the first boot object, and then make a list of all the other possible boot targets on your computer and present them to you for selection. If it works, that's fine – and it is actually a good way to learn how all of this works – but I am not convinced that it is really necessary anymore. Most systems today come with EFI firmware that is sufficiently configurable that you can set up a properly working system without too much trouble, in which case rEFInd is generally overkill.\nI hope this information is useful to some people. I realize that it is rather dry and technical, but that's just the way EFI boot is. If I have anything significantly wrong, feel free to post comments and corrections. There is obviously more that could be said about this, but I think this is more than enough for now. I hope to follow up on this post with another, which describes and discusses the specific way that I set up the Grub configuration file on my multi-boot EFI systems, if there is sufficient interest in that. It's not standard, and it is a bit of work to maintain it, but I think it has some advantages.\n","link":"https://arvimal.github.io/docs/linux-booting/01-uefi-efi/linux-on-your-laptop-a-closer-look-at-efi-boot-options/","section":"docs","tags":null,"title":""},{"body":"Secure boot with QEMU and UEFI https://www.labbott.name/blog/2016/09/15/secure-ish-boot-with-qemu/\n(Edit 9/21: I've gotten some feedback and clarifications about a few steps and also updated the wiki. Thanks to the OVMF developers!)\nDespite having too many machines in my possession, none of the x86 machines I have are currently set up to boot with UEFI. This put a real damper on my plans to poke at secure boot. Fortunately, there is virtualization technology to solve this problem. I really like being able to boot kernels directly without a full VM image. There are some instructions for getting started but they are a bit incomplete for what I wanted to do. This is what I used to get secure boot working (or at least detected) in QEMU. I make no guarantees about it actually being secure or signed correctly but it's a starting point for experiments.\nThe secure boot firmware is available as part of the standard Fedora package.\n1$ sudo dnf install edk2-ovmf You need to tell QEMU to pick up the firmware and emulate a file for storing EFI variables. The firmware used here is going to be OVMF_CODE.secboot.fd.\n1$ cp /usr/share/edk2/ovmf/OVMF_VARS.fd my_vars.fd This creates a copy of the base variables file for modification and use. The options you need to append to QEMU are (with some comments in #)\n1# required machine type 2-machine q35,smm=on,accel=kvm 3# Due to the way some of the models work in edk2, we need to disable 4# s3 resume. Without this option, qemu will appear to silently hang 5# althouh it emits an error message on the ovmf_log 6-global ICH9-LPC.disable_s3=1 7# Secure! 8-global driver=cfi.pflash01,property=secure,value=on 9# Point to the firmware 10-drive if=pflash,format=raw,unit=0,file=/usr/share/edk2/ovmf/OVMF_CODE.secboot.fd,readonly=on 11# Point to your copy of the variables 12- drive if=pflash,format=raw,file=/home/labbott/my\\_vars.fd I added these to the existing command I had for QEMU. I bumped the memory on the KVM command line to 500 as well (-m 500). If all goes well, you should be able to boot a kernel and have it detect EFI (dmesg | grep EFI) with this setup.\nTo actually enable secure boot, we need to run an EFI program to load a set of certificates. The default Fedora build provides a nice .iso with the UEFI shell and EFI application built in, /usr/share/edk2/ovmf/UefiShell.iso. Add -hda /usr/share/edk2/ovmf/UefiShell.iso to your QEMU command and remove the -kernel and -initrd options. If all goes well, you should be dropped into the UEFI shell. You can now run the command to add keys\n1Shell\u0026gt; FS0: 2FS0:\\\u0026gt; EnrollDefaultKeys.efi Your vars file should now be all set up for secure boot. If you boot with a -kernel and -initrd option, you should be able to boot a kernel and have it detect secure boot (dmesg | grep Secure).\nBooting your own kernels isn't too difficult. If you take a tree that has secure boot patches in it, make sure the following set of options is enabled\n1CONFIG_SYSTEM_DATA_VERIFICATION=y 2CONFIG_SYSTEM_BLACKLIST_KEYRING=y 3CONFIG_MODULE_SIG=y 4CONFIG_MODULE_SIG_ALL=y 5CONFIG_MODULE_SIG_UEFI=y 6CONFIG_MODULE_SIG_SHA256=y 7CONFIG_MODULE_SIG_HASH=\u0026#34;sha256\u0026#34; 8CONFIG_ASN1=y 9CONFIG_EFI_STUB=y 10CONFIG_EFI_SECURE_BOOT_SIG_ENFORCE=y 11CONFIG_ASYMMETRIC_KEY_TYPE=y 12CONFIG_ASYMMETRIC_PUBLIC_KEY_SUBTYPE=y 13CONFIG_X509_CERTIFICATE_PARSER=y 14CONFIG_PKCS7_MESSAGE_PARSER=y 15CONFIG_SIGNED_PE_FILE_VERIFICATION=y 16CONFIG_EFI_SIGNATURE_LIST_PARSER=y 17CONFIG_MODULE_SIG_KEY=\u0026#34;certs/signing_key.pem\u0026#34; 18CONFIG_SYSTEM_TRUSTED_KEYRING=y 19CONFIG_SYSTEM_TRUSTED_KEYS=\u0026#34;\u0026#34; This will be enough for the kernel to detect that secure boot is enabled and let you experiment with things. You can even issue your own pesign command\n1$ pesign -c \u0026#39;Red Hat Test Certificate\u0026#39; --certdir /etc/pki/pesign-rh-test -i arch/x86/boot/bzImage -o vmlinuz.signed -s ","link":"https://arvimal.github.io/docs/linux-booting/01-uefi-efi/secure-boot-with-qemu-and-uefi/","section":"docs","tags":null,"title":""},{"body":"The rEFInd Boot Manager: Managing Secure Boot http://www.rodsbooks.com/refind/secureboot.html\nThis Web page is provided free of charge and with no annoying outside ads; however, I did take time to prepare it, and Web hosting does cost money. If you find this Web page useful, please consider making a small donation to help keep this site up and running. Thanks!\nThis page is part of the documentation for the rEFInd boot manager. If a Web search has brought you here, you may want to start at the main page.\nNote: My Managing EFI Boot Loaders for Linux Web page includes a much more detailed description of Secure Boot in two of its subpages. Consult Dealing with Secure Boot for more information on disabling Secure Boot, using Shim, and using PreLoader; and read Controlling Secure Boot for more information on using your own keys instead of or in addition to those that came with your computer.\nNote: Macs don't (yet?) support Secure Boot, but as of version 10.11 (\u0026quot;El Capitan\u0026quot;), OS X uses its own new security feature, System Integrity Protection (SIP), which creates its own set of hoops through which rEFInd users must jump. See the rEFInd and System Integrity Protection page for details.\nIf you're using a computer that supports Secure Boot, you may run into extra complications. This feature is intended to make it difficult for malware to insert itself early into the computer's boot process. Unfortunately, it also complicates multi-boot configurations such as those that rEFInd is intended to manage. This page describes some Secure Boot basics and two specific ways of using rEFInd with Secure Boot: Using the Shim program and using the PreLoader program. (My separate EFI Boot Loaders for Linux page on Secure Boot covers the additional topics of disabling Secure Boot and adding keys to the firmware's own set of keys.) This page concludes with a look at known bugs and limitations in rEFInd's Secure Boot features.\nBasic Issues Note: You don't have to use Secure Boot. If you don't want it, you can disable it, at least on x86-64 PCs. If an ARM-based computer ships with Windows 8, this isn't an option for it. Unfortunately, the Shim and PreLoader programs described on this page currently support only x86-64, not x86 or ARM.\nThrough 2012, it became obvious that Secure Boot would be a feature that was controlled, to a large extent, by Microsoft. This is because Microsoft requires that non-server computers that display Windows 8 logos ship with Secure Boot enabled. As a practical matter, this also means that such computers ship with Microsoft's keys in their firmware. In the absence of an industry-standard body to manage the signing of Secure Boot keys, this means that Microsoft's key is the only one that's more-or-less guaranteed to be installed on the computer, thus blocking the ability to boot any OS that lacks a boot path through Microsoft's signing key.\nFortunately, Microsoft will sign third-party binaries with their key—or more precisely, with a key that Microsoft uses to sign third-party binaries. (Microsoft uses another key to sign its own binaries, and some devices, such as the Microsoft Surface tablet, lack the third-party Microsoft key.) A payment of $99 to Verisign enables a software distributor to sign as many binaries as desired. Red Hat (Fedora), Novell (SUSE), and Canonical (Ubuntu) are all using this system to enable their boot loaders to run. Unfortunately, using a third-party signing service is an awkward solution for open source software. In fact, for this very reason two separate programs exist that shift the Secure Boot \u0026quot;train\u0026quot; from Microsoft's proprietary \u0026quot;track\u0026quot; to one that's more friendly to open source authors. Both of these programs (Shim and PreLoader) are available in binary form signed by Microsoft's key. Shim enables the computer to launch binaries that are signed by a key that's built into it or that the user adds to a list known as the Machine Owner Key (MOK) list. PreLoader enables the computer to launch binaries that the user has explicitly identified as being OK. Distributions beginning with Ubuntu 12.10 (and 12.04.2), Fedora 18, and OpenSUSE 12.3 use Shim, although the Ubuntu initially shipped with an early version of Shim that's useless for launching rEFInd. (Current versions of Ubuntu ship with more flexible versions of Shim.) PreLoader is used by some smaller and more specialized distributions, such as Arch Linux. You can switch from one to the other if you like, no matter what your distribution uses by default.\nThere are three ways to sign a binary that will get it launched on a computer that uses Shim:\nSecure Boot keys—These keys are managed by the EFI firmware. In a default configuration, Microsoft is the only party that's more-or-less guaranteed to be able to sign boot loaders with these keys; however, it's possible to replace Microsoft's keys with your own, in order to take full control of Secure Boot on your computer. The trouble is that this process is tedious and varies in details from one computer to another. It's worth noting that many, but not all, computers ship with Canonical's key, which can help slightly when booting Ubuntu; if your computer is so equipped, you can use any Shim you like and not worry about adding Canonical's key to your MOK list, although you must still add a MOK key for rEFInd itself. Shim's built-in keys—It's possible, but not necessary, to compile Shim with a built-in public key. Its private counterpart can then be used to sign binaries. In practice, this key type is limited in utility; it's likely to be used by distribution maintainers to sign their own version of GRUB and the Linux kernels that it launches, nothing more. On the plus side, Shim's keys require little or no maintenance by users. One potential complication is that if you swap out one Shim binary for another, its built-in key may change, which means that the replacement Shim might no longer launch its follow-on boot loader or kernels linked to the first Shim. MOKs—Versions 0.2 and later of Shim support MOKs, which give you the ability to add your own keys to the computer. If you want to install multiple Linux distributions in Secure Boot mode, MOKs are likely to be helpful. They're vital if you want to launch kernels you compile yourself or use boot managers or boot loaders other than those provided by your distribution. All three key types are the same in form—Shim's built-in keys and MOKs are both generated using the same tools used to generate Secure Boot keys. The keys can be generated with the common openssl program, but signing EFI binaries requires either of two rarer programs: sbsign or pesign. If you use Shim with a distribution that doesn't support Secure Boot, you'll need to either sign the kernels yourself, which can be a hassle, or launch the kernels by way of a boot loader that doesn't check for signatures, such as ELILO.\nShim's author is working on merging it and PreLoader. Thus, future versions of Shim may provide the advantages of both programs.\nPreLoader is easier to set up on a distribution that doesn't support Shim because PreLoader doesn't rely on keys; instead, you tell it which binaries you trust and it will let you launch them. This works well on a system with boot managers, boot loaders, and kernels that seldom change. It's not a good solution for distribution maintainers, though, because it requires that users manually add binaries to PreLoader's list of approved binaries when the OS is installed and every time those binaries change. Also, PreLoader relies on a helper program, HashTool, to enroll hashes. (This is Geek for \u0026quot;tell the computer that a binary is OK.\u0026quot;) Unfortunately, the initial (and, as far as I know, only signed) HashTool can enroll hashes only from the partition from which it was launched, so if you want to use rEFInd to launch Linux kernels directly, it's easiest if you mount your EFI System Partition (ESP) at /boot in Linux or copy your kernels to the ESP. Another approach is to copy HashTool.efi to the partition that holds your kernel and rename it to almost anything else. rEFInd will then treat it like an OS boot loader and create a menu entry for it, enabling you to launch it as needed.\nBeginning with version 0.5.0, rEFInd can communicate with the Shim system to authenticate boot loaders. If a boot loader has been signed by a valid UEFI Secure Boot key, a valid Shim key, or a valid MOK, rEFInd will launch it. rEFInd will also launch unsigned boot loaders or those with invalid signatures if Secure Boot is disabled in or unsupported by the firmware. (If that's your situation, you needn't bother reading this page.) PreLoader is designed in such a way that it requires no explicit support in rEFInd to work.\nMy binary builds of rEFInd version 0.5.0 and later ship signed with my own keys, and I provide the public version of this key with the rEFInd package. This can help simplify setup, since you needn't generate your own keys to get rEFInd working. The rEFInd PPA for Ubuntu ships unsigned binaries, but the installation script that runs automatically when the package is installed signs the binaries with a local key as it installs them. In either case, if you lack public keys for the boot loaders that rEFInd launches, you'll need to sign your boot loaders, as described in the Managing Your MOKs section.\nUsing rEFInd with Shim Because several major distributions support Shim, I describe it first. You may need to adjust the rEFInd installation process to get it working with Shim, especially if you're not using a distribution that uses this software. In addition to installing Shim, you should know how to manage your MOKs, so I describe this topic, too. If you don't want to use Shim, you can skip ahead to the section on PreLoader.\nInstalling Shim and rEFInd Note: rEFInd's refind-install script attempts to identify whether your computer was booted with Secure Boot active and, if it was, to locate existing Shim binaries and make use of whatever it finds. Thus, you may not need to explicitly set up Shim after you install rEFInd, although you will probably have to enroll rEFInd's key in your MOK list, as described shortly.\nA working Secure Boot installation of rEFInd involves at least three programs, and probably four or more, each of which must be installed in a specific way:\nShim—You can use any version of Shim you like. In many cases, one will already be installed on your computer from your distribution, called shim.efi or shimx64.efi in the distribution's directory on the ESP. If so, it's probably best to use that version, since its built-in key will handle your distribution's kernels. If you don't currently have a Shim installed, you can copy one from another computer, copy the file from a distribution installation disc, or download a version of Shim 0.2 (old, but still usable) signed with Microsoft's Secure Boot key here. This version (created by Shim's developer, former Red Hat employee Matthew J. Garrett) includes a Shim key that's used by nothing but the MokManager.efi program that also ships with the program. No matter what version of Shim you use, you must enroll rEFInd's MOK. Ubuntu 12.10 and 13.04 ship with an earlier version of Shim (0.1) that doesn't support MOKs; avoid Shim 0.1 for use with rEFInd. You should install Shim just as you would install other EFI boot loaders, as described here. For use in launching rEFInd, it makes sense to install shim.efi in EFI/refind on your ESP, although of course this detail is up to you. MokManager—This program is included with Shim 0.2 and later. It presents a user interface for managing MOKs, and it's launched by Shim if Shim can't find its default boot loader (generally grubx64.efi) or if that program isn't properly signed. In principle, this program could be signed with a Secure Boot key or a MOK, but such binaries are usually signed by Shim keys. This program should reside in the same directory as shim.efi, under the name MokManager.efi. Although you could theoretically do without MokManager, in practice you'll need it at least temporarily to install the MOK with which rEFInd is signed. rEFInd—Naturally, you need rEFInd. Because Shim is hard-coded to launch a program called grubx64.efi, you must install rEFInd using that name and to the same directory in which shim.efi resides. In theory, rEFInd could be signed with a Secure Boot key, a Shim key, or a MOK; however, because Microsoft won't sign binaries distributed under the GPLv3, I can't distribute a version of rEFInd signed with Microsoft's Secure Boot key; and as I don't have access to the private Shim keys used by any distribution, I can't distribute a rEFInd binary signed by them. (If distributions begin including rEFInd in their package sets, though, such distribution-provided binaries could be signed with the distributions' Shim keys.) Thus, rEFInd will normally be signed by a MOK. Beginning with version 0.5.0, rEFInd binaries that I provide are signed by me. Beginning with version 0.5.1, the installation script provides an option to sign the rEFInd binary with your own key, provided the necessary support software is installed. Your boot loaders and kernels—Your OS boot loaders, and perhaps your Linux kernels, must be signed. They can be signed with any of the three key types. Indeed, your system may have a mix of all three types—a Windows 8 boot loader will most likely be signed with Microsoft's Secure Boot key, GRUB and kernels provided by most distributions will be signed with their own Shim keys, and if you use your own locally-compiled kernel or a boot loader from an unusual source you may need to sign it with a MOK. Aside from signing, these files can be installed in exactly the same way as if your computer were not using Secure Boot. If you've installed a distribution that provides Shim and can boot it with Secure Boot active, and if you then install rEFInd using the RPM file that I provide or by running refind-install, chances are you'll end up with a working rEFInd that will start up the first time, with one caveat: You'll have to use MokManager to add rEFInd's MOK to your MOK list, as described shortly. If you don't already have a working copy of Shim on your ESP, your task is more complex. Broadly speaking, the procedure should be something like this:\nBoot the computer. This can be a challenge in and of itself. You may need to use a Secure Boot–enabled Linux emergency disc, temporarily disable Secure Boot, or do the work from Windows. Download rEFInd in binary form (the binary zip or CD-R image file). If you download the binary zip file, unzip it; if you get the CD-R image file, burn it to a CD-R and mount it. Download Shim from Matthew J. Garrett's download site or from your distribution. (Don't use an early 0.1 version, though; as noted earlier, it's inadequate for use with rEFInd.) Tip: If you're running Linux, you can save some effort by using the refind-install script with its --shim /path/to/shim.efi option rather than installing manually, as in steps 4–6 of this procedure. If you've installed openssl and sbsign, using --localkeys will generate local signing keys and re-sign the rEFInd binaries with your own key, too. You can then use sbsign and the keys in /etc/refind.d/keys to sign your kernels or boot loaders.\nCopy the shim.efi and MokManager.efi binaries to the directory you intend to use for rEFInd—for instance, EFI/refind on the ESP.\nFollow the installation instructions for rEFInd on the Installing rEFInd page; however, you should normally give rEFInd the filename grubx64.efi and register shim.efi with the EFI by using efibootmgr in Linux or bcdedit in Windows. Be sure that rEFInd (as grubx64.efi), shim.efi, and MokManager.efi all reside in the same directory. If you're using Shim 0.7 or later and installing it under Linux, you may optionally keep rEFInd's refind_x64.efi name; but you must then tell Shim to use rEFInd by passing an additional -u \u0026quot;shim.efi refind_x64.efi\u0026quot; option to efibootmgr. Change the filenames to the actual filenames used by Shim and rEFInd, respectively.\nCopy the refind.cer file from the rEFInd package to your ESP, ideally to a location with few other files. (The rEFInd installation directory should work fine.)\nReboot. With any luck, you'll see a simple text-mode user interface with a label of Shim UEFI key management. This is the MokManager program, which Shim launched when rEFInd failed verification because its key is not yet enrolled.\nPress your down arrow key and press Enter to select Enroll key from disk. The screen will clear and prompt you to select a key, as shown here: This user interface was used in early versions of MokManager, but somewhere between versions 0.4 and 0.7, the user interface received an upgrade. If you've got a more recent version, it will look more like this:\n![[/MokManager1.png]]\n![[/MokManager2.png]]\nEach of the lines with a long awkward string represents a disk partition. Select one and you'll see a list of files. Continue selecting subdirectories until you find the refind.cer file you copied to the ESP earlier. (Note that in the early user interface the long lines can wrap and hide valid entries on the next line, so you may need to select a disk whose entry is masked by another one!)\nSelect refind.cer. You can type 1 to view the certificate's details if you like, or skip that and type 0 to enroll the key.\nBack out of any directories you entered and return to the MokManager main menu.\nSelect Continue boot at the main menu.\nAt this point the computer may boot into its default OS, reboot, or perhaps even hang. When you reboot it, though, rEFInd should start up in Secure Boot mode. (You can verify this by selecting the About rEFInd tool in the main menu. Check the Platform item in the resulting screen; it should verify that Secure Boot is active.) You should now be able to launch any boot loader signed with a key recognized by the firmware or by Shim (including any MOKs you've enrolled). If you want to manage keys in the future, rEFInd displays a new icon in the second (tools) row you can use to launch MokManager. (This icon appears by default if MokManager is installed, but if you edit showtools in refind.conf, you must be sure to include mok_tool as an option in order to gain access to it.)\nIf you're using rEFInd to boot multiple Linux versions, chances are you'll need to add the keys for the distributions whose Shim you're not using as MOKs. rEFInd ships with a selection of such keys and copies them to the keys subdirectory of the rEFInd installation directory on the ESP as a convenience. Note that you must enroll keys with .cer or .der filename extensions. Although .crt files contain the same information, their format is different and they cannot be used by MokManager.\nManaging Your MOKs The preceding instructions provided the basics of getting rEFInd up and running, including using MokManager to enroll a MOK on your computer. If you need to sign binaries, though, you'll have to use additional tools. The OpenSSL package provides the cryptographic tools necessary, but actually signing EFI binaries requires additional software. Two packages for this are available: sbsigntool and pesign. Both are available in binary form from this OpenSUSE Build Service (OBS) repository, and many distributions ship with at least one of them. The following procedure uses sbsigntool. To sign your own binaries, follow these steps (you can skip the first five steps if you've successfully used refind-install's --localkeys option):\nIf it's not already installed, install OpenSSL on your computer. (It normally comes in a package called openssl.)\nIf you did re-sign your rEFInd binaries with refind-install's --localkeys option, type the following two commands to generate your public and private keys: Change Your Name to your own name or other identifying characteristics, and adjust the certificate's time span (set via -days) as you see fit. If you omit the -nodes option, the program will prompt you for a passphrase for added security. Remember this, since you'll need it to sign your binaries. The result is a private key file (refind_local.key), which is highly sensitive since it's required to sign binaries, and two public keys (refind_local.crt and refind_local.cer), which can be used to verify signed binaries' authenticity. The two public key files are equivalent, but are used by different tools—sbsigntool uses refind_local.crt to sign binaries, but MokManager uses refind_local.cer to enroll the key. If you used refind-install's --localkeys option, this step is unnecessary, since these keys have already been created and are stored in /etc/refind.d/keys/.\nnot\n1$ openssl req -new -x509 -newkey rsa:2048 -keyout refind_local.key \\ 2 -out refind_local.crt -nodes -days 3650 -subj \u0026#34;/CN=Your Name/\u0026#34; 3$ openssl x509 -in refind_local.crt -out refind_local.cer -outform DER Copy the three key files to a secure location and adjust permissions such that only you can read refind_local.key. You'll need these keys to sign future binaries, so don't discard them.\nCopy the refind_local.cer file to your ESP, ideally to a location with few other files. (MokManager's user interface becomes unreliable when browsing directories with lots of files.)\nDownload and install the sbsigntool package. Binary links for various distributions are available from the OpenSUSE Build Service, or you can obtain the source code by typing git clone git://kernel.ubuntu.com/jk/sbsigntool.\nSign your binary by typing sbsign --key refind_local.key --cert refind_local.crt --output binary-signed.efi binary.efi, adjusting the paths to the keys and the binary names.\nCopy your signed binary to a suitable location on the ESP for rEFInd to locate it. Be sure to include any support files that it needs, too.\nCheck your refind.conf file to ensure that the showtools option is either commented out or includes mok_tool among its options.\nReboot. You can try launching the boot loader you just installed, but chances are it will generate an Access Denied message. For it to work, you must launch MokManager using the tool that rEFInd presents on its second row. You can then enroll your refind_local.cer key just as you enrolled the refind.cer key.\nAt this point you should be able to launch the binaries you've signed. Unfortunately, there can still be problems; see the upcoming section, Secure Boot Caveats, for information on them. Alternatively, you can try using PreLoader rather than Shim.\nUsing rEFInd with PreLoader If you want to use Secure Boot with a distribution that doesn't come with Shim but the preceding description exhausts you, take heart: PreLoader is easier to set up and use for your situation! Unfortunately, it's still not as easy to use as not using Secure Boot at all, and it's got some drawbacks, but it may represent an acceptable middle ground. To get started, proceed as follows:\nBoot the computer. As with Shim, this can be a challenge; you may need to boot with Secure Boot disabled, use a Secure Boot–enabled live CD, or do the installation from Windows. Download rEFInd in binary form (the binary zip or CD-R image file). If you download the binary zip file, unzip it; if you get the CD-R image file, burn it to a CD-R and mount it. Download PreLoader from its release page or by clicking the following links. Be sure to get both the PreLoader.efi and HashTool.efi files. Copy the PreLoader.efi and HashTool.efi binaries to the directory you intend to use for rEFInd—for instance, EFI/refind on the ESP. Follow the installation instructions for rEFInd on the Installing rEFInd page; however, give rEFInd the filename loader.efi and register PreLoader.efi with the EFI by using efibootmgr in Linux or bcdedit in Windows. Be sure that rEFInd (as loader.efi), PreLoader.efi, and HashTool.efi all reside in the same directory. Reboot. With any luck, you'll see HashTool appear with a warning message stating that it was unable to launch loader.efi and declaring that it will launch HashTool.efi. Press the Enter key to continue. HashTool should now appear. It should give you three or four options, including Enroll Hash, as shown here. Select this option ![[/HashTool1.png]]\nYou can now select the binary you want to authorize. You should first select loader.efi, since that's rEFInd. The program presents the hash (a very long number) and asks for confirmation. Be sure to select Yes. ![[/HashTool2.png]]\nNote: Unfortunately, the initial version of HashTool's file selector can't change filesystems. Thus, if you want to boot a Linux kernel using rEFInd and PreLoader, you'll need to copy the kernel to the ESP, at least temporarily. Alternatively, as noted earlier, you can copy HashTool.efi to the directory that holds the kernels or to another directory on that partition that rEFInd scans—but be sure to rename HashTool.efi or rEFInd will ignore it. You'll then see a boot loader entry for HashTool. More recent versions of HashTool can access multiple partitions, but I have yet to find a pre-signed version, so if you want to use it, you'll need to compile it yourself and then register its hash with an earlier version (or with Secure Boot temporarily disabled).\nRepeat the preceding two steps for any additional binaries you might want to enroll. These include any EFI filesystem drivers you're using, any boot loaders you're launching from rEFInd (other than those that are already signed, such as Microsoft's boot loader), and possibly your Linux kernel. At the HashTool main menu, select Exit. rEFInd should launch. If you did everything right, rEFInd should now launch follow-on boot loaders and kernels, including both programs signed with the platform's Secure Boot keys and binaries that you've authorized with HashTool. If you need to authorize additional programs, you can do so from rEFInd by using the MOK utility tool icon that launches HashTool.efi from the second row of icons. (This icon should appear by default, but if you uncomment the showtools token in refind.conf, be sure that mok_tool is present among the options.)\nAlthough PreLoader is easier to set up than Shim, particularly if you need to launch programs or kernels that aren't already signed, it suffers from the problem that you must register every new program you install, including Linux kernels if you launch them directly from rEFInd. This need can be a hassle if you update your kernels frequently, and every new registration chews up a little space in your NVRAM. Nonetheless, PreLoader can be a good Secure Boot solution for many users or if you want to build a portable Linux installation that you can use on any computer with minimal fuss.\nSecure Boot Caveats rEFInd's Secure Boot originated with version 0.5.0 of the program, and was revamped for version 0.6.2, both released in late 2012. It's worked well for myself and several others with whom I've corresponded; but you might still run into problems. Some issues you might encounter include the following:\nrEFInd uses the same EFI \u0026quot;hooks\u0026quot; as PreLoader. This method, however, is part of an optional EFI subsystem, so in theory some EFIs might not support it. For months, I knew of no such implementation, but this SuperUser question indicates that at least one such implementation exists. Subsequent discussions on the site imply that the computer doesn't support Secure Boot at all. The bottom line: If you encounter the error message Failed to install override security policy, try removing PreLoader from your boot path.\nUnder certain circumstances, the time required to launch a boot loader can increase. This is unlikely to be noticeable for the average small boot loader, but could be significant for larger boot loaders on slow filesystems, such as Linux kernels on ext2fs, ext3fs, or ReiserFS partitions.\nrEFInd's own Secure Boot support is theoretically able to work on non-86-64 platforms; however, to the best of my knowledge, Shim and PreLoader both work only on 86-64, and rEFInd is dependent upon these tools. In principle, you should be able to replace your computer's standard Secure Boot keys to use Secure Boot on these platforms with rEFInd, but this approach will require either built-in key-modification tools in the computer's setup utility or a build of LockDown.efi for your platform. I've not tested this approach on 86 or ARM, so I can't say whether it would actually work.\nx\nx\nx\nIn theory, signing Microsoft's boot loader with a MOK should work. This might be handy if you want to replace your computer's built-in keys with your own but still boot Windows—but be aware that if Windows replaces its boot loader, it will then stop working.\nIf you launch a boot loader or other program from rEFInd that relies on the EFI's standard program-launching code, that program should take advantage of Shim and its MOKs. For instance, if you launch gummiboot from rEFInd (and rEFInd from Shim), gummiboot should be able to launch Shim/MOK-signed Linux kernels. This is not currently true if you launch gummiboot directly from Shim. (You can launch gummiboot from PreLoader and it should work, though, because of technical differences between how Shim and PreLoader work.)\nMy focus in testing rEFInd's Secure Boot capabilities has been on getting Linux kernels with EFI stub loaders to launch correctly. I've done some minimal testing with GRUB 2, though. I've also tested some self-signed binaries, such as an EFI shell and MokManager. (The EFI shell launches, but will not itself launch anything that's not been signed with a UEFI Secure Boot key. This of course limits its utility.)\nSome of the awkwardness of using rEFInd with Secure Boot is due to the need to manage MOKs (either keys with Shim or hashes with PreLoader). Such problems would evaporate if you could get a copy of rEFInd signed with your distribution's Secure Boot key. Thus, if you're annoyed by such problems, try filing a feature request with your distribution maintainer to have them include rEFInd (and sign it!) with their official package set.\ncopyright © 2012–2018 by Roderick W. Smith\nThis document is licensed under the terms of the GNU Free Documentation License (FDL), version 1.3.\nIf you have problems with or comments about this Web page, please e-mail me at [[rodsmith@rodsbooks.com.]] Thanks.\nReturn to my main Web page.\n","link":"https://arvimal.github.io/docs/linux-booting/01-uefi-efi/the-refind-boot-manager-managing-secure-boot/","section":"docs","tags":null,"title":""},{"body":"You’ve probably read a lot of stuff on the internet about UEFI. Here is something important you should understand: 95% of it was probably garbage. If you think you know about UEFI, and you derived your knowledge anywhere other than the UEFI specifications, [[http://mjg59.dreamwidth.org/|mjg59′s blog]] or one of a few other vaguely reliable locations/people – [[http://www.rodsbooks.com/linux-uefi/|Rod Smith]], or [[http://blog.uncooperative.org/|Peter Jones]], or Chris Murphy, or the documentation of the relatively few OSes whose developers actually know what the hell they’re doing with UEFI – what you think you know is likely a toxic mix of misunderstandings, misconceptions, half-truths, propaganda and downright lies. So you should probably forget it all.\nGood, now we’ve got that out of the way. What I mostly want to talk about is bootloading, because that’s the bit of firmware that matters most to most people, and the bit news sites are always banging on about and wildly misunderstanding.\n===== Terminology =====\nFirst, let’s get some terminology out of the way. Both [[https://en.wikipedia.org/wiki/BIOS|BIOS]] and [[https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface|UEFI]] are types of [[http://en.wikipedia.org/wiki/Firmware|firmware]] for computers. BIOS-style firmware is (mostly) only ever found on [[https://en.wikipedia.org/wiki/IBM_PC_compatible|IBM PC compatible computers]]. UEFI is meant to be more generic, and can be found on systems which are not in the ‘IBM PC compatible’ class.\nYou do not have a ‘UEFI BIOS’. No-one has a ‘UEFI BIOS’. Please don’t ever say ‘UEFI BIOS’. BIOS is not a generic term for all PC firmware, it is a particular type of PC firmware. Your computer has a firmware. If it’s an IBM PC compatible computer, it’s almost certainly either a BIOS or a UEFI firmware. If you’re running [[http://www.coreboot.org/|Coreboot]], congratulations, Mr./Ms. Exception. You may be proud of yourself.\n[[https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface#Secure_boot|Secure Boot]] is not the same thing as UEFI. Do not ever use those terms interchangeably. Secure Boot is a single effectively optional element of the UEFI specification, which was added in version 2.2 of the UEFI specification. We will talk about precisely what it is later, but for now, just remember it is not the same thing about UEFI. You need to understand what Secure Boot is, and what UEFI is, and which of the two you are actually talking about at any given time. We’ll talk about UEFI first, and then we’ll talk about Secure Boot as an ‘extension’ to UEFI, because that’s basically what it is.\n//Bonus Historical Note//: UEFI was not invented by, is not controlled by, and has never been controlled by Microsoft. Its predecessor and basis, EFI, was developed and published by Intel. UEFI is managed by the [[http://uefi.org/|UEFI Forum]]. Microsoft is a member of the UEFI forum. So is Red Hat, and so is Apple, and so is just about every major PC manufacturer, Intel (obviously), AMD, and a [[http://uefi.org/members|laundry list of other major and minor hardware, software and firmware companies and organizations]]. It is a broad consensus specification, with all the messiness that entails, some of which we’ll talk about specifically later. It is no one company’s Evil Vehicle Of Evilness.\n===== References =====\nIf you really want to understand UEFI, it’s a really good idea to go and read the UEFI specification. You can do this. It’s very easy. You don’t have to pay anyone any money. I am not going to tell you that reading it will be the most fun you’ve ever had, because it won’t. But it won’t be a waste of your time. You can find it [[http://www.uefi.org/specs/download|right here on the official UEFI site]]. You have to check a couple of boxes, but you are not signing your soul away to Satan, or anything. It’s fine. As I write this, the current version of the spec is [[http://www.uefi.org/sites/default/files/resources/2_4_Errata_A.pdf|2.4 Errata A]], and that’s the version this post is written with regard to.\nThere is no BIOS specification. BIOS is a //de facto// standard – it works the way it worked on actual IBM PCs, in the 1980s. That’s kind of one of the reasons UEFI exists.\nNow, to keep things simple, let’s consider two worlds. One is the world of IBM PC compatible computers – hereafter referred to just as PCs – before UEFI and GPT (we’ll come to GPT) existed. This is the world a lot of you are probably familiar with and may understand quite well. Let’s talk about how booting works on PCs with BIOS firmware.\n===== BIOS booting =====\nIt works, in fact, in a very, very simple way. On your bog-standard old-skool BIOS PC, you have one or more disks which have an [[https://en.wikipedia.org/wiki/Master_boot_record|MBR]]. The MBR is another de facto standard; basically, the very start of the disk describes the partitions on the disk in a particular format, and contains a ‘boot loader’, a very small piece of code that a BIOS firmware knows how to execute, whose job it is to boot the operating system(s). (Modern bootloaders frequently are much bigger than can be contained in the MBR space and have to use a multi-stage design where the bit in the MBR just knows how to load the next stage from somewhere else, but that’s not important to us right now).\nAll a BIOS firmware knows, in the context of booting the system, is what disks the system contains. You, the owner of this BIOS-based computer, can tell the BIOS firmware which disk you want it to boot the system from. The firmware has no knowledge of anything beyond that. It executes the bootloader it finds in the MBR of the specified disk, and that’s it. The firmware is no longer involved in booting.\nIn the BIOS world, absolutely all forms of multi-booting are handled above the firmware layer. The firmware layer doesn’t really know what a bootloader is, or what an operating system is. Hell, it doesn’t know what a partition is. All it can do is run the boot loader from a disk’s MBR. You also cannot configure the boot process from outside of the firmware.\n===== UEFI booting: background =====\nOK, so we have our background, the BIOS world. Now let’s look at how booting works on a UEFI system. Even if you don’t grasp the details of this post, grasp this: //it is completely different//. Completely and utterly different from how BIOS booting works. You cannot apply any of your understanding of BIOS booting to native UEFI booting. You cannot make a little tweak to a system designed for the world of BIOS booting and apply it to //native// UEFI booting. You need to understand that it is a completely different world.\nHere’s another important thing to understand: many UEFI firmwares implement some kind of //BIOS compatibility mode//, sometimes referred to as a //CSM//. Many UEFI firmwares can boot a system just like a BIOS firmware would – they can look for an MBR on a disk, and execute the boot loader from that MBR, and leave everything subsequently up to that bootloader. People sometimes //incorrectly// refer to using this feature as ‘disabling UEFI’, which is //linguistically// nonsensical. You cannot ‘disable’ your system’s firmware. It’s just a stupid term. Don’t use it, but understand what people really mean when they say it. They are talking about using a UEFI firmware’s ability to boot the system ‘BIOS-style’ rather than native UEFI style.\nWhat I’m going to describe is //native// UEFI booting. If you have a UEFI-based system whose firmware has the BIOS compatibility feature, and you decide to use it, and you apply this decision consistently, then as far as booting is concerned, you can pretend your system is BIOS-based, and just do everything the way you did with BIOS-style booting. If you’re going to do this, though, just make sure you //do// apply it consistently. I really can’t recommend strongly enough that you do //not// attempt to mix UEFI-native and BIOS-compatible booting of permanently-installed operating systems on the same computer, and //especially// not on the same disk. It is a terrible terrible idea and will cause you heartache and pain. If you decide to do it, don’t come crying to me.\nFor the sake of sanity, I am going to assume the use of disks with a [[https://en.wikipedia.org/wiki/GUID_Partition_Table|GPT]] partition table, and EFI FAT32 [[https://en.wikipedia.org/wiki/EFI_System_partition|EFI system partitions]]. Depending on how deep you’re going to dive into this stuff you //may// find out that it’s not strictly speaking the case that you can //always// assume you’ll be dealing with GPT disks and EFI FAT32 ESPs when dealing with UEFI native boot, but the UEFI specification is quite strongly tied to GPT disks and EFI FAT32 ESPs, and this is what you’ll be dealing with in 99% of cases. Unless you’re dealing with Macs, and quite frankly, //screw// Macs.\nEdit note: the following sections (up to //Implications and Complications//) were heavily revised on 2014-01-26, a few hours after the initial version of this post went up, based on feedback from Peter Jones. Consider this to be v2.0 of the post. An earlier version was written in a somewhat less accurate and more confusing way.\n===== UEFI native booting: how it actually works – background =====\nOK, with that out of the way, let’s get to the meat. This is how native UEFI booting actually works. It’s probably helpful to go into this with a bit of high-level background.\nUEFI provides //much// more infrastructure at the firmware level for handling system boot. It’s nowhere near as simple as BIOS. Unlike BIOS, UEFI certainly does understand, to varying degrees, the concepts of ‘disk partitions’ and ‘bootloaders’ and ‘operating systems’.\nYou can sort of look at the BIOS boot process, and look at the UEFI process, and see how the UEFI process extends various bits to address specific problems.\nThe BIOS/MBR approach to finding the bootloader is pretty janky, when you think about it. It’s very ‘special sauce’: this particular tiny space at the front of the disk contains magic code that only really makes much sense to the system firmware and special utilities for writing it. There are several problems with this approach.\nIt’s inconvenient to deal with – you need special utilities to write the MBR, and just about the only way to find out what’s in one is to dd the contents out and examine them. As noted above, the MBR itself is not big enough for many modern bootloaders. What they do is install a small part of themselves to the MBR proper, and the rest to the empty space on the disk between where the conventional MBR ends and the first partition begins. There’s a rather big problem with this (well, the whole design is a big problem, but never mind), which is that there’s no reliable convention for where the first partition should begin, so it’s difficult to be sure there’ll be enough space. One thing you usually can rely on is that there won’t be //enough// space for some bootloader configurations. The design doesn’t provide any standardized layer or mechanism for selecting boot targets other than disks…but people //want// to select boot targets other than disks. i.e. they want to have multiple bootable ‘things’ – usually operating systems – per disk. The only way to do this, in the BIOS/MBR world, is for the bootloaders to handle it; but there’s no widely accepted convention for the right way to do this. There are many many different approaches, none of which is particularly interoperable with any of the others, none of which is a widely accepted standard or convention, and it’s very difficult to write tooling at the OS / OS installation layer that handles multiboot cleanly. It’s just a very messy design. The design doesn’t provide a standard way of booting from anything //except// disks. We’re not going to really talk about that in this article, but just be aware it’s another advantage of UEFI booting: it provides a standard way for booting from, for instance, a remote server. There’s no mechanism for levels above the firmware to configure the firmware’s boot behaviour. So you can imagine the UEFI Elves sitting around and considering this problem, and coming up with a solution. Instead of the firmware only knowing about disks and one ‘magic’ location per disk where bootloader code might reside, UEFI has much more infrastructure at the firmware layer for handling boot loading. Let’s look at all the things it defines that are relevant here.\n===== EFI executables =====\nThe UEFI spec defines an executable format and requires all UEFI firmwares be capable of executing code in this format. When you write a bootloader for native UEFI, you write in this format. This is pretty simple and straightforward, and doesn’t need any further explanation: it’s just a Good Thing that we now have a firmware specification which actually defines a common format for code the firmware can execute.\n===== The GPT (GUID partition table) format =====\nThe [[https://en.wikipedia.org/wiki/GUID_Partition_Table|GUID Partition Table]] format is very much tied in with the UEFI specification, and again, this isn’t something particularly complex or in need of much explanation, it’s just a good bit of groundwork the spec provides. GPT is just a standard for doing partition tables – the information at the start of a disk that defines what partitions that disk contains. It’s a better standard for doing this than MBR/’MS-DOS’ partition tables were in many ways, and the UEFI spec requires that UEFI-compliant firmwares be capable of interpreting GPT (it also requires them to be capable of interpreting MBR, for backwards compatibility). All of this is useful groundwork: what’s going on here is the spec is establishing certain capabilities that everything above the firmware layer can rely on the firmware to have.\n===== EFI system partitions =====\nI actually really wrapped my head around the EFI system partition concept while revising this post, and it was a great ‘aha!’ moment. Really, the concept of ‘EFI system partitions’ is just an answer to the problem of the ‘special sauce’ MBR space. The concept of some undefined amount of empty space at the start of a disk being ‘where bootloader code lives’ is a pretty crappy design, as we saw above. EFI system partitions are just UEFI’s solution to that.[[https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/#fn:2|1]]\nThe solution is this: we require the firmware layer to be capable of reading some specific types of filesystem. The UEFI spec requires that compliant firmwares be capable of reading the FAT12, FAT16 and FAT32 variants of the [[https://en.wikipedia.org/wiki/File_Allocation_Table|FAT]] format, in essence. In fact what it does is codify a particular interpretation of those formats as they existed at the point UEFI was accepted, and say that UEFI compliant firmwares must be capable of reading those formats. As the spec puts it:\n“The file system supported by the Extensible Firmware Interface is based on the FAT file system. EFI defines a specific version of FAT that is explicitly documented and testable. Conformance to the EFI specification and its associate reference documents is the only definition of FAT that needs to be implemented to support EFI. To differentiate the EFI file system from pure FAT, a new partition file system type has been defined.”\nAn ‘EFI system partition’ is really just any partition formatted with one of the UEFI spec-defined variants of FAT and given a specific GPT partition type to help the firmware find it. And the purpose of this is just as described above: allow everyone to rely on the fact that the firmware layer will definitely be able to read data from a pretty ‘normal’ disk partition. Hopefully it’s clear why this is a better design: instead of having to write bootloader code to the ‘magic’ space at the start of an MBR disk, operating systems and so on can just create, format and mount partitions in a widely understood format and put bootloader code and anything else that they might want the firmware to read there.\nThe whole ESP thing seemed a bit bizarre and confusing to me at first, so I hope this section explains why it’s actually a very sensible idea and a good design – the bizarre and confusing thing is really the BIOS/MBR design, where the only way for you to write something from the OS layer that you knew the firmware layer could consume was to write it into some (but you didn’t know how much) Magic Space at the start of a disk, a convention which isn’t actually codified anywhere. That really //isn’t// a very sensible or understandable design, if you step back and take a look at it.\nAs we’ll note later, the UEFI spec tends to take a ‘you must at least do these things’ approach – it rarely prohibits firmwares from doing anything else. It’s not against the spec to write a firmware that can execute code in other formats, read other types of partition table, and read partitions formatted with filesystems other than the UEFI variants of FAT. But a UEFI compliant firmware must //at least// do all these things, so if you are writing an OS or something else that you want to run on //any// UEFI compliant firmware, this is why the EFI system partition concept is so important: it gives you (at least in theory) 100% confidence that you can put an EFI executable on a partition formatted with the UEFI FAT implementation and the correct GPT partition type, and the system firmware will be able to read it. This is the thing you can take to the bank, like ‘the firmware will be able to execute some bootloader code I put in the MBR space’ was in the BIOS world.\nSo now we have three important bits of groundwork the UEFI spec provides: thanks to these requirements, any other layer can confidently rely on the fact that the firmware:\nCan read a partition table Can access files in some specific filesystems Can execute code in a particular format This is much more than you can rely on a BIOS firmware being capable of. However, in order to complete the vision of a firmware layer that can handle booting multiple targets – not just disks – we need one more bit of groundwork: there needs to be a mechanism by which the firmware //finds// the various possible boot targets, and a way to configure it.\n===== The UEFI boot manager =====\nThe UEFI spec defines something called the //UEFI boot manager//. (Linux distributions contain a tool called ''efibootmgr'' which is used to manipulate the configuration of the UEFI boot manager). As a sample of what you can expect to find if you do read the UEFI spec, it defines the UEFI boot manager thusly:\n“The UEFI boot manager is a firmware policy engine that can be configured by modifying architecturally defined global NVRAM variables. The boot manager will attempt to load UEFI drivers and UEFI applications (including UEFI OS boot loaders) in an order defined by the global NVRAM variables.”\nWell, that’s that cleared up, let’s move on. {{./icon_wink.gif}}No, not really. Let’s translate that to Human. With only a reasonable degree of simplification, you can think of the UEFI boot manager as being a boot menu. With a BIOS firmware, your firmware level ‘boot menu’ is, necessarily, the disks connected to the system at boot time – no more, no less. This is not true with a UEFI firmware.\nThe UEFI boot manager can be configured – simply put, you can add and remove entries from the ‘boot menu’. The firmware can also (it fact the spec requires it to, in various cases) effectively ‘generate’ entries in this boot menu, according to the disks attached to the system and possibly some firmware configuration settings. It can also be examined – you can look at what’s in it.\nOne rather great thing UEFI provides is a mechanism for doing this //from other layers//: you can configure the system boot behaviour from a booted operating system. You can do all this by using the ''efibootmgr'' tool, once you have Linux booted via UEFI somehow. There are Windows tools for it too, but I’m not terribly familiar with them. Let’s have a look at some typical ''efibootmgr'' output, which I stole and slightly tweaked from the Fedora forums:\n''' [root@system directory]# efibootmgr -v BootCurrent: 0002 Timeout: 3 seconds BootOrder: 0003,0002,0000,0004 Boot0000* CD/DVD Drive BIOS(3,0,00) Boot0001* Hard Drive HD(2,0,00) Boot0002* Fedora HD(1,800,61800,6d98f360-cb3e-4727-8fed-5ce0c040365d)File(\\EFI\\fedora\\grubx64.efi) Boot0003* opensuse HD(1,800,61800,6d98f360-cb3e-4727-8fed-5ce0c040365d)File(\\EFI\\opensuse\\grubx64.efi) Boot0004* Hard Drive BIOS(2,0,00)P0: ST1500DM003-9YN16G . [root@system directory]# '''\nThis is a nice clean example I stole and slightly tweaked from the Fedora forums. We can see a few things going on here.\nThe first line tells you which of the ‘boot menu’ entries you are //currently// booted from. The second is pretty obvious (if the firmware presents a boot menu-like interface to the UEFI boot manager, that’s the timeout before it goes ahead and boots the default entry). The BootOrder is the order in which the entries in the list will be tried. The rest of the output shows the actual boot entries. We’ll describe what they actually do later.\nIf you boot a UEFI firmware entirely normally, without doing any of the tweaks we’ll discuss later, what it ought to do is try to boot from each of the ‘entries’ in the ‘boot menu’, in the order listed in //BootOrder//. So on this system it would try to boot the entry called ‘opensuse’, then if that failed, the one called ‘Fedora’, then ‘CD/DVD Drive’, and then the second ‘Hard Drive’.\n===== UEFI native booting: how it actually works – boot manager entries =====\nWhat does these entries actually //mean//, though? There’s actually a //huge// range of possibilities that makes up rather a large part of the complexity of the UEFI spec all by itself. If you’re reading the spec, pour yourself an extremely large shot of gin and turn to the EFI_DEVICE_PATH_PROTOCOL section, but note that this is a generic protocol that’s used for other things than booting – it’s UEFI’s Official Way Of Identifying Devices For All Purposes, used for boot manager entries but also for all sorts of other purposes. Not every possible EFI device path makes sense as a UEFI boot manager entry, for obvious reasons (you’re probably not going to get too far trying to boot from your video adapter). But you can certainly have an entry that points to, say, a PXE server, not a disk partition. The spec has lots of bits defining valid non-disk boot targets that can be added to the UEFI boot manager configuration.\nFor our purposes, though, lets just consider fairly normal disks connected to the system. In this case we can consider three types of entry you’re likely to come across.\n==== BIOS compatibility boot entries ====\nBoot0000 and Boot0004 in this example are actually BIOS compatibility mode entries, not UEFI native entries. They have not been added to the UEFI boot manager configuration by any external agency, but generated by the firmware itself – this is a common way for a UEFI firmware to implement BIOS compatibility booting, by generating UEFI boot manager entries that trigger a BIOS-compatible boot of a given device. How they //present this to the user// is a different question, as we’ll see later. Whether you see any of these entries or not will depend on your particular firmware, and its configuration. Each of these entries just gives a name – ‘CD/DVD Drive’, ‘Hard Drive’ – and says “if this entry is selected, boot this disk (where ‘this disk’ is ''3,0,00'' for Boot0000 and ''2,0,00'' for Boot0004) in BIOS compatibility mode”.\n==== ‘Fallback path’ UEFI native boot entries ====\nBoot0001 is an entry (fictional, and somewhat unlikely, but it’s for illustrative purposes) that tells the firmware to try and boot from a particular disk, and in UEFI mode not BIOS compatibility mode, but doesn’t tell it anything more. It doesn’t specify a particular boot target on the disk – it just says to boot the disk.\nThe UEFI spec defines a sort of ‘fallback’ path for booting this kind of boot manager entry, which works in principle somewhat like BIOS drive booting: it looks in a standard location for some boot loader code. The details are different, though.\nWhat the firmware will actually do when trying to boot in this way is reasonably simple. The firmware will look through each EFI system partition on the disk in the order they exist on the disk. Within the ESP, it will look for a file with a specific name and location. On an x86-64 PC, it will look for the file ''\\EFI\\BOOT\\BOOTx64.EFI''. What it actually looks for is ''\\EFI\\BOOT\\BOOT{machine type short-name}.EFI'' – ‘x64′ is the “machine type short-name” for x86-64 PCs. The other possibilities are ''BOOTIA32.EFI'' (x86-32), ''BOOTIA64.EFI'' (Itanium), ''BOOTARM.EFI'' (AArch32 – that is, 32-bit ARM) and ''BOOTAA64.EFI'' (AArch64 – that is, 64-bit ARM). It will then execute the first qualifying file it finds (obviously, the file needs to be in the executable format defined in the UEFI specification).\nThis mechanism is not designed for booting permanently-installed OSes. It’s more designed for booting hotpluggable, device-agnostic media, like live images and OS install media. And this is indeed what it’s usually used for. If you look at a UEFI-capable live or install medium for a Linux distribution or other OS, you’ll find it has a GPT partition table and contains a FAT-formatted partition at or near the start of the device, with the GPT partition type that identifies it as an EFI system partition. Within that partition there will be a \\EFI\\BOOT directory with at least one of the specially-named files above. When you boot a Fedora live or install medium in UEFI-native mode, this is the mechanism that is used. The BOOTx64.EFI (or whatever) file handles the rest of the boot process from there, booting the actual operating system contained on the medium.\n==== Full UEFI native boot entries ====\nBoot0002 and Boot0003 are ‘typical’ entries for operating systems permanently installed to permanent storage devices. These entries show us the full power of the UEFI boot mechanism, by not just saying “boot from this disk”, but “boot this specific bootloader in this specific location on this specific disk”, using all the ‘groundwork’ we talked about above.\nBoot0002 is a boot entry produced by a UEFI-native Fedora installation. Boot0003 is a boot entry produced by a UEFI-native OpenSUSE installation. As you may be able to tell, all they’re saying is “load this file from this partition”. The partition is the ''HD(1,800,61800,6d98f360-cb3e-4727-8fed-5ce0c040365d)'' bit: that’s referring to a specific partition (using the EFI_DEVICE_PATH_PROTOCOL, which I’m really not going to attempt to explain in any detail – you don’t necessarily need to know it, if you interact with the boot manager via the firmware interface and ''efibootmgr''). The file is the ''File(\\EFI\\opensuse\\grubx64.efi)'' bit: that just means “load the file in this location on the partition we just described”. The partition in question will almost always be one that qualifies as an EFI system partition, because of the considerations above: that’s the type of partition we can trust the firmware to be able to access.\nThis is the mechanism the UEFI spec provides for operating systems to make themselves available for booting: the operating system is intended to install a bootloader which loads the OS kernel and so on to an EFI system partition, and add an entry to the UEFI boot manager configuration with a name – obviously, this will usually be derived from the operating system’s name – and the location of the bootloader (in EFI executable format) that is intended for loading that operating system.\nLinux distributions use the ''efibootmgr'' tool to deal with the UEFI boot manager. What a Linux distribution actually does, so far as bootloading is concerned, when you do a UEFI native install is really pretty simple: it creates an EFI system partition if one does not already exist, installs an EFI boot loader with an appropriate configuration – often grub2-efi, but there are others – into a correct path in the EFI system partition, and calls ''efibootmgr'' to add an appropriately-named UEFI boot manager entry pointing to its boot loader. Most distros will use an existing EFI system partition if there is one, though it’s perfectly valid to create a new one and use that instead: as we’ve noted, UEFI is a permissive spec, and if you follow the design logically, there’s really no problem with having just as many EFI system partitions as you want.\n===== Configuring the boot process (the firmware UI) =====\nThe above describes the basic mechanism the UEFI spec defines that manages the UEFI boot process. It’s important to realize that your firmware user interface may well not represent this mechanism very clearly. Unfortunately, the spec intentionally refrains from defining how the boot process should be represented to the user or how the user should be allowed to configure it, and what that means – since we’re dealing with [[https://www.happyassassin.net/2013/05/03/a-day-in-the-life-of-a-firmware-engineer/|firmware engineers]] – is that every firmware does it differently, and some do it insanely.\n//Many// firmwares do have fairly reasonable interfaces for boot configuration. A good firmware design will at least show you the boot order, with a reasonable representation of the entries on it, and let you add or remove entries, change the order, or override the order for a specific boot (by changing it just for that boot, or directly instructing the firmware to boot a particular menu entry, or even giving you the option to simply say “boot this disk”, either in BIOS compatibility mode or UEFI ‘fallback’ mode – my firmware does this). Such an interface will often show ‘full’ UEFI native boot entries (like the Fedora and openSUSE examples we saw earlier) only by their name; you have to examine the ''efibootmgr -v'' output to know precisely what these entries will actually try and //do// when invoked.\nSome firmwares try to abstract and simplify the configuration, and may do a good or a bad job of it. For instance, if you have an option to ‘enable or disable’ BIOS compatibility mode, what it’ll really likely //do// add is configure whether the firmware adds BIOS compatibility entries for attached drives to the UEFI boot manager configuration or not. If you have an option to ‘enable or disable’ UEFI native booting, what likely really happens when you ‘disable’ it is that the firmware changes the UEFI boot manager configuration to leave all UEFI-native entries out of the BootOrder.\nThe key point to remember is that any configuration option inside your firmware interface which is to do with booting is really, behind the scenes, configuring the behaviour of the UEFI boot manager. If you understand all the stuff we’ve discussed above, you may well find it easier to figure out what’s //really// happening when you twiddle the knobs your firmware interface exposes.\nIn the BIOS world, you’ll remember, you don’t always find that systems are configured to try and boot from removable drives – CD, USB – before booting from permanent drives. Some are, and some aren’t. Some will try CD before the hard disks, but not USB. People have got fairly used to having to check the BIOS configuration to ensure the boot order is ‘correct’ when trying to install a new operating system.\nThis applies to the UEFI world too, but because of the added flexibility/complexity of the UEFI boot manager mechanism, it can look unfamiliar and scary.\nIf you want to ensure that your system tries to boot from removable devices using the ‘fallback’ mechanism before it tries to boot ‘permanent’ boot entries – as you will want to do if you want to, say, install Fedora – you need this to be the default for your firmware, or you need to be able to tell the firmware this. Depending on your firmware’s interface, you may find there is a ‘menu entry’ for each attached removable device and you just have to adjust the boot order to put it at the top of the list, or you may find that there is the mechanism to directly request ‘UEFI fallback boot of this particular disk’, or you may find that the firmware tries to abstract the configuration somehow. We just don’t know, and that makes writing instructions for this quite hard. But now you broadly understand how things work behind the scenes, you may find it easier to understand your firmware user interface’s representation of that.\n===== Configuring the boot process (from an operating system) =====\nAs we’ve noted above, unlike in the BIOS world, you can actually configure the UEFI boot process from the operating system level. If you have an insane firmware, you may //have// to do this in order to achieve what you want.\nYou can use the ''efibootmgr'' tool mentioned earlier to add, delete and modify entries in the UEFI boot manager configuration, and actually do quite a lot of other stuff with it too. You can change the boot order. You can tell it to boot some particular entry in the list on the next boot, instead of using the //BootOrder// list (if you or some other tool has configured this to happen, your ''efibootmgr -v'' output will include a //BootNext// item stating which menu entry will be loaded on the next boot). There are tools for Windows that can do this stuff from Windows, too. So if you’re really struggling to manage to do whatever it is you want to do with UEFI boot configuration from your firmware interface, but you //can// boot a UEFI native operating system of some kind, you may want to consider doing your boot configuration from that operating system rather than from the firmware UI.\nSo to recap:\nYour UEFI firmware contains something very like what you think of as a boot menu. You can query its configuration with ''efibootmgr -v'', from any UEFI-native boot of a Linux OS, and also //change// its configuration with ''efibootmgr'' (see the man page for details). This ‘boot menu’ can contain entries that say ‘boot this disk in BIOS compatibility mode’, ‘boot this disk in UEFI native mode via the fallback path’ (which will use the ‘look for BOOT(something).EFI’ method described above), or ‘boot the specific EFI format executable at this specific location (almost always on an EFI system partition)’. The nice, clean design that the UEFI spec is trying to imply is that all operating systems should install a bootloader of their own to an EFI system partition, add entries to this ‘boot menu’ that point to themselves, and butt out from trying to take control of booting anything else. Your firmware UI has free rein to represent this mechanism to you in whatever way it wants, and it may do this well, or it may do this poorly. ===== Installing operating systems to UEFI-based computers =====\nLet’s have a quick look at some specific consequences of the above that relate to installing operating systems on UEFI computers.\n==== UEFI native and BIOS compatibility booting ====\nHere’s a very very simple one which people sometimes miss:\nIf you boot the installation medium in ‘UEFI native’ mode, it will do a UEFI native install of the operating system: it will try to write an EFI-format bootloader to an EFI system partition, and attempt to add an entry to the UEFI boot manager ‘boot menu’ which loads that bootloader. If you boot the installation medium in ‘BIOS compatibility’ mode, it will do a BIOS compatible install of the operating system: it will try to write an MBR-type bootloader to the magic MBR space on a disk. This applies (with one minor caveat I’m going to paper over for now) to all OSes of which I’m aware. So you probably want to make sure you understand how, in your firmware, you can choose to boot a removable device in UEFI native mode and how you can choose to boot it in BIOS compatibility mode, and make sure you pick whichever one you actually want to use for your installation.\nYou really cannot do a completely successful UEFI-native installation of an OS if you boot its installation medium in BIOS compatibility mode, because the installer will not be able to configure the UEFI boot manager (this is only possible when booted UEFI-native).\nIt is theoretically possible for an OS installer to install the OS in the BIOS style – that is, write a bootloader to a disk’s MBR – after being booted in UEFI native mode, but most of them //won’t// do this, and that’s probably sensible.\n==== Finding out which mode you’re booted in ====\nIt is possible that you might find yourself with your operating system installer booted, and not sure whether it’s actually booted in UEFI native mode or BIOS compatibility mode. Don’t panic! It’s pretty easy to find out which, in a few different ways. One of the easiest is just to try and talk to the UEFI boot manager. If what you have booted is a Linux installer or environment, and you can get to a shell (ctrl-alt-f2 in the Fedora installer, for instance), run ''efibootmgr -v''. If you’re booted in UEFI native mode, you’ll get your UEFI boot manager configuration, as shown above. If you’re booted in BIOS compatibility mode, you’ll get something like this:\n''' Fatal: Couldn't open either sysfs or procfs directories for accessing EFI variables. Try 'modprobe efivars' as root. '''\nIf you’ve booted some other operating system, you can try running a utility native to that OS which tries to talk to the UEFI boot manager, and see if you get sensible output or a similar kind of error. Or you can examine the system logs and search for ‘efi’ and/or ‘uefi’, and you’ll probably find some kind of indication.\n==== Enabling UEFI native boot ====\nTo be bootable in UEFI native mode, your OS installation medium must obviously actually comply with all this stuff we’ve just described: it’s got to have a GPT partition table, and an EFI system partition with a bootloader in the correct ‘fallback’ path – \\EFI\\BOOT\\BOOTx64.EFI (or the other names for the other platforms). If you’re having trouble doing a UEFI native boot of your installation medium and can’t figure out why, check that this is actually the case. Notably, when using the ''livecd-iso-to-disk'' tool to write a Fedora image to a USB stick, you must pass the ''--efi'' parameter to configure the stick to be UEFI bootable.\n==== Forcing BIOS compatibility boot ====\nIf your firmware seems to make it very difficult to boot from a removable medium in BIOS compatibility mode, but you really want to do that, there’s a handy trick you can use: just make the medium not UEFI native bootable at all. You can do this pretty easily by just wiping all the EFI system partitions. (Alternatively, if using ''livecd-iso-to-disk'' to create a USB stick from a Fedora image, you can just leave out the ''--efi'' parameter and it won’t be UEFI bootable). If at that point your firmware refuses to boot it in BIOS compatibility mode, commence swearing at your firmware vendor (if you didn’t already).\n==== Disk formats (MBR vs. GPT) ====\nHere’s another very important consideration:\nIf you want to do a ‘BIOS compatibility’ type installation, you probably want to install to an MBR formatted disk. If you want to do a UEFI native installation, you probably want to install to a GPT formatted disk. Of course, to make life complicated, many firmwares //can// boot BIOS-style from a GPT formatted disk. UEFI firmwares are in fact technically //required// to be able to boot UEFI-style from an MBR formatted disk (though we are not particularly confident that they all really can). But you really should avoid this if at all possible. This consideration is quite important, as it’s one that trips up quite a few people. For instance, it’s a bad idea to boot an OS installer in UEFI native mode and then attempt to install to an MBR formatted disk without reformatting it. This is very likely to fail. Most modern OS installers will automatically reformat the disk in the correct format if you allow them to completely wipe it, but if you try and tell the installer ‘do a UEFI native installation to this MBR formatted disk and don’t reformat it because it has data on it that I care about’, it’s very likely to fail, even though this configuration is technically covered in the UEFI specification. Specifically, Windows and Fedora at least explicitly disallow this configuration.\n==== Checking the disk format ====\nYou can use the ''parted'' utility to check the format of a given disk:\n''' [adamw@adam Downloads]$ sudo parted /dev/sda GNU Parted 3.1 Using /dev/sda Welcome to GNU Parted! Type 'help' to view a list of commands. (parted) p Model: ATA C300-CTFDDAC128M (scsi) Disk /dev/sda: 128GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags:\nNumber Start End Size Type File system Flags 1 1049kB 525MB 524MB primary ext4 boot 2 525MB 128GB 128GB primary lvm\n(parted) '''\nSee that ''Partition table: msdos''? This is an MBR/MS-DOS formatted disk. If it was GPT-formatted, that would say ''gpt''. You can reformat the disk with the other type of partition table by doing ''mklabel gpt'' or ''mklabel msdos'' from within parted. This will destroy the contents of the disk.\nWith most OS installers, if you pick a disk configuration that blows away the entire contents of the target disk, the installer will automatically reformat it using the most appropriate configuration for the type of installation you’re doing, but if you want to use an existing disk without reformatting it, you’re going to have to check how it’s formatted and take this into account.\n==== Handling EFI system partition if doing manual partitioning ====\nI can only give authoritative advice for Fedora here, but the gist may be useful for other distros / OSes.\nIf you allow Fedora to handle partitioning for you when doing a UEFI native installation – and you use a GPT-formatted disk, or allow it to reformat the disk (by deleting all existing partitions) – it will handle the EFI system partition stuff for you.\nIf you use custom partitioning, though, it will expect you to provide an EFI system partition for the installer to use. If you don’t do this, the installer will complain (with a somewhat confusing error message) and refuse to let you start the installation.\nSo if you’re doing a UEFI native install and using custom partitioning, you need to ensure that a partition of the ‘EFI system partition’ type is mounted at ''/boot/efi'' – this is where Fedora expects to find the EFI system partition it’s using. If there is an existing EFI system partition on the system, just set its mount point to ''/boot/efi''. If there is not an EFI system partition yet, create a partition, set its type to //EFI system partition//, make it at least 200MB big (500MB is good), and set its mount point to ''/boot/efi''.\n==== A specific example ====\nTo boil down the above: if you bought a Windows 8 or later system, you //almost// certainly have a UEFI native install of Windows to a GPT-formatted disk. This means that if you want to install another OS alongside that Windows install, you almost certainly want to do a UEFI-native installation of your other OS. If you don’t like all this UEFI nonsense and want to go back to the good old world you’re familiar with, you will, I’m afraid, have to blow away the UEFI-native Windows installation, and it would be a good idea to reformat the disk to MBR.\n===== Implications and Complications =====\nSo, that’s how UEFI booting works, at least a reasonable approximation. When I describe it like that, it almost all makes sense, right?\nHowever, all is not sweetness and light. There are problems. There always are.\nAttentive readers may have noticed that I’ve talked about the UEFI spec //providing// a mechanism. This is accurate, and important. As the UEFI spec is a ‘broad consensus’ sort of thing, one of its major shortcomings (looked at from a particular perspective) is that it’s nowhere near prescriptive enough.\nIf you read the UEFI spec critically, its basic approach is to define a set of functions that UEFI compliant firmwares must support. What it doesn’t do a lot of at all is strictly requiring things to be done in any particular way, or not done in any particular way.\nSo: the spec says that a system firmware must do all the stuff I’ve described above, in order to be considered a UEFI-compliant firmware. The spec, however, doesn’t talk about what operating systems ‘should’ or ‘must’ do at all, and it doesn’t say that firmwares must //not// support (or no-one may expect them to support, or whatever)…anything at all. If you’re making a UEFI firmware, in other words, you have to support GPT formatted disks, and FAT-formatted EFI system partitions, and you must read UEFI boot manager entries in the standard format, and you must do this and that and the other – but you can also do any //other// crap you like.\nIt’s pretty easy to read certain implications from the spec – it carefully sets up this nice mechanism for handling OS (or other ‘bootable thing’) selection at the firmware level, for instance, with the clear implication “hey, it’d be great if all OSes were written to this mechanism”. But the UEFI spec doesn’t //require// that, and neither does any other widely-respected specification.\nSo, what happens in the real world is that we wind up with really dumb crap. Apple, for instance, ships at least //some// Macs with their bootloaders in an HFS+ partition. The spec says a UEFI-compliant firmware must support UEFI FAT partitions with the specific GPT partition type that identifies them as an “EFI system partition”, but it doesn’t say the firmware can’t //also// recognize some other filesystem type and load a bootloader from that. (Whether you consider such a partition to be an “EFI system partition” or not is an interesting philosophical conundrum, but let’s skate right over that for now).\nThe world would pretty clearly be a better place if everyone just damn well used the EFI system partition format the spec goes to such great pains to define, but Apple is Apple and we can’t have nice things, so Apple went right ahead and wrote firmwares that //also// can read and load code from HFS+ partitions, and now everyone else has to deal with that or tell Macs to go and get boned. Apple also goes quite a long way beyond the spec in its boot process design, and if you want your alternative OS to show up on its graphical boot menu with a nice icon and things, you have to do more than what the UEFI spec would suggest.\nThere are various similar incredibly annoying corner cases we’ve come across, but let’s not go into them all right now. This post is long enough.\nAlso, as we noted earlier, the spec makes no requirements as to how the mechanism should be represented to the user. So if a couple of software companies write OSes to behave ‘nicely’ according to the conventions the spec is clearly designed to back, and install EFI boot loaders and define EFI boot manager entries with nice clear names – like, oh say, “Fedora” and “Windows” – they are implicitly relying on the firmware to then give the user //some// kind of sane interface //somewhere// relatively discoverable that lets them choose to boot “Windows” or “Fedora”. The more firmwares don’t do a good job of this, the less willing OS engineers will be to rely on the ‘proper’ conventions, and the more likely they’ll be to start rebuilding ugly hacks above the firmware level.\nTo be fair, we could do somewhat more at the OS level. We could present all those neat efibootmgr capabilities rather more obviously – we can use that ‘don’t respect BootOrder on the next boot, but instead boot //this//‘ capability, for instance, and have ‘Reboot to Windows’ as an option. It’d be kinda nice if someone looked at exposing all this functionality somewhere more obvious than efibootmgr. Windows 8 systems do use this, to some extent – you can reboot your system to the firmware UI from the Windows 8 settings menus, for instance. But still.\nAll this is really incredibly frustrating, because UEFI is so //close// to making things really a lot better. The BIOS approach doesn’t provide any kind of convention or standard for multibooting at all – it //has// to be handled entirely above the firmware level. We (the industry) could have come up with some sort of convention for handling multiboot, but we never did, so it just became a multiple-decade epic fail, where each operating system came up with its own approach and lots of people wrote their own bootloaders which tried to subsume all the operating systems and all the operating systems and independent bootloaders merrily fought like cats in a sack. I mean, pre-UEFI multibooting is such a clusterf**k it’s not even worth going into, it’s broken sixteen ways from Sunday by definition.\nIf UEFI – or a spec built on top of it – had just //mandated// that everybody follow the conventions UEFI carefully establishes, and //mandated// that firmwares provide a sensible user interface, the win would have been epic. But it doesn’t, so it’s entirely possible that in a UEFI world things will be //even worse than they were in the BIOS world//. If many more firmwares show up that don’t present a good UI for the UEFI boot manager mechanism, what could happen is that OS vendors give up on the UEFI boot manager mechanism (or decide to support it //and// alternatives, because choice!) and just reinvent the entire goddamn nightmare of BIOS multibooting //on top of UEFI// – and we’ll all have to deal with all of that, //plus// the added complication of the UEFI boot manager layer. You’ll have multiple bootloaders fighting to load multiple operating systems all on top of the whole UEFI boot manager mechanism which is just throwing a whole bunch of other variables into the equation.\nThis is not a prospect filling the mind of anyone who’s had to think about it with joy.\nStill, it’s important to recognize that the sins of UEFI in this area are sins of omission – they are not sins of commission, and they’re not really the result of evil intent on anyone’s part. The entity you should really be angry with if you have an idiotic system firmware that doesn’t give you good access to the UEFI boot manager mechanism is not the UEFI forum, or Microsoft, and it //certainly// isn’t Fedora and even more //certainly// isn’t me ;). The entity you should be angry at is your system/motherboard manufacturer and the goddamn incompetents they hired to write the firmware, because the UEFI spec makes it really damn clear to anyone with two brain cells to rub together that it would be a very good idea to provide some kind of useful user interface to the UEFI boot manager, and any firmware which doesn’t do so is crap code by definition. Yes, the UEFI forum should’ve realized that firmware engineers couldn’t code their way out of a goddamned paper bag and just ordered them to do so, but still, it’s ultimately the firmware engineers who should be lined up against the nearest wall.\nWait, we can simplify that. “Any firmware is crap code”. Usually pretty accurate.\n===== Secure Boot =====\nSo now we come, finally, to Secure Boot.\nSecure Boot is not magic. It’s not complicated. OK, that’s a lie, it’s incredibly complicated, but the //theory// isn’t very complicated. And no, Secure Boot itself is not evil. I am entirely comfortable stating this as a fact, and you should be too, unless you think GPG is evil.\nSecure Boot is defined in chapter 28 of the UEFI spec (2.4a, anyway). It’s actually a pretty clever mechanism. But what it does can be described very, very simply. It says that the firmware can contain a set of signatures, and refuse to run any EFI executable which is not signed with one of those signatures.\nThat’s it. Well, no, it really isn’t, but that’s a reasonably acceptable simplification. Security is hard, so there are all kinds of wibbly bits to implementing a really secure bootchain using Secure Boot, and mjg59 can tell you all about them, or you can pour another large shot of gin and read the whole of chapter 28. But that’s the basic idea.\nUsing public key cryptography to verify the integrity of something is hardly a radical or evil concept. Pretty much all Linux distributions depend on it – we sign our packages and have our package managers go AWOOGA AWOOGA if you try to install a package which isn’t signed with one of our keys. This isn’t us being evil, and I don’t think anyone’s ever accused an OS of being evil for using public key cryptographic signing to establish trust in this way. Secure Boot is literally this exact same perfectly widely accepted mechanism, applied to the boot chain. Yet because a bunch of journalists //wildly// grasped the wrong end of the stick, it’s widely considered to be slightly more evil than Hitler.\nSecure Boot, as defined in the UEFI spec, says nothing at all about what the keys the firmware trusts should be, or where they should come from. I’m not going to go into all the goddamn details, because it gets stultifyingly boring and this post is too long already. But the executive summary is that the spec is utterly and entirely about defining a //mechanism// for doing cryptographic verification of a boot chain. It does not really even consider any kind of icky questions about the //policy// for doing so. It does nothing evil. It is as flexible as it could reasonably be, and takes care to allow for all the mechanisms involved to be configurable at multiple levels. The word ‘Microsoft’ is not mentioned. It is not in any way, shape, or form a secret agenda for Microsoft’s domination of the world. If you doubt this, at the very bloody least, go and //read// it. I’ve given you all the necessary pointers. There is literally not a single legitimate reason I can think of for anyone to be //angry// with the idea “hey, it’d be neat if there was a mechanism for optional cryptographic verification of bootloader code in this firmware specification”. None. Not one.\n===== Secure Boot in the real world =====\nMost of the unhappiness about Secure Boot is not really about Secure Boot the mechanism – whether the people expressing that unhappiness //think// it is or not – but about specific implementations of Secure Boot in the real world.\nThe only one we really care about is Secure Boot as it’s implemented on PCs shipped with Microsoft Windows 8 or higher pre-installed.\nMicrosoft has these things called the [[http://msdn.microsoft.com/en-us/library/windows/hardware/jj128256.aspx|Windows Hardware Certification Requirements]]. There they are. They are not Top Secret, Eyes Only, You Will Be Fed To Bill Gates’ Sharks After Reading – they’re right there on the Internet for anyone to read.\nIf you want to get cheap volume licenses of Windows from Microsoft to pre-install on your computers and have a nice “reassuring” ‘Microsoft Approved!’ sticker or whatever on the case, you have to comply with these requirements. That’s all the force they have: they are not //actually// a part of the law of the United States or any other country, whatever some people seem to believe. Bill Gates cannot feed you to his sharks if you sell a PC that doesn’t comply with these requirements, so long as you don’t want a cheap copy of Windows to pre-install and a nice sticker. There is literally no requirement for a PC sold //outside// the Microsoft licensing program to configure Secure Boot in any particular way, or include Secure Boot at all. A PC that claims to have a UEFI 2.2 or later compliant firmware must implement Secure Boot, but can ship with it configured in literally absolutely any way it pleases (including turned off).\nIf you’re going to have very loud opinions about Secure Boot, you have zero excuse for not going and reading the Microsoft certification requirements. Right now. I’ll wait. You can search for “Secure Boot” to get to the relevant bit. It starts at “System.Fundamentals.Firmware.UEFISecureBoot”.\nYou should read it. But here is a summary of what it says.\nComputers complying with the requirements must:\nShip with Secure Boot turned on (except for servers) Have Microsoft’s key in the list of keys they trust Disable BIOS compatibility mode when Secure Boot is enabled (actually the UEFI spec requires this too, if I read it correctly) Support signature blacklisting x86 computers complying with the requirements must additionally:\nAllow a physically present person to disable Secure Boot Allow a physically present person to enable Custom Mode, and modify the list of keys the firmware trusts ARM computers complying with the requirements must additionally:\nNOT allow a physically present person to disable Secure Boot NOT allow a physically present person to enable Custom Mode, and modify the list of keys the firmware trusts Yes. You read that correctly. The Microsoft certification requirements, for x86 machines, //explicitly require implementers to give a physically present user complete control over Secure Boot// – turn it off, or completely control the list of keys it trusts. Another important note here is that while the certification requirements state that the out-of-the-box list of trusted keys must //include// Microsoft’s key, they don’t say, for e.g., that it must //not include// any other keys. The requirements explicitly and intentionally allow for the system to ship with any number of other trusted keys, too.\nThese requirements aren’t present entirely out of the goodness of Microsoft’s heart, or anything – they’re present in large part because other people explained to Microsoft that if they weren’t present, it’d have a hell of a lawsuit on its hands[[https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/#fn:1|2]] – but they are present. Anyone who actually understands UEFI and Secure Boot cannot possibly read the requirements any other way, they are extremely clear and unambiguous. They both clearly //intend to// and //succeed in// ensuring the owner of a certified system has complete control over Secure Boot.\nIf you have an x86 system that claims to be Windows certified but does not allow you to disable Secure Boot, it is in direct violation of the certification requirements, and you should certainly complain very loudly to someone. If a lot of these systems exist then we clearly have a problem and it might be time for that giant lawsuit, but so far I’m not aware of this being the case. All the x86-based, Windows-certified systems I’ve seen //have// had the ‘disable Secure Boot’ option in their firmwares.\nNow, for ARM machines, the requirements are significantly more evil: they state exactly the opposite, that it must //not// be possible to disable Secure Boot and it must //not// be possible for the system owner to change the trusted keys. This is bad and wrong. It makes Microsoft-certified ARM systems into a closed shop. But it’s worth noting it’s no //more// bad or wrong than most other major ARM platforms. Apple locks down the bootloader on all iDevices, and most Android devices also ship with locked bootloaders.\nIf you’re planning to buy a Microsoft-certified ARM device, be aware of this, and be aware that you will not be in control of what you can boot on it. If you don’t like this, don’t buy one. But also don’t buy an iDevice, or an Android device with a locked bootloader (you can buy Android devices with unlocked or unlockable bootloaders, still, but you have to do your research).\nAs far as x86 devices go, though, right now, Microsoft’s certification requirements actually //explicitly protect// your right to determine what can boot on your system. This is good.\n===== Recommendations =====\nThe following are AdamW’s General Recommendations On Managing System Boot, offered with absolutely no guarantees of accuracy, purity or safety.\nIf you can possibly manage it, have one OS per computer. If you need more than one OS, buy more computers, or use virtualization. If you can do this everything is very simple and it doesn’t much matter if you have BIOS or UEFI firmware, or use UEFI-native or BIOS-compatible boot on a UEFI system. Everything will be nice and easy and work. You will whistle as you work, and be kind to children and small animals. All will be sweetness and light. Really, do this. If you absolutely must have more than one OS per computer, at least have one OS //per disk//. If you’re reasonably comfortable with how BIOS-style booting works and you don’t think you need Secure Boot, it’s pretty reasonable to use BIOS-compatible booting rather than UEFI-style booting in this situation on a UEFI-capable system. You’ll probably have less pain to deal with and you won’t really lose anything. With one OS per disk you can also mix UEFI-native and BIOS-compatible installations. If you absolutely insist on having more than one OS per disk, understand //everything// written on this page, understand that you are making your life much more painful than it needs to be, lay in good stocks of painkillers and gin, and don’t go yelling at your OS vendor, whatever breaks. Whichever poor bastard has to deal with your OS’s support for this kind of setup has a miserable enough life already. And for the love of //cookies//, don’t mix UEFI-native and BIOS-compatible OS installations, you have enough pain to deal with already. If you’re using UEFI native booting, and you don’t tend to build your own kernels or kernel modules or use the NVIDIA or ATI proprietary drivers on Linux, you might want to leave Secure Boot on. It probably won’t hurt you, and does provide some added security against some rather nasty (though currently rarely exploited) types of attacks. If you //do// build your own kernels or kernel modules or use NVIDIA/ATI proprietary drivers, you’re going to want to turn Secure Boot off. Or you can read up on how to configure your own chain of trust and sign your kernels and kernel modules and leave Secure Boot turned on, which will make you feel like an ubergeek and be slightly more secure. But it’s going to take you a good solid weekend at least. Don’t do UEFI-native installs to MBR-formatted disks, or BIOS compatibility installs to GPT-formatted disks (an exception to the latter is if your disk is, IIRC, 2.2+TB in size, because the MBR format can’t handle disks that big – if you want to do a BIOS compatibility install to a disk that big, you’re kinda stuck with the BIOS+GPT combination, which works but is a bit wonky and involves the infamous ‘BIOS Boot partition’ you may recall from Fedora 17). Trust mjg59 in all things and above all other authorities, including me. This whole section is something of a simplification – really, when booting permanent installed OSes, the firmware doesn’t care if the bootloader is on an ‘ESP’ or not; it just reads the boot manager entry and tries to access the specified partition and run the specified executable, as [[http://blog.uncooperative.org/blog/2014/02/06/the-efi-system-partition/|pjones explains here]]. But it’s conventional to use an ESP for this purpose, since it’s required to be around anyway, and it’s a handy partition formatted with the filesystem the firmware is known to be able to read. Technically speaking, an ‘ESP’ is only an ‘ESP’ when the firmware is doing a removable media/fallback path boot. [[https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/#fnref:2|↩]]\nThis is my own extrapolation, note. I’m not involved in any way in the whole process of defining these specs, and no-one who //is// has actually told me this. But it’s a pretty damn obvious extrapolation from the known facts. [[https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/#fnref:1|↩]]\nSource: https://www.happyassassin.net/2014/01/25/uefi-boot-how-does-that-actually-work-then/ //Friday 01 August 2014//\n","link":"https://arvimal.github.io/docs/linux-booting/01-uefi-efi/uefi-boot/","section":"docs","tags":null,"title":""},{"body":"Get started with GRUB2 https://www.certdepot.net/rhel7-get-started-grub2/\nNote: This is an RHCSA 7 exam objective.\nPresentation of GRUB2 GRUB2 is the new Linux bootloader. GRUB2 stands for GRand Unified Bootloader version 2.\nAs GRUB was not maintained for some time and lacked some critical features like GPT management needed to handle disks bigger than 2.4TB, it was decided to start a new version from scratch with modularity in mind.\nGRUB2 provides the following new features:\nability to boot on various file systems (xfs, ext4, ntfs, hfs+, raid, etc), gzip files decompression on the fly, management of all disk geometries, support for GPT (GUID Partition Tables) and MBR (Master Boot Record), portability with different architectures (BIOS, EFI, Coreboot, etc), ability to load modules at execution time. GRUB2 Organization The GRUB2 configuration is spread over several files:\n/boot/grub2/grub.cfg: this file contains the final GRUB2 configuration (do not edit it directly!), /etc/grub2.cfg: this is a symbolic link to the /boot/grub2/grub.cfg file, /etc/default/grub: this file contains the list of the GRUB2 variables (the values of the environment variables can be edited), /etc/sysconfig/grub: this is a symbolic link to the /etc/default/grub file, /etc/grub.d: this directory contains all the individual files internally used by GRUB2. This tutorial will only explore knowledge required for the RHCSA exam. Refer to the Additional Resources section for more details.\nBasic Management To get the details about the current active kernel, type:\n1# grub2-editenv list 2saved_entry=CentOS Linux (3.10.0-229.11.1.el7.x86_64) 7 (Core) Note: This information is stored in the /boot/grub2/grubenv file.\nTo get the list of the kernels displayed at boot time, type:\n1# grep ^menuentry /boot/grub2/grub.cfg 2menuentry \u0026#39;CentOS Linux (3.10.0-229.20.1.el7.x86_64) 7 (Core)\u0026#39; ... 3menuentry \u0026#39;CentOS Linux (3.10.0-229.14.1.el7.x86_64) 7 (Core)\u0026#39; ... 4menuentry \u0026#39;CentOS Linux 7 (Core), with Linux 0-rescue-f19b719117b44bf3a3fb777bd4127\u0026#39; ...caf To permanently define the kernel to execute at boot time (here 0 for the first entry), type:\n1# grub2-set-default 0 To display the GRUB2 variables, type:\n1# cat /etc/default/grub 2GRUB_TIMEOUT=5 3GRUB_DISTRIBUTOR=\u0026#34;$(sed \u0026#39;s, release .*$,,g\u0026#39; /etc/system-release)\u0026#34; 4GRUB_DEFAULT=saved 5GRUB_DISABLE_SUBMENU=true 6GRUB_TERMINAL=\u0026#34;serial console\u0026#34; 7GRUB_SERIAL_COMMAND=\u0026#34;serial --speed=115200\u0026#34; 8GRUB_CMDLINE_LINUX=\u0026#34;rd.lvm.lv=rhel/swap crashkernel=auto rd.lvm.lv=rhel/root console=ttyS0,115200\u0026#34; 9GRUB_DISABLE_RECOVERY=\u0026#34;true\u0026#34; Where\nGRUB_TIMEOUT defines the boot waiting delay (here 5 seconds), GRUB_DISTRIBUTOR contains the distribution name (here CentOS Linux), GRUB_DEFAULT specifies the default menu entry; it can be a number, an entry name or the string saved which means the entry saved during the last reboot or the execution of the grub2-set-default command, GRUB_DISABLE_SUBMENU allows (false) or not (true) the display of a submenu (see below), GRUB_TERMINAL defines the terminal input \u0026amp; output device (here console and serial), GRUB_SERIAL_COMMAND configures the serial port, GRUB_CMDLINE_LINUX specifies the command-line arguments added to the menu entries for the Linux kernel, GRUB_DISABLE_RECOVERY defines if all entries can be selected in recovery mode through a separate line (false) or only the default entry (true). If you want to change the content of any variables in the previous file, you will need to type:\n1# grub2-mkconfig -o /boot/grub2/grub.cfg Note: This is the main command to memorize for the exam. You can also replace /boot/grub2/grub.cfg with /etc/grub2.cfg\nTo better understand some of the environment variables, here are the standard display with GRUB_DISABLE_RECOVERY=”true” and GRUB_DISABLE_SUBMENU=true:\n1 CentOS Linux 7 (Core), with Linux 3.10.0-229.20.1.el7.x86_64 2 CentOS Linux 7 (Core), with Linux 3.10.0-229.14.1.el7.x86_64 3 CentOS Linux 7 (Core), with Linux 0-rescue-f19b719117b44bf3a3fb777bd4127\u0026gt; 4 5 Use the ^ and v keys to change the selection. 6 Press \u0026#39;e\u0026#39; to edit the selected item, or \u0026#39;c\u0026#39; for a command prompt. If GRUB_DISABLE_RECOVERY is set to “false”, here is the new display:\n1 CentOS Linux 7 (Core), with Linux 3.10.0-229.20.1.el7.x86_64 2 CentOS Linux 7 (Core), with Linux 3.10.0-229.20.1.el7.x86_64 (recovery m\u0026gt; 3 CentOS Linux 7 (Core), with Linux 3.10.0-229.14.1.el7.x86_64 4 CentOS Linux 7 (Core), with Linux 3.10.0-229.14.1.el7.x86_64 (recovery m\u0026gt; 5 CentOS Linux 7 (Core), with Linux 0-rescue-f19b719117b44bf3a3fb777bd4127\u0026gt; 6 CentOS Linux 7 (Core), with Linux 0-rescue-f19b719117b44bf3a3fb777bd4127\u0026gt; 7 8 Use the ^ and v keys to change the selection. 9 Press \u0026#39;e\u0026#39; to edit the selected item, or \u0026#39;c\u0026#39; for a command prompt. Each kernel line gets an associated line in recovery mode.\nIf GRUB_DISABLE_RECOVERY is now set to “true” (like in the initial standard display) and GRUB_DISABLE_SUBMENU is set to false, here is the new display:\n1 CentOS Linux 7 (Core) 2 Advanced options for CentOS Linux 7 (Core) 3 Use the ^ and v keys to change the selection. 4 Press \u0026#39;e\u0026#39; to edit the selected item, or \u0026#39;c\u0026#39; for a command prompt. If the first entry is selected (“CentOS Linux 7 (Core)”), the system boots. If the second option is chosen, the standard menu is shown with an additional line at the bottom to go back to the first menu with the Esc key:\n1 CentOS Linux 7 (Core), with Linux 3.10.0-229.20.1.el7.x86_64 2 CentOS Linux 7 (Core), with Linux 3.10.0-229.14.1.el7.x86_64 3 CentOS Linux 7 (Core), with Linux 0-rescue-f19b719117b44bf3a3fb777bd4127\u0026gt; 4 5 Use the ^ and v keys to change the selection. 6 Press \u0026#39;e\u0026#39; to edit the selected item, or \u0026#39;c\u0026#39; for a command prompt. 7 Press Escape to return to the previous menu. Additional Resources To better explore GRUB2, you can:\nread Brendan Swigart’s article, loot at a GRUB2 CentOS article, explore the GRUB2 configuration manual, read a Tecmint article about configuring and troubleshooting GRUB2, read a LinuxSecrets tutorial about changing boot order with GRUB2, read this article describing the RHEL 7 booting process. Customizing the GRUB 2 Configuration File https://docs.fedoraproject.org/en-US/Fedora/23/html/System_Administrators_Guide/sec-Customizing_the_GRUB_2_Configuration_File.html\nGRUB 2 scripts search the user's computer and build a boot menu based on what operating systems the scripts find. To reflect the latest system boot options, the boot menu is rebuilt automatically when the kernel is updated or a new kernel is added.\nHowever, users may want to build a menu containing specific entries or to have the entries in a specific order. GRUB 2 allows basic customization of the boot menu to give users control of what actually appears on the screen.\nGRUB 2 uses a series of scripts to build the menu; these are located in the /etc/grub.d/ directory. The following files are included:\n01_users, which is created only when a boot loader password is assigned in a kickstart file. 10_linux, which locates kernels in the default partition of Fedora. 30_os-prober, which builds entries for operating systems found on other partitions. 40_custom, a template, which can be used to create additional menu entries. Scripts from the /etc/grub.d/ directory are read in alphabetical order and can be therefore renamed to change the boot order of specific menu entries.\nWith the GRUB_TIMEOUT key set to 0 in the /etc/default/grub file, GRUB 2 does not display the list of bootable kernels when the system starts up. In order to display this list when booting, press and hold any alphanumeric key when the BIOS information is displayed; GRUB 2 will present you with the GRUB menu.\nBy default, the key for the GRUB_DEFAULT directive in the /etc/default/grub file is the word saved. This instructs GRUB 2 to load the kernel specified by the saved_entry directive in the GRUB 2 environment file, located at /boot/grub2/grubenv. You can set another GRUB record to be the default, using the grub2-set-default command, which will update the GRUB 2 environment file.\nBy default, the saved_entry value is set to the name of latest installed kernel of package type kernel. This is defined in /etc/sysconfig/kernel by the UPDATEDEFAULT and DEFAULTKERNEL directives. The file can be viewed by the root user as follows:\n1~]# cat /etc/sysconfig/kernel 2# UPDATEDEFAULT specifies if new-kernel-pkg should make 3# new kernels the default 4UPDATEDEFAULT=yes 5 6# DEFAULTKERNEL specifies the default kernel package type 7DEFAULTKERNEL=kernel-core The DEFAULTKERNEL directive specifies what package type will be used as the default. Installing a package of type kernel-debug will not change the default kernel while the DEFAULTKERNEL is set to package type kernel.\nGRUB 2 supports using a numeric value as the key for the saved_entry directive to change the default order in which the operating systems are loaded. To specify which operating system should be loaded first, pass its number to the grub2-set-default command. For example:\n1~]# grub2-set-default 2 Note that the position of a menu entry in the list is denoted by a number starting with zero; therefore, in the example above, the third entry will be loaded. This value will be overwritten by the name of the next kernel to be installed.\nTo force a system to always use a particular menu entry, use the menu entry name as the key to the GRUB_DEFAULT directive in the /etc/default/grub file. To list the available menu entries, run the following command as root:\n1~]# awk -F\\\u0026#39; \u0026#39;$1==\u0026#34;menuentry \u0026#34; {print $2}\u0026#39; /etc/grub2.cfg The file name /etc/grub2.cfg is a symlink to the grub.cfg file, whose location is architecture dependent. For reliability reasons, the symlink is not used in other examples in this chapter. It is better to use absolute paths when writing to a file, especially when repairing a system.\nChanges to /etc/default/grub require rebuilding the grub.cfg file as follows:\nGRUB 2 - Fedora Project Wiki https://fedoraproject.org/wiki/GRUB_2\nGRUB 2 is the latest version of GNU GRUB, the GRand Unified Bootloader. A bootloader is the first software program that runs when a computer starts. It is responsible for loading and transferring control to the operating system kernel, (Linux, in the case of Fedora). The kernel, in turn, initializes the rest of the operating system.\nGRUB 2 has replaced what was formerly known as GRUB (i.e. version 0.9x), which has, in turn, become GRUB Legacy.\nStarting with Fedora 16, GRUB 2 is the default bootloader on x86 BIOS systems. For upgrades of BIOS systems the default is also to install GRUB 2, but you can opt to skip bootloader configuration entirely.\nUpdating GRUB 2 configuration on BIOS systems The grub2 packages contain commands for installing a bootloader and for creating a bootloader configuration file.\ngrub2-install will install the bootloader - usually in the MBR, in free unpartioned space, and as files in /boot. The bootloader is installed with something like:\n1grub2-install /dev/sda grub2-mkconfig will create a new configuration based on the currently running system, what is found in /boot, what is set in /etc/default/grub, and the customizable scripts in /etc/grub.d/ . A new configuration file is created with:\n1grub2-mkconfig -o /boot/grub2/grub.cfg The configuration format has evolved over time, and a new configuration file might be slightly incompatible with the old bootloader. It is therefore a good idea to first run grub2-install whenever you would need to run grub2-mkconfig.\nThe Fedora installer, anaconda, will run these grub2 commands and there is usually no reason to run them manually.\nIt is generally safe to directly edit /boot/grub2/grub.cfg in Fedora. Grubby in Fedora patches the configuration when a kernel update is performed and will try to not make any other changes than what is necessary. (Other distributions, in particular Debian and Debian-derived distributions provide a software patch that adds an update-grub command which is neither included nor needed in Fedora.) Manual changes might however be overwritten with grub2-mkconfig next time the system is upgraded with anaconda. Some customizations can be placed in /etc/grub.d/40_custom or /boot/grub2/custom.cfg and will survive running grub2-mkconfig.\nUpdating GRUB 2 configuration on UEFI systems To install or fix GRUB 2 on a UEFI system on Fedora 18 or newer, you need to do four things:\nUEFI firmware, in general, likes to boot from an EFI System Partition on a disk with a GPT label. In gdisk, it looks something like this:\n1Number Start (sector) End (sector) Size Code Name 2 1 2048 264191 128.0 MiB EF00 EFI System That partition should be formatted as FAT. If in doubt, FAT32 is a good dialect of FAT to choose.\nFedora expects this partition to be mounted at /boot/efi.\nInstall the bootloader files If you don't already have the relevant packages installed, do for Fedora 22 and later versions with DNF or with YUM for older Fedora releases:\n1dnf install grub2-efi shim 2yum install grub2-efi shim If you do, then try:\n1dnf reinstall grub2-efi shim 2yum reinstall grub2-efi shim instead.\nMake sure that /boot/efi is mounted when you do this.\nThis installs the signed shim and the GRUB 2 binary.\nCreate a GRUB 2 configuration Under EFI, GRUB 2 looks for its configuration in /boot/efi/EFI/fedora/grub.cfg. For newly installed kernels to work, grubby expects /etc/grub2-efi.cfg to be a symlink to the real grub.cfg (i.e. /boot/efi/EFI/fedora/grub.cfg).\nIf you already have a grub 2 EFI config file, you should be okay. If not, grub2-mkconfig can help, but your mileage may vary.\n1grub2-mkconfig -o /boot/efi/EFI/fedora/grub.cfg grub2-install shouldn't be used on EFI systems. The grub2-efi package installs a prebaked grubx64.efi on the EFI System partition, which looks for grub.cfg on the ESP in /EFI/fedora/ whereas the grub2-install command creates a custom grubx64.efi, deletes the original installed one, and looks for grub.cfg in /boot/grub2/.\nCreate a boot menu entry TL;DR: This should happen automatically. If it doesn't, read on.\nWhen you power on your system, your firmware will look for EFI variables that tell it how to boot. If you're already booted in EFI mode and EFI runtime services are working correctly, you can configure your boot menu with efibootmgr. If not, you'll have to bootstrap the process.\nFortunately, shim can help you bootstrap. The EFI program /boot/efi/EFI/BOOT/fallback.efi will look for files called BOOT.CSV in your ESP and will add boot entries corresponding to them, if such entries do not already appear to exist. shim provides a BOOT.CSV file that will add an entry for grub2-efi for you. So just using the EFI Shell to invoke fallback.efi should do the trick. You can do this with commands like:\n1\u0026gt; fs0: 2\u0026gt; cd EFI\\BOOT 3\u0026gt; fallback.efi If you have no boot entries at all, then just booting off your disk in UEFI mode should automatically invoke /boot/efi/EFI/BOOT/BOOTX64.EFI, which will, in turn, invoke fallback.efi.\nIf you already have incorrect boot entries, you'll either need to delete them or to modify BOOT.CSV to create new entries with different names.\nAdding Other operating systems to the GRUB 2 menu grub2-mkconfig will add entries for other operating systems it can find. That will be done based on the output of the os-prober tool.\nThat might however not work so well, especially not for booting other Linux operating systems, and especially not on UEFI systems. See http://www.gnu.org/software/grub/manual/grub.html#Multi_002dboot-manual-config .\nSetting default entry Please look to (default) kernel sysconfig options. if file /etc/sysconfig/kernel have\n1UPDATEDEFAULT=yes in every kernel update the grub entry is update to last entry, if you don't want that please set:\n1UPDATEDEFAULT=no (write \u0026quot;no\u0026quot; in lower case)\nDue to grub2-mkconfig (and os-prober) we cannot predict the order of the entries in /boot/grub2/grub.cfg, so we set the default by name/title instead.\nOpen /etc/default/grub and ensure this line exists:\n1GRUB_DEFAULT=saved and ensure this line not exists:\n1GRUB_SAVEDEFAULT=true or ensure this line exists:\n1GRUB_SAVEDEFAULT=false Apply the change to grub.cfg by running:\nNow list all possible menu entries\n1grep -P \u0026#34;submenu|^menuentry\u0026#34; /boot/grub2/grub.cfg | cut -d \u0026#34;\u0026#39;\u0026#34; -f2 Now set the desired default menu entry\n1grub2-set-default \u0026#34;\u0026lt;submenu title\u0026gt;\u0026lt;menu entry title\u0026gt;\u0026#34; Verify the default menu entry\n1grub2-editenv list If you understand the risks involved and still want to directly modify /boot/grub2/grub.cfg, here's how you can do it:\nEdit /boot/grub2/grub.cfg, and change the line\n1set default=\u0026#34;0\u0026#34; to\n1set default=\u0026#34;5\u0026#34; Encountering the dreaded GRUB 2 boot prompt If improperly configured, GRUB 2 may fail to load and subsequently drop to a boot prompt. To address this issue, proceed as follows:\nLoad the XFS and LVM modules 1insmod xfs 2insmod lvm List the drives which GRUB 2 sees: 1grub2\u0026gt; ls The output for a dos partition table /dev/sda with three partitons will look something like this: 1(hd0) (hd0,msdos3) (hd0,msdos2) (hd0,msdos1) While the output for a gpt partition table /dev/sda with four partitions will look something like this: 1(hd0) (hd0,gpt4) (hd0,gpt3) (hd0,gpt2) (hd0,gpt1) With this information you can now probe each partition of the drive and locate your vmlinuz and initramfs files: 1ls (hd0,1)/ Will list the files on /dev/sda1. If this partition contains /boot, the output will show the full name of vmlinuz and initramfs.\nArmed with the location and full name of vmlinuz and initramfs you can now boot your system. 5a. Declare your root partition:\n1grub\u0026gt; set root=(hd0,3) 5b. Declare the kernel you wish to use:\n1grub\u0026gt; linux (hd0,1)/vmlinuz-3.0.0-1.fc16.i686 root=/dev/sda3 rhgb quiet selinux=0 2# NOTE : add other kernel args if you have need of them 3# NOTE : change the numbers to match your system 5c. Declare the initrd to use:\n1 2grub\u0026gt; initrd (hd0,1)/initramfs-3.0.0-1.fc16.i686.img 3# NOTE : change the numbers to match your system 5d. Instruct GRUB 2 to boot the chosen files:\n1grub\u0026gt; boot After boot, open a terminal.\nIssue the grub2-mkconfig command to re-create the grub.cfg file grub2 needed to boot your system:\n1grub2-mkconfig -o /boot/grub2/grub.cfg Issue the grub2-install command to install grub2 to your hard drive and make use of your config: 1grub2-install --boot-directory=/boot /dev/sda 2# Note: your drive may have another device name. Check for it with mount command output. Additional Scenario It's also possible to boot into a configfile that's located on another partition. If the user is faced with such a scenario, as is often the case with multi-boot systems containing Ubuntu and Fedora, the following steps in the grub rescue shell might become useful to know:\n1insmod part_msdos 2insmod xfs 3insmod lvm 4set root=\u0026#39;hd0,msdos1\u0026#39; 5configfile /grub2/grub.cfg Where, hd0,msdos1 is the pertinent boot partition, which holds the grub.cfg file.\nOther GRUB 2 issues Absent Floppy Disk : It has been reported by some users that GRUB 2 may fail to install on a partition's boot sector if the computer floppy controller is activated in BIOS without an actual floppy disk drive being present. A possible workaround is to run (post OS install) from rescue mode:\n1grub2-install \u0026lt;target device\u0026gt; --no-floppy Setting a password for interactive edit mode If you wish to password-protect GRUB2's interactive edit mode but you do not want to require users to enter a password to do a plain, simple, ordinary boot, create /etc/grub.d/01_users with the following lines:\n1cat \u0026lt;\u0026lt; EOF 2set superusers=\u0026#34;root\u0026#34; 3export superusers 4password root secret 5EOF To apply your changes run:\n1grub2-mkconfig -o /boot/grub2/grub.cfg You can encrypt the password by using pbkdf2. Use grub2-mkpasswd-pbkdf2 to encrypt the password, then replace the password line with:\n1password_pbkdf2 root grub.pbkdf2.sha512.10000.1B4BD9B60DE889A4C50AA9458C4044CBE129C9607B6231783F7E4E7191D8254C0732F4255178E2677BBE27D03186E44815EEFBAD82737D81C87F5D24313DDDE7.E9AEB53A46A16F30735E2558100D8340049A719474AEEE7E3F44C9C5201E2CA82221DCF2A12C39112A701292BF4AA071EB13E5EC8C8C84CC4B1A83304EA10F74 Starting from atleast Fedora 21, the --md5pass kickstart option must be set using output from grub2-mkpasswd-pbkdf2.\nUsing old graphics modes in bootloader Terminal device is chosen with GRUB_TERMINAL; additional quote from http://www.gnu.org/software/grub/manual/grub.html#Simple-configuration\nValid terminal output names depend on the platform, but may include ‘console’ (PC BIOS and EFI consoles), ‘serial’ (serial terminal), ‘gfxterm’ (graphics-mode output), ‘ofconsole’ (Open Firmware console), or ‘vga_text’ (VGA text output, mainly useful with Coreboot).\nThe default is to use the platform's native terminal output.\nThe default in Fedora is gfxterm and to get the legacy graphics modes you need to set GRUB_TERMINAL to right variable from the description above in /etc/default/grub\nEnable Serial Console in Grub To enable Serial console in grub add the following entry's to /etc/default/grub\n( Adjust baudrate/parity/bits/flow control to fit your environment and cables)\n1GRUB_CMDLINE_LINUX=\u0026#39;console=tty0 console=ttyS0,115200n8\u0026#39; 2GRUB_TERMINAL=serial 3GRUB_SERIAL_COMMAND=\u0026#34;serial --speed=115200 --unit=0 --word=8 --parity=no --stop=1\u0026#34; And re-generate grub\ngrub2-mkconfig -o /boot/grub2/grub.cfg\nNOTE: in UEFI boot environment, use efi0 instead of --unit=0. If that doesn't work, check that your serial port is visible in your UEFI environment, e.g. by running devtree or dh -p SerialIO in EFI Shell. See this discussion for more information.\nNormally, GRUB2 will be installed and set up by the installer, Anaconda, during the installation process. You will probably never have to deal with manual installation of GRUB2. However, in certain situations , you will want to install GRUB2 manually, especially if you need to repair the existing GRUB2 installation or you want to change its configuration.\nThis procedure shows the steps to install GRUB2 on a UEFI system on Fedora 18 or newer. The procedure consists of four parts.\nCreating an EFI System Partition The UEFI firmware requires to boot from an EFI System Partition on a disk with a GPT label. To create such a partition:\nList available block devices to find a place to create your ESP.\nCreate at least a 128 MiB disk partition using a GPT label on the primary hard disk.\nFor the sake of this procedure, we assume that the created partition is recognized as /dev/sda1.\nFormat the partition with the FAT32 file system.\nCreate the /boot/efi directory as a mount point for the new partition.\nMount the partition to the /boot/efi mount point.\n1# mount /dev/sda1 /boot/efi Proceed to the next part.\nInstall the bootloader files In order to use GRUB2 with on the UEFI systems, you need to install or re-install appropriate packages:\nRe-install the necessary packages.\n1# dnf reinstall grub2-efi grub2-efi-modules shim If the above command ends with an error, install the packages.\n1# dnf install grub2-efi grub2-efi-modules shim More information\nThis installs the signed shim and the GRUB2 binary. Create a GRUB2 configuration If you already have a working GRUB2 EFI configuration file, you do not need to do anything else.\nOtherwise, create the configuration file using the grub2-mkconfig command.\n1# grub2-mkconfig -o /boot/grub2/grub.cfg More information\nUnder EFI, GRUB2 looks for its configuration in /boot/efi/EFI/fedora/grub.cfg, however the postinstall script of grub2-common installs a small shim which chains to the standard configuration at /boot/grub2/grub.cfg which is generated above. To reset this shim to defaults, delete the existing /boot/efi/EFI/fedora/grub.cfg and then dnf reinstall grub2-common.\nFor newly installed kernels to work, grubby expects /etc/grub2-efi.cfg to be a symlink to the real grub.cfg (for example /boot/grub2/grub.cfg).\nSolving problems with UEFI bootloader When you power on your system, your firmware will look for EFI variables that tell it how to boot. On running systems, which have booted into the EFI mode and their EFI runtime services are working correctly, you can configure your boot menu with efibootmgr.\nIf not, shim can help you bootstrap. The EFI program /boot/efi/EFI/BOOT/fallback.efi will look for files called BOOT.CSV in your ESP and will add boot entries corresponding to them. The shim command provides its own BOOT.CSV file that will add an entry for grub2-efi.\nDuring the boot process, you can use the EFI Shell to invoke the fallback.efi profile to boot the system:\nEnter the boot partition.\nNavigate into the EFI\\BOOT directory.\nInvoke the fallback.efi profile.\nMore information\nIf you have no boot entries at all, then just booting off your disk in UEFI mode should automatically invoke /boot/efi/EFI/BOOT/BOOTX64.EFI, which will, in turn, invoke fallback.efi.\nIf you already have incorrect boot entries, you’ll either need to delete them or to modify BOOT.CSV to create new entries with different names.\nThe Grub2 Rescue shell https://aty.sdsu.edu/bibliog/latex/debian/grub2rescue.html\nIntroduction Nothing is more frustrating than making some small change to your system, and then discovering that it won't boot. This must have happened to me dozens of times over the years; and the problem is always something different and unexpected.\nThe most frustrating experience you can have with GRUB is to be dropped into its “Rescue shell”. You might get a cryptic error message, followed by\nEntering rescue mode . . .\ngrub rescue\u0026gt;\nNo help; no advice on how to proceed; and even the Grub2 Manual tells you nothing useful. Yuck.\nThe rescue shell is an exceedingly minimal, Spartan environment. It offers only a tiny subset of the regular Grub shell's commands:\nset unset ls insmod\nThese commands offer no options, and it is impossible even to learn which ones are available. Even common commands like cat and cd are not available. At first glance, it would seem impossible to do anything useful in this limited environment.\nAnd yet, it's actually possible to go through the booting process manually — provided that you know something about the booting process, and how Grub handles it. In fact, the operations that Grub executes automatically can be done by hand, just with the limited means provided by the rescue shell.\nUnderstanding Disaster Actually, the fact that you see the grub rescue\u0026gt; prompt is good news in disguise. It means you haven't wiped out Grub's booting system. The hardware has gone through the POST process, and loaded the primary stage of the boot loader; but the information available to that stage (supposedly, the addresses of the disk blocks that hold the next stage) was wrong. Grub is alive, but it needs a little help.\nThe common causes of this situation are things that changed the locations of the next pieces of Grub's boot-time subsystem. Maybe you re-formatted the filesystem that holds those files; maybe you updated a kernel, but didn't re-generate Grub's configuration files; maybe you ran update-grub with incorrect partition identifiers in the /etc/grub.d/40_custom shell script. The result was that Grub's early stages that depend on absolute block addresses couldn't find the following pieces. You can tell the part of Grub that's already working how to proceed.\nWith luck, the error message that precedes the rescue prompt will tell you what Grub looked for but couldn't find. Write it down, and take appropriate action after you've re-booted your box.\nDiagnosing disaster The first thing to do is to find out what Grub knows already. At the\ngrub rescue\u0026gt;\nprompt, enter the command:\nset\nand Grub will tell you what little it knows. Again, take note of this information, as it will provide clues to what you need to do next — as well as clues to fixing the problem before the next reboot.\nThe main Grub variables available at this point are usually the prefix and root parameters. What Grub calls prefix is the location (in Grub's peculiar notation) of the directory that holds Grub's pieces. In normal *IX terminology, this would usually be /boot/grub. But Grub doesn't have mounted filesystems yet; it only knows about disk partitions, which it calls things like (hd0,msdos1).\nSo, if you have a separate boot partition, which is normally mounted on /boot, Grub will need to have prefix set to an address of the form (hd0,msdos1)/grub. On the other hand, if your /boot directory is in your root-filesystem's partition, Grub will need to have prefix=(hd0,msdos1)/boot/grub.\nSimilarly, what Grub calls root is NOT the partition that contains the root filesystem, but the partition that contains the kernel and initial RAM filesystem (i.e., initramfs) files. That usually means that Grub thinks root=(hd0,msdos1).\nFixing the problem First of all, make sure Grub can see the partitions that contain these vital parts. Tell the rescue shell:\nls\nand it will show you the partitions it knows about. This will be a list of things like\n(hd0,msdos1) (hd0,msdos2) . . .\nwhich mean /dev/sda1, /dev/sda2, and so on. Remember that Grub's name for the first disk is hd0; the second disk is hd1, etc. — but the partitions themselves are numbered normally, starting at 1 instead of zero.\nDon't be misled by a superficial resemblance between the rescue-shell ls command and the normal ls that you use at a bash prompt. The normal command has scads of options; the rescue-shell command is a stripped-down version with no options, and a different output format. Only the names are similar.\nIf the rescue shell had a cat command, you could list the contents of /boot/grub/device.map to learn Grub's correspondence between disks and names; but it doesn't, so you can't. Keep a copy of the device.map file printed out beforehand, because the devices might not map out the way you expect. (For example, on my machine, Grub thinks sda is hd0, as you'd expect; but it also thinks sdb is hd2, and sdc is hd1, which is screwy.)\nThen, if Grub has the wrong values for either prefix or root, you can fix its error by telling the rescue shell something like\nset prefix=(hd0,msdos1)/boot/grub\nor whatever the correct value is in your box.\nRemember that you can verify that Grub has the correct values for these parameters with a simple\nset\ncommand. And you can double-check by telling the rescue shell to list the contents of those directories:\nls $prefix/\nProceed to boot manually Now you need to lead Grub through its normal booting sequence. The first step is to make sure it has its module available:\ninsmod normal\nThis module is the “guts” of Grub2: it contains the apparatus for reading configuration files, and displaying the usual Grub boot menu. The correct prefix and root parameter values are needed, if Grub is to find any modules.\nOnce the module is inserted, you can execute it as a new rescue-shell command:\nnormal\nAnother vital module that must be loaded is the linux.mod file:\ninsmod linux\nNow you can set up the linux kernel's command line:\nlinux /boot/vmlinuz-3.16.0-4-686-pae root=/dev/sda2 ro\nor whatever is the correct name for your kernel. Note that the “root” in this line points (in normal terms) to your root filesystem's disk partition; it is different from Grub's root parameter! You can specify the root partition here in perfectly normal terms — either by specifying --fs-uuid and the UUID of the partition, or by using a filesystem label, as in root=LABEL=ROOT (if your root filesystem is named ROOT). If you need additional command-line parameters, like video=640x480, be sure to add them here as well.\nSimilarly, you need to tell Grub where the initial RAMdisk filesystem is:\ninitrd /boot/initrd.img-3.16.0-4-686-pae\nMake sure it matches the kernel version!\nNow, with both the kernel and the initrd modules installed, and their arguments supplied, Grub should be able to boot. Tell the rescue shell to do so:\nboot\nOnce the linux and normal modules are inserted, most of Grub's apparatus will be working, and the larger set of normal GrubScript commands will be accessible. Or, if you get everything messed up and want to start over, the usual invocation will re-boot the system.\nBack to normal When you are back up, be sure to fix the errors that caused the booting problem. If the configuration parameters are set in the file and any special scripts (like ), you should be able to get a correct just by executing (as root):\nupdate-grub\nand\ngrub-install /dev/sda\n(or whatever disk is marked as the boot device in your BIOS).\nSometimes, the error that brought up the rescue shell was\nerror: no such device:\nfollowed by a UUID for some partition that has disappeared — usually, due to a re-made partition. In this case, you may need to invoke\nupdate-initramfs -u -v\nto get the correct partition named in the initrd.img file.\nCopyright © 2015, 2017 Andrew T. Young\nBack to the . . . main LaTeX page\nGrubEFIReinstall https://wiki.debian.org/GrubEFIReinstall\nStarting with Windows 8 most Desktop PC have EFI as firmware instead of the legacy BIOS. If your EFI based PC is not booting debian, here is an easy way to reinstall grub-efi, the bootloader used by debian on these PCs.\nTo reinstall grub, you need either a live CD/USB to access your current system , or you can use the rEFInd boot manager on a live CD/USB to boot your current system.\nUsing the rEFInd rescue media At the author's web page http://www.rodsbooks.com/refind/getting.html, you will find updated direct links to all sorts of packaging. To boot from a rescue media, select either the CD iso or the image for USB stick, most firmware offers the choice nowadays. If choosing the latter make sure to follow the instructions in the readme. It is recommended to read the author's web pages to get a better understanding of what you are doing.\nBoot your computer with the Refind media Refind will parse your hard drive for installed kernels, and provide you a graphic menu to boot them. Choose your Linux Kernel and boot it.\nReinstalling grub-efi on your hard drive Check that the computer booted in computer in EFI mode:\n1[ -d /sys/firmware/efi ] \u0026amp;\u0026amp; echo \u0026#34;EFI boot on HDD\u0026#34; || echo \u0026#34;Legacy boot on HDD\u0026#34; 2should return \u0026#34;EFI boot on HDD\u0026#34;. After starting a root shell ( if you boot from a live media, you should start a chroot shell instead, as explained in https://help.ubuntu.com/community/Grub2/Installing#via_ChRoot ) check that your EFI system partition (most probably /dev/sda1) is mounted on /boot/efi. If the /boot/efi directory does not exist, you will need to create it.\n1mount /dev/sda1 /boot/efi Reinstall the grub-efi package\n1apt-get install --reinstall grub-efi Put the debian bootloader in /boot/efi and create an appropriate entry in the computer NVRAM\n1grub-install /dev/sda Re create a grub config file based on your disk partitioning schema\n1update-grub You should check afterwards that:\nCheck 1. the bootloader is existing in /boot/efi/EFI/debian/grubx64.efi\n1file /boot/efi/EFI/debian/grubx64.efi 2 3/boot/efi/EFI/debian/grubx64.efi: PE32+ executable (EFI application) x86-64 (stripped to external PDB), for MS Windows Check 2. the nvram entry was properly created.\n1efibootmgr --verbose | grep debian You can now reboot, and Grub should greet you.\nTroubleshooting If after this steps you're not booting, the EFI of your PC might have some bugs.\nProblem1: Weak EFI implementation only recognizes the fallback bootloader The uefi firmware refuses to boot the debian/grubx64.efi bootloader, and so we have to hijack the uefi fallback boot loader. See http://mjg59.livejournal.com/138188.html for details.\nUsing debian installer in rescue mode, /dev/sda1 being the FAT32 ESP partition, /dev/sda2 the root partition\n1mkdir /target 2mount /dev/sda2 /target 3mount /dev/sda1 /target/boot/efi 4for i in /sys /proc /dev; do mount --bind $i /target$i; done 5chroot /target 1cd /boot/efi/EFI 2mkdir boot 3cp debian/grubx64.efi boot/bootx64.efi 4exit 5for i in /sys /proc /dev; do umount /target$i; done 6umount /target/boot/efi 7umount /target Once booted into your normal Debian, tell grub to ensure the fallback boot loader up to date. To do that, run the following:\n1echo \u0026#34;grub-efi-amd64 grub2/force_efi_extra_removable boolean true\u0026#34; | sudo debconf-set-selections Note: The above command will permanently hijack the fallback boot loader, which might be undesirable in dual-boot setups.\nProblem2: EFI boot entries disappear after reboot The uefi firmware did not create a proper boot entry in NVRAM. This has been seen in a Lenovo Thinkcenter M92Z. The symptom for this will be a missing HD path after the debian entry in the efibootmgr --verbose output.\n1BootCurrent: 0024 2Timeout: 0 seconds 3BootOrder: 0024,0022,0023,0016,0000,0001 4Boot0000* debian Vendor(99e275e7-75a0-4b37-a2e6-c5385e6c00cb,) 5Boot0016* Generic Usb Device Vendor(99e275e7-75a0-4b37-a2e6-c5385e6c00cb,) 6Boot0022* UEFI: IPv4 Intel(R) 82579LM Gigabit Network Connection ACPI(a0341d0,0)PCI(19,0)MAC(d43d7e6d8bfc,0)IPv4(0.0.0.0:0\u0026lt;-\u0026gt;0.0.0.0:0,0, 0AMBO 7Boot0023* UEFI: IPv6 Intel(R) 82579LM Gigabit Network Connection ACPI(a0341d0,0)PCI(19,0)MAC(d43d7e6d8bfc,0)030d3c000000000000000000000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000AMBO 8Boot0024* UEFI: Generic Flash Disk 8.00 ACPI(a0341d0,0)PCI(1d,0)USB(1,0)USB(1,0)HD(1,800,2a5f,02f23208-1aa9-4b6c-b6e1-8155390eb9db)AMBO You can then try to install Refind as your bootloader in the hard drive, following the steps at this gist: https://gist.github.com/EmmanuelKasper/9590327.\nHow to update GRUB2 using grub2-editenv and grubby in RHEL 8 Linux https://www.golinuxcloud.com/update-grub2-grubby-grub2-editenv-rhel-8/\nNotes: In rescue mode, in case chroot to the filesystem on-disk does not work, do the following manually: Check the partitions and type (fdisk -l), and identify if LVM volumes exist. If LVM exists, activate them using lvm vgscan and lvm vgchange -ay Mount /dev/\u0026lt;VG_name\u0026gt;/root onto a folder that will be used as a chroot folder later (mount /dev/\u0026lt;VG_name\u0026gt;/root /sysroot) Mount /dev/sda1 on /boot (Check if /dev/sda1 is the disk containing /boot) Mount other valid logical volumes (Check with lvm lvs) onto folders under /sysroot/ Eg.. /dev/rhel_vg/var/ on /sysroot/var Bind mount /proc, /sys, /dev onto /sysroot mount —bind /proc /sysroot/proc mount —bind /dev /sysroot/dev mount —bind /sys /sysroot/sys The boot loader Grand Unified Boot Loader (GRUB2) in RHEL 8 differs from the GRUB2 in RHEL 7. In this article I will share different commands to update GRUB2 and set kernel command line argument in RHEL 8 Linux.\nAn update to Red Hat Enterprise Linux 8 Beta results in /etc/default/grub changes no longer being included when issuing grub2-mkconfig -o /boot/grub2/grub.cfg. It seems that at least some options set there are now silently ignored.\nIn this article I will disable IPv6 using GRUB2 (ipv6.disable) on RHEL 8 Linux to demonstrate the steps to update GRUB2 in RHEL 8 Linux host.\nUpdate GRUB2 using grub2-editenv The grub2-editenv utility is actually the recommended path to alter these variables. As a result, the following can be used. Appending an extra argument:\n1[root@rhel-8 ~]# grub2-editenv - list | grep kernelopts 2kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet Here copy paste the content from above command and append the additional kernel parameter you wish to add to the GRUB2.\n1[root@rhel-8 ~]# grub2-editenv - set \u0026#34;kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1\u0026#34; Alternatively you can also choose a shorter and less error prone approach as shown below\n1[root@rhel-8 ~]# grub2-editenv - set \u0026#34;$(grub2-editenv - list | grep kernelopts) ipv6.disable=1\u0026#34; Here, $(grub2-editenv - list | grep kernelopts) will automatically select the existing kernelopts and will append the additional kernel command line argument.\nVerify the newly added output\n1[root@rhel-8 ~]# grub2-editenv - list | grep kernelopts 2kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1 Next reboot the node and verify the configuration to make sure your changes are persistent\n1[root@rhel-8 ~]# grub2-editenv - list | grep kernelopts 2kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1 As you can see our IPv6 is disabled in the GRUB2 command line.\n1[root@rhel-8 ~]# cat /proc/cmdline 2BOOT_IMAGE=(hd0,msdos1)/vmlinuz-4.18.0-80.el8.x86_64 root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1 Similarly to remove a parameter or argument from kernel command line in GRUB2, use the below syntax\n1# grub2-editenv - set \u0026#34;$(grub2-editenv - list | grep kernelopts | sed -e \u0026#39;s///\u0026#39;)\u0026#34; Lastly reboot your system for the changes to take effect.\nUpdate GRUB2 using grub2-mkconfig The older method of achieving this behaviour is still possible, but the existing kernelopts value will need to be unset first:\n1[root@rhel-8 ~]# grep GRUB_CMDLINE_LINUX /etc/default/grub 2GRUB_CMDLINE_LINUX=\u0026#34;crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet\u0026#34; Here I will update ipv6.disable=1 in the GRUB2 configuration file /etc/default/grub\n1[root@rhel-8 ~]# grep GRUB_CMDLINE_LINUX /etc/default/grub 2GRUB_CMDLINE_LINUX=\u0026#34;crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1\u0026#34; But as you see the existing kernelopts reflects old GRUB2 entry, so if we reboot the node or rebuild our GRUB2 then the new changes will not reflect on the node.\n1[root@rhel-8 ~]# grub2-editenv - list | grep kernelopts 2kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet So we need to unset the kernelopts which is an additional step here:\n1[root@rhel-8 ~]# grub2-editenv - unset kernelopts next rebuild the grub configuration\n1[root@rhel-8 ~]# grub2-mkconfig -o /boot/grub2/grub.cfg 2Generating grub configuration file ... 3done Next re-verify kernelopts\n1[root@rhel-8 ~]# grub2-editenv - list | grep kernelopts 2kernelopts=root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1 So our changes are visible as expected.\nUpdate GRUB2 using grubby grubby is a utility for manipulating bootloader-specific configuration files.\nYou can use grubby also for changing the default boot entry, and for adding/removing arguments from a GRUB2 menu entry.\n1[root@rhel-8 ~]# grubby --info DEFAULT 2index=0 3kernel=\u0026#34;/boot/vmlinuz-4.18.0-80.el8.x86_64\u0026#34; 4args=\u0026#34;ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet $tuned_params\u0026#34; 5root=\u0026#34;/dev/mapper/rhel-root\u0026#34; 6initrd=\u0026#34;/boot/initramfs-4.18.0-80.el8.x86_64.img $tuned_initrd\u0026#34; 7title=\u0026#34;Red Hat Enterprise Linux (4.18.0-80.el8.x86_64) 8.0 (Ootpa)\u0026#34; 8id=\u0026#34;f653c3662e81432aa484cd1639a04047-4.18.0-80.el8.x86_64\u0026#34; Add the argument you wish to append to the kernel command line menu\n1[root@rhel-8 ~]# grubby --args ipv6.disable=1 --update-kernel DEFAULT Next verify the GRUB2 configuration\n1[root@rhel-8 ~]# grubby --info DEFAULT 2index=0 3kernel=\u0026#34;/boot/vmlinuz-4.18.0-80.el8.x86_64\u0026#34; 4args=\u0026#34;ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet $tuned_params ipv6.disable=1\u0026#34; 5root=\u0026#34;/dev/mapper/rhel-root\u0026#34; 6initrd=\u0026#34;/boot/initramfs-4.18.0-80.el8.x86_64.img $tuned_initrd\u0026#34; 7title=\u0026#34;Red Hat Enterprise Linux (4.18.0-80.el8.x86_64) 8.0 (Ootpa)\u0026#34; 8id=\u0026#34;f653c3662e81432aa484cd1639a04047-4.18.0-80.el8.x86_64\u0026#34; Next reboot the node to activate the changes\n1[root@rhel-8 ~]# cat /proc/cmdline 2BOOT_IMAGE=(hd0,msdos1)/vmlinuz-4.18.0-80.el8.x86_64 root=/dev/mapper/rhel-root ro crashkernel=auto resume=/dev/mapper/rhel-swap rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet ipv6.disable=1 Lastly I hope the steps from the article to set kernel command line argument, update GRUB2 using grub2-editenv, grub2-mkconfig and grubby in RHEL 8 Linux was helpful. So, let me know your suggestions and feedback using the comment section.\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/02-grub2/","section":"docs","tags":["grub","grub2","bootloader","mbr","guid","gpt","efi","bios","boot","grub2-mkconfig"],"title":""},{"body":"Boot Loader Specification https://systemd.io/BOOT_LOADER_SPECIFICATION/\nTL;DR: Currently there’s no common boot scheme across architectures and platforms for open-source operating systems. There’s also little cooperation between multiple distributions in dual-boot (or triple, … multi-boot) setups. We’d like to improve this situation by getting everybody to commit to a single boot configuration format that is based on drop-in files, and thus is robust, simple, works without rewriting configuration files and is free of namespace clashes.\nThe Boot Loader Specification defines a scheme how different operating systems can cooperatively manage a boot loader configuration directory, that accepts drop-in files for boot menu items that are defined in a format that is shared between various boot loader implementations, operating systems, and userspace programs. The same scheme can be used to prepare OS media for cases where the firmware includes a boot loader. The target audience for this specification is:\nBoot loader developers, to write a boot loader that directly reads its configuration at runtime from these drop-in snippets Firmware developers, to add generic boot loading support directly to the firmware itself Distribution and Core OS developers, in order to create these snippets at OS/kernel package installation time UI developers, for implementing a user interface that discovers the available boot options OS Installer developers, to prepare their installation media and for setting up the initial drop-in directory Why is there a need for this specification? Of course, without this specification things already work mostly fine. But here’s why we think this specification is needed:\nTo make the boot more robust, as no explicit rewriting of configuration files is required any more To allow an out of the box boot experience on any platform without the need of traditional firmware mechanisms (e.g. BIOS calls, UEFI Boot Services) To improve dual-boot scenarios. Currently, multiple Linux installations tend to fight over which boot loader becomes the primary one in possession of the MBR, and only that one installation can then update the boot loader configuration of it freely. Other Linux installs have to be manually configured to never touch the MBR and instead install a chain-loaded boot loader in their own partition headers. In this new scheme as all installations share a loader directory no manual configuration has to take place, and all participants implicitly cooperate due to removal of name collisions and can install/remove their own boot menu entries at free will, without interfering with the entries of other installed operating systems. Drop-in directories are otherwise now pretty ubiquitous on Linux as an easy way to extend configuration without having to edit, regenerate or manipulate configuration files. For the sake of uniformity, we should do the same for extending the boot menu. Userspace code can sanely parse boot loader configuration which is essential with modern BIOSes which do not necessarily initialize USB keyboards anymore during boot, which makes boot menus hard to reach for the user. If userspace code can parse the boot loader configuration, too, this allows for UIs that can select a boot menu item to boot into, before rebooting the machine, thus not requiring interactivity during early boot. To unify and thus simplify configuration of the various boot loaders around, which makes configuration of the boot loading process easier for users, administrators and developers alike. For boot loaders with configuration scripts such as grub2, adopting this spec allows for mostly static scripts that are generated only once at first installation, but then do not need to be updated anymore as that is done via drop-in files exclusively. Why not simply rely on the EFI boot menu logic? EFI is not ubiquitous, especially not in embedded systems. If you have an EFI system, it provides a boot options logic that can offer similar functionality. Here’s why we think that it is not enough for our uses:\nThe various EFI implementations implement the boot order/boot item logic to different levels. Some firmware implementations do not offer a boot menu at all and instead unconditionally follow the EFI boot order, booting the first item that is working. If the firmware setup is used to reset all data usually all EFI boot entries are lost, making the system entirely unbootable, as the firmware setups generally do not offer a UI to define additional boot items. By placing the menu item information on disk, it is always available, regardless if the BIOS setup data is lost. Harddisk images should be moveable between machines and be bootable without requiring explicit EFI variables to be set. This also requires that the list of boot options is defined on disk, and not in EFI variables alone. EFI is not universal yet (especially on non-x86 platforms), this specification is useful both for EFI and non-EFI boot loaders. Many EFI systems disable USB support during early boot to optimize boot times, thus making keyboard input unavailable in the EFI menu. It is thus useful if the OS UI has a standardized way to discover available boot options which can be booted to. Technical Details Everything described below is located on a placeholder file system $BOOT. The installer program should pick $BOOT according to the following rules:\nOn disks with MBR disk labels If the OS is installed on a disk with MBR disk label, and a partition with the MBR type id of 0xEA already exists it should be used as $BOOT. Otherwise, if the OS is installed on a disk with MBR disk label, a new partition with MBR type id of 0xEA shall be created, of a suitable size (let’s say 500MB), and it should be used as $BOOT. On disks with GPT disk labels If the OS is installed on a disk with GPT disk label, and a partition with the GPT type GUID of bc13c2ff-59e6-4262-a352-b275fd6f7172 already exists, it should be used as $BOOT. Otherwise, if the OS is installed on a disk with GPT disk label, and an ESP partition (i.e. with the GPT type UID of c12a7328-f81f-11d2-ba4b-00a0c93ec93b) already exists and is large enough (let’s say 250MB) and otherwise qualifies, it should be used as $BOOT. Otherwise, if the OS is installed on a disk with GPT disk label, and if the ESP partition already exists but is too small, a new suitably sized (let’s say 500MB) partition with GPT type GUID of bc13c2ff-59e6-4262-a352-b275fd6f7172 shall be created and it should be used as $BOOT. Otherwise, if the OS is installed on a disk with GPT disk label, and no ESP partition exists yet, a new suitably sized (let’s say 500MB) ESP should be created and should be used as $BOOT. This placeholder file system shall be determined during installation time, and an fstab entry may be created. It should be mounted to either /boot/ or /efi/. Additional locations like /boot/efi/, with /boot/ being a separate file system, might be supported by implementations. This is not recommended because the mounting of $BOOT is then dependent on and requires the mounting of the intermediate file system.\nNote: $BOOT should be considered shared among all OS installations of a system. Instead of maintaining one $BOOT per installed OS (as /boot/ was traditionally handled), all installed OS share the same place to drop in their boot-time configuration.\nFor systems where the firmware is able to read file systems directly, $BOOT must be a file system readable by the firmware. For other systems and generic installation and live media, $BOOT must be a VFAT (16 or 32) file system. Applications accessing $BOOT should hence not assume that fancier file system features such as symlinks, hardlinks, access control or case sensitivity are supported.\nThis specification defines two types of boot loader entries. The first type is text based, very simple and suitable for a variety of firmware, architecture and image types (“Type #1”). The second type is specific to EFI, but allows single-file images that embed all metadata in the kernel binary itself, which is useful to cryptographically sign them as one file for the purpose of SecureBoot (“Type #2”).\nNot all boot loader entries will apply to all systems. For example, Type #1 entries that use the efi key and all Type #2 entries only apply to EFI systems. Entries using the architecture key might specify an architecture that doesn’t match the local one. Boot loaders should ignore all entries that don’t match the local platform and what the boot loader can support, and hide them from the user. Only entries matching the feature set of boot loader and system shall be considered and displayed. This allows image builders to put together images that transparently support multiple different architectures.\nNote that the $BOOT partition is not supposed to be exclusive territory of this specification. This specification only defines semantics of the /loader/ directory inside the file system (see below), but it doesn’t intend to define ownership of the whole file system exclusively. Boot loaders, firmware, and other software implementating this specification may choose to place other files and directories in the same file system. For example, boot loaders that implement this specification might install their own boot code into the $BOOT partition. On systems where $BOOT is the ESP this is a particularly common setup. Implementations of this specification must be able to operate correctly if files or directories other than /loader/ are found in the top level directory. Implementations that add their own files or directories to the file systems should use well-named directories, to make name collisions between multiple users of the file system unlikely.\nType #1 Boot Loader Specification Entries We define two directories below $BOOT:\n$BOOT/loader/ is the directory containing all files needed for Type #1 entries $BOOT/loader/entries/ is the directory containing the drop-in snippets. This directory contains one .conf file for each boot menu item. Note: In all cases the /loader/ directory should be located directly in the root of the file system. Specifically, if $BOOT is the ESP, then /loader/ directory should be located directly in the root directory of the ESP, and not in the /EFI/ subdirectory.\nInside the $BOOT/loader/entries/ directory each OS vendor may drop one or more configuration snippets with the suffix “.conf”, one for each boot menu item. The file name of the file is used for identification of the boot item but shall never be presented to the user in the UI. The file name may be chosen freely but should be unique enough to avoid clashes between OS installations. More specifically it is suggested to include the machine ID (/etc/machine-id or the D-Bus machine ID for OSes that lack /etc/machine-id), the kernel version (as returned by uname -r) and an OS identifier (The ID field of /etc/os-release). Example: $BOOT/loader/entries/6a9857a393724b7a981ebb5b8495b9ea-3.8.0-2.fc19.x86_64.conf.\nThese configuration snippets shall be Unix-style text files (i.e. line separation with a single newline character), in the UTF-8 encoding. The configuration snippets are loosely inspired on Grub1’s configuration syntax. Lines beginning with ‘#’ shall be ignored and used for commenting. The first word of a line is used as key and shall be separated by one or more spaces from its value. The following keys are known:\ntitle shall contain a human readable title string for this menu item. This will be displayed in the boot menu for the item. It is a good idea to initialize this from the PRETTY_NAME of /etc/os-release. This name should be descriptive and does not have to be unique. If a boot loader discovers two entries with the same title it is a good idea to show more than just the raw title in the UI, for example by appending the version field. This field is optional. Example: “Fedora 18 (Spherical Cow)”. version shall contain a human readable version string for this menu item. This is usually the kernel version and is intended for use by OSes to install multiple kernel versions at the same time with the same title field. This field shall be in a syntax that is useful for Debian-style version sorts, so that the boot loader UI can determine the newest version easily and show it first or preselect it automatically. This field is optional. Example: 3.7.2-201.fc18.x86_64. machine-id shall contain the machine ID of the OS /etc/machine-id. This is useful for boot loaders and applications to filter out boot entries, for example to show only a single newest kernel per OS, or to group items by OS, or to maybe filter out the currently booted OS in UIs that want to show only other installed operating systems. This ID shall be formatted as 32 lower case hexadecimal characters (i.e. without any UUID formatting). This key is optional. Example: 4098b3f648d74c13b1f04ccfba7798e8. linux refers to the Linux kernel to spawn and shall be a path relative to the $BOOT directory. It is recommended that every distribution creates a machine id and version specific subdirectory below $BOOT and places its kernels and initial RAM disk images there. Example: /6a9857a393724b7a981ebb5b8495b9ea/3.8.0-2.fc19.x86_64/linux. initrd refers to the initrd to use when executing the kernel. This also shall be a path relative to the $BOOT directory. This key is optional. This key may appear more than once in which case all specified images are used, in the order they are listed. Example: 6a9857a393724b7a981ebb5b8495b9ea/3.8.0-2.fc19.x86_64/initrd. efi refers to an arbitrary EFI program. This also takes a path relative to $BOOT. If this key is set, and the system is not an EFI system this entry should be hidden. options shall contain kernel parameters to pass to the Linux kernel to spawn. This key is optional and may appear more than once in which case all specified parameters are used in the order they are listed. devicetree refers to the binary device tree to use when executing the kernel. This also shall be a path relative to the $BOOT directory. This key is optional. Example: 6a9857a393724b7a981ebb5b8495b9ea/3.8.0-2.fc19.armv7hl/tegra20-paz00.dtb. devicetree-overlay refers to a list of device tree overlays that should be applied by the boot loader. Multiple overlays are separated by spaces and applied in the same order as they are listed. This key is optional but depends on the devicetree key. Example: /6a9857a393724b7a981ebb5b8495b9ea/overlays/overlay_A.dtbo /6a9857a393724b7a981ebb5b8495b9ea/overlays/overlay_B.dtbo architecture refers to the architecture this entry is defined for. The argument should be an architecture identifier, using the architecture vocabulary defined by the EFI specification (i.e. IA32, x64, IA64, ARM, AA64, …). If specified and this does not match (case insensitively) the local system architecture this entry should be hidden. Each configuration drop-in snippet must include at least a linux or an efi key and is otherwise not valid. Here’s an example for a complete drop-in file:\n1# /boot/loader/entries/6a9857a393724b7a981ebb5b8495b9ea-3.8.0-2.fc19.x86_64.conf 2title Fedora 19 (Rawhide) 3version 3.8.0-2.fc19.x86_64 4machine-id 6a9857a393724b7a981ebb5b8495b9ea 5options root=UUID=6d3376e4-fc93-4509-95ec-a21d68011da2 6architecture x64 7linux /6a9857a393724b7a981ebb5b8495b9ea/3.8.0-2.fc19.x86_64/linux 8initrd /6a9857a393724b7a981ebb5b8495b9ea/3.8.0-2.fc19.x86_64/initrd On EFI systems all Linux kernel images should be EFI images. In order to increase compatibility with EFI systems it is highly recommended only to install EFI kernel images, even on non-EFI systems, if that’s applicable and supported on the specific architecture.\nConversely, in order to increase compatibility it is recommended to install generic kernel images that make few assumptions about the firmware they run on, i.e. it is a good idea that both images shipped as UEFI PE images and those which are not don’t make unnecessary assumption on the underlying firmware, i.e. don’t hard depend on legacy BIOS calls or UEFI boot services.\nNote that these configuration snippets may only reference kernels (and EFI programs) that reside on the same file system as the configuration snippets, i.e. everything referenced must be contained in the same file system. This is by design, as referencing other partitions or devices would require a non-trivial language for denoting device paths. If kernels/initrds are to be read from other partitions/disks the boot loader can do this in its own native configuration, using its own specific device path language, and this is out of focus for this specification. More specifically, on non-EFI systems configuration snippets following this specification cannot be used to spawn other operating systems (such as Windows).\nType #2 EFI Unified Kernel Images A unified kernel image is a single EFI PE executable combining an EFI stub loader, a kernel image, an initramfs image, and the kernel command line. See the description of the --uefi option in dracut(8). Such unified images will be searched for under $BOOT/EFI/Linux/ and must have the extension .efi. Support for images of this type is of course specific to systems with EFI firmware. Ignore this section if you work on systems not supporting EFI.\nImages of this type have the advantage that all metadata and payload that makes up the boot entry is monopolized in a single PE file that can be signed cryptographically as one for the purpose of EFI SecureBoot.\nA valid unified kernel image must contain two PE sections:\n.cmdline section with the kernel command line .osrel section with an embedded copy of the os-release file describing the image The PRETTY_NAME= and VERSION_ID= fields in the embedded os-release file are used the same as title and version in the “boot loader specification” entries. The .cmdline section is used instead of the options field. linux and initrd fields are not necessary, and there is no counterpart for the machine-id field.\nOn EFI, any such images shall be added to the list of valid boot entries.\nAdditional notes Note that these configurations snippets do not need to be the only configuration source for a boot loader. It may extend this list of entries with additional items from other configuration files (for example its own native configuration files) or automatically detected other entries without explicit configuration.\nTo make this explicitly clear: this specification is designed with “free” operating systems in mind, starting Windows or MacOS is out of focus with these configuration snippets, use boot-loader specific solutions for that. In the text above, if we say “OS” we hence imply “free”, i.e. primarily Linux (though this could be easily be extended to the BSDs and whatnot).\nNote that all paths used in the configuration snippets use a Unix-style “/” as path separator. This needs to be converted to an EFI-style “\u0026quot; separator in EFI boot loaders.\nLogic A boot loader needs a file system driver to discover and read $BOOT, then simply reads all files $BOOT/loader/entries/*.conf, and populates its boot menu with this. On EFI, it then extends this with any unified kernel images found in $BOOT/EFI/Linux/*.efi. It may also add additional entries, for example a “Reboot into firmware” option. Optionally it may sort the menu based on the machine-id and version fields, and possibly others. It uses the file name to identify specific items, for example in case it supports storing away default entry information somewhere. A boot loader should generally not modify these files.\nFor “Boot Loader Specification Entries” (Type #1), the kernel package installer installs the kernel and initrd images to $BOOT (it is recommended to place these files in a vendor and OS and installation specific directory) and then generates a configuration snippet for it, placing this in $BOOT/loader/entries/xyz.conf, with xyz as concatenation of machine id and version information (see above). The files created by a kernel package are private property of the kernel package and should be removed along with it.\nFor “EFI Unified Kernel Images” (Type #2), the vendor or kernel package installer creates the combined image and drops it into $BOOT/EFI/Linux/. This file is also private property of the kernel package and should be removed along with it.\nA UI application intended to show available boot options shall operate similar to a boot loader, but might apply additional filters, for example by filtering out the booted OS via the machine ID, or by suppressing all but the newest kernel versions.\nAn OS installer picks the right place for $BOOT as defined above (possibly creating a partition and file system for it) and pre-creates the /loader/entries/ directory in it. It then installs an appropriate boot loader that can read these snippets. Finally, it installs one or more kernel packages.\nOut of Focus There are a couple of items that are out of focus for this specification:\nIf userspace can figure out the available boot options, then this is only useful so much: we’d still need to come up with a way how userspace could communicate to the boot loader the default boot loader entry temporarily or persistently. Defining a common scheme for this is certainly a good idea, but out of focus for this specification. This specification is just about “Free” Operating systems. Hooking in other operating systems (like Windows and macOS) into the boot menu is a different story and should probably happen outside of this specification. For example, boot loaders might choose to detect other available OSes dynamically at runtime without explicit configuration (like systemd-boot does it), or via native configuration (for example via explicit Grub2 configuration generated once at installation). This specification leaves undefined what to do about systems which are upgraded from an OS that does not implement this specification. As the previous boot loader logic was largely handled by in distribution-specific ways we probably should leave the upgrade path (and whether there actually is one) to the distributions. The simplest solution might be to simply continue with the old scheme for old installations and use this new scheme only for new installations. Links systemd-boot(7)bootctl(1)\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/boot-loader-specification/","section":"docs","tags":null,"title":""},{"body":"CentOS / RHEL 7: GRUB2 configuration file /boot/grub2/grub.cfg explained – The Geek Diary https://www.thegeekdiary.com/centos-rhel-7-grub2-configuration-file-bootgrub2grub-cfg-explained/\nThe GRUB2 configuration file /boot/grub2/grub.cfg – Starting RHEL 7 GRUB 2 is the bootloader. The GRUB 2 configuration file is /boot/grub2/grub.cfg. – Do not edit this file directly. Use the grub2-mkconfig command to generate grub.cfg. This command uses the template scripts in /etc/grub.d and menu-configuration settings taken from /etc/default/grub when generating grub.cfg. – The /etc/grub2.cfg file is a symbolic link to /boot/grub2/grub.cfg.\nBelow is a sample GRUB2 configuration file.\n1..... (skiped for breivity) 2### BEGIN /etc/grub.d/10_linux ### 3menuentry \u0026#39;CentOS Linux (3.10.0-514.el7.x86_64) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-3.10.0-514.el7.x86_64-advanced-10bac86a-a9be-478c-b63f-46d3ca061e03\u0026#39; { 4\tload_video 5\tset gfxpayload=keep 6\tinsmod gzio 7\tinsmod part_msdos 8\tinsmod xfs 9\tset root=\u0026#39;hd0,msdos1\u0026#39; 10\tif [ x$feature_platform_search_hint = xy ]; then 11\tsearch --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint=\u0026#39;hd0,msdos1\u0026#39; a52207e4-01fd-4f12-98b7-681d56f21dc5 12\telse 13\tsearch --no-floppy --fs-uuid --set=root a52207e4-01fd-4f12-98b7-681d56f21dc5 14\tfi 15\tlinux16 /vmlinuz-3.10.0-514.el7.x86_64 root=/dev/mapper/cl-root ro crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet LANG=en_US.UTF-8 16\tinitrd16 /initramfs-3.10.0-514.el7.x86_64.img 17} 18menuentry \u0026#39;CentOS Linux (0-rescue-9cdb9ab3246a4b3f9c0849ecd597f25e) 7 (Core)\u0026#39; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option \u0026#39;gnulinux-0-rescue-9cdb9ab3246a4b3f9c0849ecd597f25e-advanced-10bac86a-a9be-478c-b63f-46d3ca061e03\u0026#39; { 19\tload_video 20\tinsmod gzio 21\tinsmod part_msdos 22\tinsmod xfs 23\tset root=\u0026#39;hd0,msdos1\u0026#39; 24\tif [ x$feature_platform_search_hint = xy ]; then 25\tsearch --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint=\u0026#39;hd0,msdos1\u0026#39; a52207e4-01fd-4f12-98b7-681d56f21dc5 26\telse 27\tsearch --no-floppy --fs-uuid --set=root a52207e4-01fd-4f12-98b7-681d56f21dc5 28\tfi 29\tlinux16 /vmlinuz-0-rescue-9cdb9ab3246a4b3f9c0849ecd597f25e root=/dev/mapper/cl-root ro crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet 30\tinitrd16 /initramfs-0-rescue-9cdb9ab3246a4b3f9c0849ecd597f25e.img 31} 32....... The /etc/default/grub File GRUB 2 menu-configuration settings are taken from /etc/default/grub when generating grub.cfg. The following lists the contents of the /etc/default/grub file:\n1# cat /etc/default/grub 2GRUB_TIMEOUT=5 3GRUB_DISTRIBUTOR=\u0026#34;$(sed \u0026#39;s, release .*$,,g\u0026#39; /etc/system-release)\u0026#34; 4GRUB_DEFAULT=saved 5GRUB_DISABLE_SUBMENU=true 6GRUB_TERMINAL_OUTPUT=\u0026#34;console\u0026#34; 7GRUB_CMDLINE_LINUX=\u0026#34;crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet\u0026#34; 8GRUB_DISABLE_RECOVERY=\u0026#34;true\u0026#34; If changes are made to any of these parameters, you need to run grub2-mkconfig to re-generate the /boot/grub2/grub.cfg file. For example:\n1# grub2-mkconfig –o /boot/grub2/grub.cfg Values are described as follows:GRUB_TIMEOUT: The time in seconds after the menu is displayed to boot the default entry, unless a key is pressed. The default is 5. Set to 0 to boot immediately without displaying the menu, or to -1 to wait indefinitely.GRUB_DISTRIBUTOR: Set by distributors of GRUB and is used to generate more informative menu entry titles. The example evaluates to CentOS Linux Server.GRUB_DEFAULT The default menu entry to boot. A value of 0 boots the first menuentry. A value of 1 boots the second menuentry. A value of saved instructs GRUB 2 to load the last successfully loaded operating system.\nA GRUB_DEFAULT value of saved also allows you to use the grub2-set-default and grub2-reboot commands to specify the default entry. These two commands are described as follows:grub2-set-default: Sets the default entry for all subsequent rebootsgrub2-reboot: Sets the default entry for the next reboot only\nFor example, with GRUB_DEFAULT=saved, the following command sets the default entry for all subsequent reboots to the second menuentry:\nGRUB_DISABLE_SUBMENU: By default, the grub2-mkconfig command generates a top-level menu entry for the kernel with highest version number and puts all other found kernels or alternative menu entries for recovery mode in a submenu. Setting GRUB_DISABLE_SUBMENU=true disables this.GRUB_TERMINAL_OUTPUT: The terminal output device. When specifying multiple devices, separate the valid terminal output names with spaces.GRUB_CMDLINE_LINUX: Kernel boot parameters. More information on kernel boot parameters is provided in the next slide.GRUB_DISABLE_RECOVERY: By default, two menu entries are generated for each Linux kernel: one default entry and one entry for recovery mode. Setting GRUB_DISABLE_RECOVERY=“true” disables this.\nExplaining menuentry The GRUB 2 configuration file, /boot/grub2/grub.cfg, contains menuentry stanzas, which represent an installed Linux kernel. Each stanza begins with the menuentry keyword with options. Each menuentry is also a single boot menu entry in the GRUB 2 menu. The associated block of code is enclosed in curly brackets, { }.\n![[/menuentry-RHEL-CentOS-7.png]]\nThe stanza includes a linux16 directive followed by the path to the kernel and an initrd16 directive followed by the path to the initramfs image. The linux16 directive specifies the kernel version number to be booted as well as kernel boot parameters. A separate /boot partition was created; therefore, the path to the kernel (as well as to the initramfs image) are relative to /boot.\nThe initrd16 directive must point to the location of the initramfs file corresponding to the same kernel version. In other words, the kernel as given on the linux16 /vmlinuz-[kernel_version] line must match the version number of the initramfs image given on the initrd16 /initramfs-[kernel_version].img line of each stanza.\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/centos-rhel-7-grub2-configuration-file/","section":"docs","tags":null,"title":""},{"body":"CentOS / RHEL 7 : How to reinstall GRUB2 from rescue mode https://www.thegeekdiary.com/centos-rhel-7-how-to-reinstall-grub2-from-rescue-mode/\nCentOS / RHEL 7 now includes GRUB2 which uses a new way of installing to the MBR of your boot device. You may have to reinstall the GRUB2 bootloader if your system is not bootable after a failure. In order to reinstall GRUB2 you have to boot into rescue mode. Follow the steps below to boot into rescue mode and reinstall GRUB2 bootloader.\nBooting into rescue mode and reinstalling GRUB2 Boot from the RHEL7 installation DVD by altering the boot order in Bios and selecting DVD media as the first booting preference. Note : Older version of RHEL 7 DVD will not work here. So make sure you have latest version RHEL 7 DVD with you.\nAt the boot screen, Select the Troubleshooting option at the end of the screen. ![[/troubleshooting-option-for-RHEL-7-rescue-mode.png]]\nAt the next screen, select the option Rescue a CentOS Linux system. ![[/rescue-a-centos-7-system-reinstall-GRUB2.png]]\nOn the next screen, press enter to continue. When asked if you would like Rescue to find your installation, choose Continue. ![[/find-linux-installation-for-rescue-mode-RHEL-7-reinstall-GRUB2.png]]\nIf you run into trouble detecting your install, retry using the Skip option and manually detect and mount your storage. You would get a message shown in the picture below if the rescue mode has detected the correct installation.\n![[/system-has-been-mounted-under-mntsysimage-RHEL-7-reinstall-GRUB2.png]]\nNext step is to change your root directory to /mnt/sysimage using the chroot command. This makes your system the root environment.\nUse the grub2-install command to re-write the MBR to your boot device. The boot device is usually /dev/sda.\nYou should get a successful installation message as shown below.\n![[/grub2-install-RHEL-7.png]]\nTo reboot the system first exit from the chroot environment and the run reboot command.\nReinstalling grub2 on UEFI-based machines If you are on an UEFI-based machine, make sure you add the below 2 steps as well before you re-install GRUB2 using “grub2-install” command.\nIf the EFI System Partition has been recreated or damaged, these files can be recovered by reinstalling the grub2-efi, grub2-efi-modules and shim packages. 1# yum reinstall grub2-efi grub2-efi-modules shim If /boot/efi/EFI/redhat/grub.cfg has been removed or damaged, it can be restored with the following command: 1# grub2-mkconfig -o /boot/efi/EFI/redhat/grub.cfg ","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/centos-rhel7-how-to-reinstall-grub2-from-rescue-mode/","section":"docs","tags":null,"title":""},{"body":"Difference between grubx64 and shimx64? https://askubuntu.com/questions/342365/what-is-the-difference-between-grubx64-and-shimx64\nTypically, EFI/ubuntu/grubx64.efi on the EFI System Partition (ESP) is the GRUB binary, and EFI/ubuntu/shimx64.efi is the binary for shim.\nThe latter is a relatively simple program that provides a way to boot on a computer with Secure Boot active. On such a computer, an unsigned version of GRUB won't launch, and signing GRUB with Microsoft's keys is impossible, so shim bridges the gap and adds its own security tools that parallel those of Secure Boot. In practice, shim registers itself with the firmware and then launches a program called grubx64.efi in the directory from which it was launched, so on a computer without Secure Boot (such as a Mac), launching shimx64.efi is just like launching grubx64.efi. On a computer with Secure Boot active, launching shimx64.efi should result in GRUB starting up, whereas launching grubx64.efi directly probably won't work.\nNote that there's some ambiguity possible. In particular, if you want to use a boot manager or boot loader other than GRUB in a Secure Boot environment with shim, you must call that program grubx64.efi, even though it's not GRUB. Thus, if you were to install rEFInd on a Secure Boot-enabled computer, grubx64.efi could be the rEFInd binary. This binary would probably not reside in EFI/ubuntu, though; both it and a shim binary would probably go in EFI/refind. Also, as you've got a Mac (which doesn't support Secure Boot), there's no need to install rEFInd in this way; it makes much more sense to install rEFInd as EFI/refind/refind_x64.efi (its default location and name).\nNote that the rEFInd documentation includes a whole page on Secure Boot. Chances are you won't benefit from reading it, user190735, since you're using a Mac. I mention it only in case some other reader comes along who's trying to use rEFInd in conjunction with Secure Boot.\nReferences: wiki.ubuntu.com/SecurityTeam/SecureBoot https://askubuntu.com/questions/342365/what-is-the-difference-between-grubx64-and-shimx64 ","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/difference-between-grubx64-and-shimx64/","section":"docs","tags":["grub","grubx64","shim","shimx64","grub2","efi","boot","linux"],"title":""},{"body":"Grub2/Troubleshooting - Community Help Wiki https://help.ubuntu.com/community/Grub2/Troubleshooting#grub_rescue.3E-1\n[[Grub2 Troubleshooting - Community Help Wiki 8b8db45a75634d82a27b2181e8904881 Troubleshooting]]\nset prefix=(hdX,Y)/boot/grub Use the values determined earlier.\nExample: If the Ubuntu system is on sda5, enter: set prefix=(hd0,5)/boot/grub\nConfirm the correct X,Y values and press ENTER.\nExample: If the Ubuntu system is on sda5, enter: set root=(hd0,5)\nLoad the normal module.\nIf the module fails to load, try the full path: insmod (hdX,Y)/boot/grub/normal.mod\nTransition to the normal GRUB 2 mode with increased functionality.\nIf the module loads, HELP, TAB completion and command recall using the UP/DN keys should be available.\n(Optional) Review the current settings.\nLoad the linux module. An error message usually means the path is incorrect.\nIf the vmlinuz symlink does not exist in /, use the full path to the kernel in /boot\nSelects the latest initrd image.\nIf the initrd symlink does not exist in /, use the full path to the initrd image in /boot\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/grub2-troubleshooting-community-help-wiki/","section":"docs","tags":null,"title":""},{"body":"How to reset a root password on Fedora https://fedoramagazine.org/reset-root-password-fedora/\nA system administrator can easily reset a password for a user that has forgotten their password. But what happens if the system administrator forgets the root password? This guide will show you how to reset a lost or forgotten root password. Note that to reset the root password, you need to have physical access to the machine in order to reboot and to access GRUB settings. Additionally, if the system is encrypted, you will also need to know the LUKS passphrase.\nEdit the GRUB settings First you need to interrupt the boot process. So you’ll need to turn on the system or restart, if it’s already powered on. The first step is tricky because the grub menu tends to flash by very quickly on the screen.\nPress E on your keyboard when you see the GRUB menu:\n![[grub.png]]\nAfter pressing ‘e’ the following screen is shown:\n![[grub2.png]]\nUse your arrow keys to move the the linux16 line.\n![[grub3.png]]\nUsing your del key or backspace key, remove rhgb quiet and replace with the following.\n1rd.break enforcing=0 ![[grub4.png]]\nAfter editing the lines, Press Ctrl-x to start the system. If the system is encrypted, you will be prompted for the LUKS passphase here.\nNote: Setting enforcing=0, avoids performing a complete system SELinux relabeling. Once the system is rebooted, restore the correct SELinux context for the /etc/shadow file. (this is explained a little further in this process)\nMounting the filesystem The system will now be in emergency mode. Remount the hard drive with read-write access:\n1# mount –o remount,rw /sysroot Password Change Run chroot to access the system.\n1# chroot /sysroot You can now change the root password.\n1# passwd Type the new root password twice when prompted. If you are successful, you should see a message that all authentication tokens updated successfully.\nType exit, twice to reboot the system.\nLog in as root and restore the SELinux label to the /etc/shadow file.\n1# restorecon -v /etc/shadow Turn SELinux back to enforcing mode.\n1# setenforce 1 ","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/how-to-reset-a-root-password-on-fedora/","section":"docs","tags":null,"title":""},{"body":"Preliminary Work: Getting GRUB2 on a qemu disk https://codezen.org/viridis-ng/2012/08/31/preliminary-work-getting-a-grub2-on-a-qemu-disk/\nIn this article, we’ll cover the very first step in writing a toy operating system: preparing a disk to boot your kernel from.\nWe’ll be using GRUB (GRand Unified Bootloader) version 2, which has plenty of nice features, is modern, and is what Linux uses so it’s very well tested.\nAssumptions This is not a hand-holdy kind of write-up because this isn’t a hand-holdy subject. Before you start you should have a Linux machine running natively (unless you want to nest VMs which is a terrible idea for debugging). You should have qemu installed, preferably the kvm variant but that will be an unimportant distinction for quite awhile.\nReasoning Why QEMU? QEMU provides seamless KVM integration, and has a myriad of devices supported, and has GDB support. In my prior efforts I used Bochs which is a fine x86 emulator with a decent debugger, but it’s device selection is limited and I’ve become more familiar with QEMU in the intervening years.\nWhy GRUB2? GRUB is a solid, flexible bootloader. Traditionally, toy OSes target floppy like devices and part of the learning experience is writing that initial 512 bytes of assembly and the boot signature. I’ve written too many of those already, but the honest truth is that bootloaders aren’t part of the kernel and so they are uninteresting.\nThe second reason is that using GRUB allows us to be hosted on a real filesystem (we use an ext2 boot partition in this article) and with a real file-format (ELF) which comes in handy when manipulating the FS from Linux or using debug tools on the binary.\nThe last reason is that GRUB provides an abstraction from BIOS interrupts like e820 to count memory.\nAnd, as for why version 2 specifically, for no other reason than it’s the latest.\nCreate a QEMU disk QEMU comes with a nice tool to create disks. We’re going to use the raw format because it will allow us to easily mount portions of the disk later with losetup.\nFirst, create a decent size raw disk. I made mine 10G which is overkill for our purposes, but I’ve got plenty of room to spare.\n1jack@sagan:$ qemu-img create -f raw disk.img 10g Grab a Linux ISO I tried and tried to convince my local copy of the grub utilities to install to a partition I created in the disk.img but when booting in qemu it failed to find the secondary boot files, tossed a message and dumped to a useless rescue prompt. In the end I decided it would be 10x easier to install from within the QEMU environment so that all of the device maps and IDs would naturally sort themselves out.\nI chose to install from the Arch Linux install CD. In particular the August 2012 version, although future installation media will probably be okay.\nBoot the ISO in QEMU Use the following command to boot QEMU with the Linux ISO, and the disk image.\n1jack@sagan:$ qemu -hda disk.img -cdrom [path to Linux ISO] -m 1024 This should get you to a prompt. At this point, the architecture (x86/x86_64) doesn’t matter as the GRUB media is identical.\nSetup the Disk I used cfdisk to create two new primary partitions. 1 100MB partition for boot and 1 with the rest.\n1livecd:# cfdisk /dev/sda Then create your filesystems. I want to use ext2 for the /boot and ext4 for the other partition because later I plan on having some fun with ext4.\n1livecd:# mkfs.ext2 /dev/sda1 2... 3livecd:# mkfs.ext4 /dev/sda2 Install GRUB2 to the Disk Mount the boot FS to /mnt\n1livecd:# mount /dev/sda1 /mnt And then use grub-install to copy the relevant files and setup the MBR. We specify boot directory because otherwise grub-install will try to use /boot on the live CD and will fail to map that to a usable device.\n1livecd:# grub-install --boot-directory=/mnt /dev/sda It should report no errors.\nFinally, unmount the boot FS\n1livecd:# umount /mnt And you can either shutdown like it’s a real machine or just kill QEMU afterwards.\nTesting the Boot Now, restart the QEMU without the ISO argument to see if you can get to a GRUB prompt.\n1jack@sagan:$ qemu -hda disk.img -m 1024 Almost instantaneously you should get a window that looks like:\n![[/2012-08-30-184653_718x880_scrot-e1346370405695.png]]\nMounting Partitions from Linux Now that we have a bootloader in place, hopefully we won’t have to use any other outside help in our QEMU environment. However, obviously the next step requires we have a file to boot. That’s for the next post, but to get to that point we need to be able to copy the file into our disk, which is complicated by the fact that it’s not just a stupid filesystem image, but a full disk image with a partition table and everything.\nTo mount the partitions we need to use losetup to create a loopback devices for just the relevant parts of the image file. Conveniently losetup takes the -o (offset) and --sizelimit arguments which allow you to loopback map a portion of a file.\nFirst, let’s take a look at the output of fdisk‘s p (print) command to get the byte offsets and sizes of our partitions.\n1jack@sagan:$ fdisk disk.img 2... 3Command (m for help):p 4Disk disk.img: 10.7 GB, 10737418240 bytes 5255 heads, 63 sectors/track, 1305 cylinders, total 20971520 sectors 6Units = sectors of 1 * 512 = 512 bytes 7Sector size (logical/physical): 512 bytes / 512 bytes 8I/O size (minimum/optimal): 512 bytes / 512 bytes 9Disk identifier: 0x00000000 10 11 Device Boot Start End Blocks Id System 12disk.img1 63 192779 96358+ 83 Linux 13disk.img2 192780 20971519 10389370 83 Linux The important things here are the partitions starts and ends, and the unit size.\nOur first partition, the ext2 boot partition that GRUB cares about, starts at byte (63 * 512 =) 32256. It ends at byte (192779 * 512) = 98702848. So it’s size, in bytes is 98702848 - 32256 = 98670592\nWe can then use the starting offset and the size to bind a loopback device to that portion of the disk.img.\n1jack@sagan:$ sudo losetup -f -o 32256 --sizelimit 98670592 disk.img The -f flag lets losetup use the first available loopback device. /dev/loop0 is the likely choice, but you can check it with losetup -a to list the current loopback devices.\n1jack@sagan:$ losetup -a 2/dev/loop0: []: (/path/to/disk.img), offset 32256, sizelimit 98670592 Now that the loopback is setup, you can mount the filesystem like any other block device and it should work without error and even show the grub files placed there from the ISO.\n1jack@sagan:$ sudo mount /dev/loop0 /mount/point 2jack@sagan:$ ls /mount/point/ 3grub lost+found 4jack@sagan:$ ls /mount/point/grub 5fonts grubenv i386-pc locale themes In the next post we’ll be loading our kernel to /mount/point/ and using the GRUB prompt to boot into it.\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/preliminary-work-getting-grub2-on-a-qemu-disk/","section":"docs","tags":null,"title":""},{"body":"PXE Boot, What is PXE? How does it work? https://linuxhit.com/pxe-boot-what-is-pxe-how-does-it-work/\nHow does it work? Putting it all together PXE Boot – Introduction What can you expect to learn about PXE from this post? High level overview of PXE boot process. Use cases for PXE boot. Detailed end to end overview of the PXE boot process. Technical details of each stage. What is PXE? In this post we are deep diving into PXE boot. PXE stands for preboot execution environment. It is standards base and can be implemented using open source software or vendor supported products. PXE is a key part of data center infrastructure because it enables automated provisioning of servers or work stations over a network. An in depth understanding of the PXE stack benefits anyone working on infrastructure deployment of bare metal servers, embedded devices and IOT devices.\nI first implemented a PXE boot environment in a production data center 15 years ago. Installing operating systems from CDROM was painfully slow and we desired an automated solution. The knowledge I gained from that project increased in value through out my career. Since then I have worked with PXE in large scale deployments provisioning thousands and thousands of hosts in data centers across the globe. I am excited to share what I have learned through years of hands on experience.\nWhy did I write this guide? PXE is often seems like a dark art. Typically only a handful of people in the team truly know how the environment’s PXE infrastructure boot works. Additionally debugging it is hard, debugging remotely even harder. Therefore, I wrote this guide to help demystify PXE boot by explaining it a simple, thorough and interesting fashion.\nHigh level overview of PXE boot PXE Use Case, What problem does it solve? PXE solves a problem large enterprises face. How do you automate provisioning or installation of operating systems on large quantities of machines?\nOperating system such as Windows or Linux have mechanisms to automate installation. Typically you create a seed file or configuration. The seed file provides answers to the questions asked by the OS installer. In the linux world examples of this are debian preseed files or Redhat kickstart files. But still you need access to the installation media on CD/DVD-ROM or a USB drive. A human running around with the usb drive touching every server does not scale. Its time consuming and error prone. Lets imagine a world where a human puts a server in the rack, powers it on and is done. This has many benefits:\nInstallers can be less technical. Reduced time spent per server. Less error prone due to automation. OS installation tools are centralized and easier to update. This is where PXE comes in. PXE is a standards based approached to solving the problem of getting the OS onto the system without a human being putting media (USB, CD/DVD-ROM) in the system. It does this by bootstrapping the machine over the network.\nIn a fully automated environment the human installing the server does the following:\nInstalls server in the rack. Connects power and network. Walks away. The powered on server automatically fetches a network boot file (NBF) to boot itself up and provisions an operating system. It is a beautiful thing when its working properly\nHow does it work? It all starts with the NIC The start of a PXE workflow is booting network interface card (NIC). In a typical PC or laptop the NIC will not do anything until the operating system boots and loads the proper driver. However network booting requires a PXE enabled NIC. The NIC contains firmware with a tiny network stack. This firmware is capable of connecting to the network and fetching a file to boot, commonly referred to as the network boot file (NBF). The file could be a kernel or it could be network enabled boot loader.\nThe server boots the file downloaded off the network. Typically the boot image kicks off an automated installation of an operating system. Now lets dive into the components that make this process possible.\nPXE boot components A typical PXE environment has the following components.\nPXE enabled NICs Not all NICs are equal. Many consumer grade network cards do not have a PXE capabilities. Although that is rapidly changing as advances make it easier to include more features in cheaper devices. PXE enabled NICs are the defacto standard in data center grade servers. We suggest you double check before you buy. However I would be surprised if any major server manufacturer ships a NIC without PXE capability these days.\nSome of the PXE enabled NICs even use open source PXE firmware. IPXE is an open source firmware often installed on data center NICs.\nDHCP Server DHCP stands for Dynamic Host Configuration Protocol. There are two types of actors in DHCP. The DHCP server and the DHCP client.\nA DHCP server provides a network configuration to clients. Specifically, DHCP provides an IP network configuration to a client. A DHCP client runs on computers that join the network and need a configuration.\nAn example of real world DHCP use you are probably familiar with is connecting to your office LAN. Your laptop has no idea what IP addresses are in use on the network it has joined. The DHCP client on your laptop sends a broadcast to the network indicating it is looking for a DHCP server. A response is sent from the the server to announce its availability. Your client acknowledges this by sending a request for a DHCP lease. The DHCP server sees this request and finds an unused IP address. Your laptop gets a DHCP lease offer from the server. The lease offer among other things includes the IP address you will use. Your laptop’s DHCP client accepts the offer and begins using the IP address to talk to on the network. As lease expiration time approaches your laptop will ask to renew.\nIn a PXE boot environment there is always a DHCP server. The machines that are being provisioned are DHCP clients. The PXE enabled NIC has a DHCP client built into its firmware.\nDHCP supports a wide range of options that can be provided to network clients. But typically it consists of an IP address for use by the client, a default gateway address and DNS servers to use for name resolution. In the case of PXE, an option that contains the IP address of the server to download its boot files from.\nTFTP Server TFTP stands for trivial file transfer protocol. TFTP is a simple UDP based protocol for getting or sending a file. It’s simplicity lends well to being implemented in firmware environments where resources are limited. Due to its simple nature TFTP has no bells or whistles. Getting and putting files are supported, that’s it. There is no directory listing, you must know the exact path of the file you want to download. Additionally there is no authentication or authorization.\nWhile TFTP is still commonly used in PXE environments, advances is in technology has resulted in some PXE implementations supporting more complex protocols like HTTP or ISCSI. For example the IPXE firmware supports:\nHTTP ISCSI Storage Area Networks (SAN) Fiber channel over ethernet (FCOE) Storage Area Networks (SAN) ATA over etherent (AOE) ![[PXE-Flow-1.jpg.jpg]]\nThis diagram illustrates the PXE boot flow from power on to network boot file download.\nThe PXE environment we just described is a simple and common configuration. It is a good starting point for newcomers trying to understand PXE for the first time.\nHere are some variations you will see in the real world. Especially in enterprises.\nDHCP relay or “helper”. The relay forwards DHCP request to a DHCP server not on the local LAN. This functionality is common on enterprise routers. PXE proxy or relay. This is often used when one does not have the access required to modify the DHCP server configuration. In this case the relay responds to the DHCP request with just the server and filename of the network boot file. Letting the existing DHCP server provide the standard IP configuration. HTTP or HTTPS instead of TFTP for retrieval for the network boot file. Conclusion In conclusion PXE is a very powerful tool for automating and managing the provisioning and updates of data center infrastructure, embedded devices, IOT devices and even workstations. We have covered the basics and hope you walk away from this article with a better understanding.\nAppendix \u0026amp; further reading We appreciate feedback. If you have ideas on how we can make this article or site better please leave a comment.\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/pxe-boot-what-is-pxe-how-does-it-work/","section":"docs","tags":null,"title":""},{"body":"2 ways to boot with old kernel version in RHEL 8 using grubby https://www.golinuxcloud.com/boot-with-old-kernel-version-rhel-8-grubby/\nHow to set default boot kernel in RHEL 8 Linux using [[Grubby]]? How to change the default boot entry for kernel in RHEL 8? How to boot with old kernel version in RHEL 8? How to revert to previous kernel version ?\n![[2 ways to boot with old kernel version in RHEL 8 u a8dc265805864b838050c6c5c42008b6 old-kernel.jpg]]\nEarlier I had shared the steps to set default kernel in RHEL/CentOS 7 Linux node. Now with RHEL 8 the GRUB2 configuration parameter has changed again and now we use grubby to set default kernel or to change the default boot entry for kernel in the system.\nAt the time of writing this article CentOS 8 was not available hence the steps could not be validated on CentOS 8 but I will assume that the same steps should work also on CentOS 8. If you face any problems while executing these steps on CentOS 8 then please drop in the details in the comment box at the end of this article.\nWhat is Grubby? grubby is a command line tool for updating and displaying information about the configuration files for various architecture specific bootloaders. It is primarily designed to be used from scripts which install new kernels and need to find information about the current boot environment.\nGRUB configuration file The default bootloader target is primarily determined by the architecture for which grubby has been built. Each architecture has a preferred bootloader, and each bootloader has its own configuration file. If no bootloader is selected on the command line, grubby will use these default settings to search for an existing configuration. If no bootloader configuration file is found, grubby will use the default value for that architecture. These defaults are listed in the table below.\nGrubby Arguments Below are some of the arguments which we will use in this article. These snippets are taken from man page of grubby\nCheck default boot kernel Before we configure our system to boot with old kernel version or set different boot kernel for our RHEL 8 system, let us check the current default kernel.\nHere this means that post reboot the node will continue to boot from /boot/vmlinuz-4.18.0-80.7.1.el8_0.x86_64 and mapped entries\nTo check the mapped index with this kernel use below command\nYou can get the list of initrd image available on your system under /boot as shown below:\nTo get more information about the respective initrd image, you can use grubby --info\nGet index ID of kernel using grubby Before we configure our system to boot with old kernel version in RHEL 8, we must be familiar with the index mapping. Get the list of available kernels installed on your system\nSo as you see for the demonstration of this article I have installed 3 versions of kernel. Similarly I have three different initrd images mapped to respective kernel\nHere the latest kernel will be considered to have index 0 then the older version will be mapped with index 1 then the next older version will be mapped with index 2and so on..\nNow here since my system is running with the latest available kernel on my system, the index will be shown as \u0026quot;0\u0026quot;\nSimilarly if I boot my system with older kernel then the index will be shown respectively\nFor the oldest kernel available on my system\nSet default boot kernel (Grubby) Now since we know the default kernel and index, we can proceed with the next steps to set default boot kernel using grubby in RHEL 8 and allow your system to boot with old kernel version. There are two methods to set default kernel using grubby tool\nMethod 1: Boot with old kernel version using index I hope we are clear on the kernel to index mapping part. So here I will demonstrate the usage of --set-default-index to set default kernel using index ID. Currently my system is running with index 0 i.e. latest kernel, which now I will change to older kernel version with index 1\nNext you can check the default kernel using which the system will be booted during next reboot.\nSimilarly check the default index value which will be active post reboot\nTo activate the changes, reboot the node\nPost reboot validate the changes\nAs expected now our system is running with kernel mapped with index 1 i.e. 4.18.0-80.4.2.el8\nVerify the same in the active GRUB2 configuration file\nMethod 2: Boot with old kernel version using initrd image Now here this step is little less confusing as you don't have to remember the index value. Here you can directly give the initrd image location using which you wish to set the default boot kernel.\nNow currently my system is running with below kernel version\nTo change default kernel to 4.18.0-80.7.1.el8_0.x86_64 which is the latest available kernel on our system we will use the mapped initrd image\nNext you can verify the status of default kernel and default index which will be active post reboot of the node\nNext let us reboot our node to activate the changes\nPost reboot as expected, our new kernel is loaded on the system\nverify the same using GRUB2 configuration file\nThe same details can be checked using below commands again\nLastly I hope the steps from the article to set default boot kernel using grubby and boot with old kernel version in RHEL 8 Linux was helpful. So, let me know your suggestions and feedback using the comment section.\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/two-ways-to-boot-with-old-kernel-version-in-rhel-8-using-grubby/","section":"docs","tags":null,"title":""},{"body":"2 ways to update and rebuild initrd image in CentOS/RHEL 7 and 8 https://www.golinuxcloud.com/update-rebuild-initrd-image-centos-rhel-7-8/\nHow do I unpack or uncompress, and then repack or re-compress, an initrd or initramfs boot image file? How do I modify the contents of an initrd or initramfs? How do I view an initrd or initramfs? How to customize initrd in RHEL Linux. How to rebuild initrd image in RHEL 8 Linux. How to update initrd in RHEL 7 Linux. How to update initrd with XV compressed data. How to rebuild initrd image with LZMA compressed data. How to rebuild the initial ramdisk image in Red Hat Enterprise Linux. How to rebuild initial ram disk image in Red Hat Enterprise Linux. How to remake or recreate the initrd or initramfs.\n![[2 ways to update and rebuild initrd image in CentO 327aae521d6a489894f00648e19a906b initrd.jpg]]\nWhat is initrd? The initial RAM disk (initrd) is an initial root file system that is mounted prior to when the real root file system is available. The initrd is bound to the kernel and loaded as part of the kernel boot procedure. The kernel then mounts this initrd as part of the two-stage boot process to load the modules to make the real file systems available and get at the real root file system. The initrd file contains a minimal set of directories and executables to achieve this, such as the insmod tool to install kernel modules into the kernel. In other words, it contains the necessary executables and system files to support the second-stage boot of a Linux system. The initrd image is present under /boot directory and is owned by kernel package. The version of the running kernel on the system will be used to identify the current initrd image used during booting process. There are two initrd image available with RHEL 7. The one which is created after kernel is installed on the root file system i.e. available inside /boot/initramfs-$(uname -r).img while the other one is available inside the RHEL ISO DVD which is loaded at the initial stage of system boot up. In this article we study about the steps to update and rebuild initrd available in the RHEL ISO DVD, to learn about the steps to extract and rebuild initramfs from the system you can follow this article.\nWhy should I update initrd? Initrd contains many drivers for third party vendors along with many modules and executables which help OS detect the underlying hardware. It is possible that on a new hardware the initrd fails to detect the underlying hardware part such as Network Card, Storage Adapter etc. In such situations we can modify the initrd image.\nAlthough instead of adding driver modules from third party vendor into initrd, I would recommend creating a custom DUD (Driver Update Disk) as it also performs the same task and is a better alternative rather than updating and rebuilding initrd.\nModifying initrd in production environment is not recommended, if you have a valid subscription then you should get in touch with your support team to handle any issue which requires initrd modification.\nRather than modifying the initrd image, you can also opt to create an updates.img file which is called at a later stage of the BOOT UP. But if your problem is related to detection failure of underlying hardware then updates.img will not help.\nWhich one to choose initrd.img vs updates.img? anaconda has the capability to incorporate updates at runtime to fix any bugs or issues with the installer. These updates are generally distributed as a disk image file (referred to as updates.img in this article).\nSo we have two options with us to alter the boot up process with our customized changes, one with initrd and the other with updates.img\nThe answer to this question depends on your requirement. updates.img is called at a later stage of the boot up procedure so if you wish to include important modules to detect hardware then you should update and rebuild initrd while if you need to add some bug fixes for the RHEL OS then you can go ahead with updates.img\nCheck initrd content Before we update initrd, it is a good idea to verify the existing content of our initrd image. Here I am checking the content of initrd from the RHEL 8 ISO image.\nHere in this list you can look for the content of initrd image file.\nMethod 1: Extract initrd image Based on the initrd file compression type the command to extract and rebuild initrd will vary. For our case in both RHEL 7 and 8 we have XZ compressed data in initrd file as shown below:\nSo we can use the same method to extract and rebuild initrd for both RHEL 7 and 8 Linux.\nWe will create a temporary directory where we will extract and update initrd\nTo extract initrd use the below command:\nThis will extract all the content of initrd in the current directory\nMethod 2: Extract initrd image Alternatively you can also extract the initrd using the below list of steps. To start with copy the initrd file from the RHEL 7/8 ISO DVD to a temporary directory\nVerify the file\nNow extract the file\nWith this the initrd.img will extract and create an initrd file\nExtract the content of this initrd in the current directory\nVerify the content of the initrd\nUpdate initrd image Now since we have successfully extracted initrd, you can go ahead and do your modification. For example you can add new driver modules from the vendor to support some new hardware or any other custom change.\nFor the sake of this article I wish to add a udev rule file to my initrd to detect and map the NIC cards with pre-defined PCI ID\nWe will add this in our initrd under /usr/lib/udev/rules.d\nMethod 1: Rebuild initrd image If you extract initrd using Method 1 then follow this procedure to rebuild initrd image, navigate to your temporary directory where you did extract initrd image.\nExecute the below command to rebuild initrd image with xz as compression format\nCheck the compression type of your new initrd file\nMethod 2: Rebuild initrd image If you perform extract initrd using Method 2 then follow this procedure to rebuild initrd image, navigate to your temporary directory where you did extract initrd image.\nRemove the initrd file which was already extracted is in the same directory.\nNext rebuild initrd image using the below command:\nVerify the new initrd image\nVerify initrd image Now since we successfully rebuild initrd image, let us verify the content of our new initrd and make sure our new rule file is present in this initrd image\nSo as you see our file is now part of the initrd file. So now you can use this initrd file to boot up your system.\nSimilarly you can verify the content of initrd which you create using the Method 2.\nLastly I hope the steps from the article to update and rebuild initrd image in CentOS/RHEL 7 and 8 Linux was helpful. So, let me know your suggestions and feedback using the comment section.\nReferences:How to extract and repackage the anaconda installation initrd.img from Red Hat Enterprise Linux 7 DVD iso media?\n","link":"https://arvimal.github.io/docs/linux-booting/02-boot-loaders/two-ways-to-update-and-rebuild-initrd-image-in-centos-and-rhel8/","section":"docs","tags":null,"title":""},{"body":"","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/04-troubleshooting/","section":"docs","tags":null,"title":""},{"body":"How to View and Change Boot Sequence in Linux Terminal https://www.makeuseof.com/how-to-view-and-change-boot-sequence-in-linux-terminal/\nHave you ever had a need to change your boot sequence via terminal? Maybe you're doing so remotely via SSH, or maybe you can't manage to get into the BIOS during that two second sweet spot when your computer is first turned on. In this article, we'll explain how to easily change the boot sequence via terminal.\nView the Boot Sequence Assuming your computer supports EFI (Extensive Firmware Interface), which is pretty near all computers nowadays, you may view the current boot sequence via terminal with the command:\n1efibootmgr -v This will display all boot devices on your computer, and resemble something like:\n1BootCurrent: 0000 2Timeout: 2 seconds 3BootOrder: 0000,0004,0005,0003 4Boot0000* ubuntu\tHD(...)/File(\\EFI\\UBUNTU\\SHIMX64.EFI) 5Boot0003* Hard Drive\tBBS(...) 6Boot0004* UEFI: JetFlashTranscend 32GB 1100 ... 7Boot0005* UEFI: JetFlashTranscend 32GB 1100, Partition 1... The first line shows the current device that was booted from, the third line shows the computer's current boot sequence, and the following lines list each bootable device.\nTake note of the numbers such as 000, 003, etc. In this example, we can see the current boot sequence is the Ubuntu installation, followed by the hard drive, and the two different partitions on a 32GB USB drive.\nChange Boot Sequence Choose your new boot sequence by the device numbers, and change your boot sequence with the command:\n1sudo efibootmgr -o 5,0,4,3 Using the above example, that command would change the boot sequence to try the USB drive first, followed by the main Ubuntu installation.\nIt's that simple, and you can now change the boot sequence on any Linux computer via terminal without scrambling to get into the BIOS when first powering on the computer.\nImage Credit: Logan Weaver/Unsplash\nRunning Linux From a USB Drive: Are You Doing It Right?\nDid you know that can do a full install of Linux on a USB drive? Here's how to create a Linux USB PC in your pocket!\nAbout The Author\n","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/how-to-view-and-change-boot-sequence-in-linux-term/","section":"docs","tags":null,"title":""},{"body":"Recover a Red Hat 8 or CentOS 8 Instance That's Failing Due to GRUB2 BLS Configuration File Issues https://aws.amazon.com/premiumsupport/knowledge-center/ec2-linux-recover-blscfg-file/\nI'm running a Red Hat 8 or CentOS 8 Amazon Elastic Compute Cloud (Amazon EC2) instance. How can I recover the BLS configuration (blscfg) file found under /boot/loader/entries/ if it is corrupted or deleted?\nGRUB2 in RHEL 8 and Centos 8 uses blscfg files and entries in /boot/loader for the boot configuration, as opposed to the previous grub.cfg format. The grubby tool is recommended for managing the blscfg files and retrieving information from the /boot/loader/entries/. If the blscfg files are missing from this location or corrupted, grubby doesn't show any results. You must regenerate the files to recover functionality. To regenerate the blscfg, create a temporary rescue instance, and then remount your Amazon Elastic Block Store (Amazon EBS) volume on the rescue instance. From the rescue instance, regenerate the blscfg for any installed kernels.\nImportant: Don't perform this procedure on an instance store-backed instance. This recovery procedure requires a stop and start of your instance, which means that any data on the instance will be lost. For more information, see Determining the Root Device Type of Your Instance.\nAttach the root volume to a rescue EC2 instance\nCreate an EBS snapshot of the root volume. For more information, see Creating an Amazon EBS Snapshot.\nOpen the Amazon EC2 console.\nNote: Be sure that you are in the correct Region. The Region appears in the Amazon EC2 console to the right of your account information. You can choose a different Region from the drop down menu, if needed.\nSelect Instances from the navigation pane, and then choose the impaired instance.\nSelect Actions, select Instance State, and then choose Stop.\nIn the Description tab, under Root device, choose /dev/sda1, and then choose the EBS ID.\nSelect Actions, select Detach Volume, and then select Yes, Detach. Note the Availability Zone.\nLaunch a similar rescue EC2 instance in the same Availability Zone. This instance becomes your rescue instance.\nAfter the rescue instance has launched, select Volumes from the navigation pane, and then choose the detached root volume of the impaired instance.\nSelect Actions, and then select Attach Volume.\nChoose the rescue instance ID (id-xxxxx), and then set an unused device. In this example, the unused device is /dev/sdf.\nMount the volume of the impaired instance\nUse SSH to connect to the rescue instance.\nRun the lsblk command to view your available disk devices.\n1[ec2-user@ip-10-10-1-111 /]s lsblk 2NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT 3xvda 202:0 0 10G 0 disk 4├─xvda1 202:1 0 1M 0 part 5└─xvda2 202:2 0 10G 0 part / 6xvdf 202:80 0 10G 0 disk 7├─xvdf1 202:81 0 1M 0 part 8└─xvdf2 202:82 0 10G 0 part Note: Nitro-based instances expose EBS volumes as NVMe block devices. The output generated by the lsblk command on Nitro-based instances shows the disk names as nvme[0-26]n1. For more information, see Amazon EBS and NVMe on Linux instances.\nCreate a mount directory, and then mount the root partition of the mounted volume to this new directory. In the preceding example, /dev/xvdf2 is the root partition of the mounted volume. For more information, see Making an Amazon EBS Volume Available for Use on Linux. 1sudo mkdir /mount 2sudo mount /dev/xvdf2 /mount Mount /dev, /run, /proc, and /sys of the rescue instance to the same paths as the newly mounted volume. 1sudo mount -o bind /dev /mount/dev 2sudo mount -o bind /run /mount/run 3sudo mount -o bind /proc /mount/proc 4sudo mount -o bind /sys /mount/sys Start the chroot environment. 1sudo chroot /mount Regenerate the blscfg files\nRun the rpm command. Take note of the available kernels in your instance. 1[root@ip-10-10-1-111 ~]# rpm -q --last kernel 2kernel-4.18.0-147.3.1.el8_1.x86_64 Tue 21 Jan 2020 05:11:16 PM UTC 3kernel-4.18.0-80.4.2.el8_0.x86_64 Tue 18 Jun 2019 05:06:11 PM UTC To recreate the blscfg file, run the kernel-install command. Note: kernel-install binary is provided with the systemd-udev rpm installation package.\n1sudo kernel-install add 4.18.0-147.3.1.el8_1.x86_64 /lib/modules/4.18.0-147.3.1.el8_1.x86_64/vmlinuz Replace 4.18.0-147.3.1.el8_0.x86_64 with your kernel version number.\nThe blscfg for the designated kernel regenerates under /boot/loader/entries/.\n1[root@ip-10-10-1-111 ~]# ls /boot/loader/entries/ 22bb67fbca2394ed494dc348993fb9b94-4.18.0-147.3.1.el8_1.x86_64.conf If needed, repeat step 2 for other installed kernels on the instance. The latest kernel is set to the default kernel.\nRun the grubby command --default kernel to see the current default kernel.\n1sudo grubby --default-kernel Exit from chroot and unmount the /dev, /run, /proc, and /sys mounts. 1Exit 2sudo umount /mount/dev 3sudo umount /mount/run 4sudo umount /mount/proc 5sudo umount /mount/sys 6sudo umount /mount Mount the device back to the original instance with the correct block device mapping. The device now boots with the default kernel. ","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/recover-a-red-hat-8-or-centos-8-instance-thats-failing-due-to-grub2-bls-configuration-file-issues/","section":"docs","tags":null,"title":""},{"body":"https://wiki.centos.org/TipsAndTricks/CreateNewInitrd\nIf you have changed a motherboard or moved a disk to a different system it may fail to boot due to the lack of appropriate drivers in the initial RAM disk image (initramfs for CentOS 6, initrd for CentOS 5).\nBoot in Rescue Mode Boot from a CentOS installation disc (for example, CD #1 or DVD). Type \u0026quot;linux rescue\u0026quot; at the \u0026quot;boot:\u0026quot; prompt. Mount all filesystems in read-write mode. Create the New Initramfs or Initrd Change root to real root ('/') on your hard disk and make the new initramfs or initrd.\n1mount --bind /proc /mnt/sysimage/proc 2mount --bind /dev /mnt/sysimage/dev 3mount --bind /sys /mnt/sysimage/sys 4chroot /mnt/sysimage For CentOS 7 and multipathed root ('/') issue the following before chroot-ing to '/mnt/sysimage':\n1mount --bind /run /mnt/sysimage/run 2systemctl start multipathd.service For CentOS 6:\nCreate a backup copy of the current initramfs:\n1cp -p /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak Now create the initramfs for the current kernel:\n1dracut -f If you need to build it for a specific kernel version (replace the version appropriately):\n1dracut -f /boot/initramfs-2.6.32-358.el6.x86_64.img 2.6.32-358.el6.x86_64 One useful option you might want to add is -H (--hostonly). With this option dracut installs only what is needed for booting your system. Otherwise dracut by default adds many drivers to the initramfs making its size larger than necessary. Many other options may be exercised. Please see man dracut, man dracut.conf and the upstream Deployment Guide.\nFor CentOS 5:\nCreate a backup copy of the current initrd:\n1cp -p /boot/initrd-$(uname -r).img /boot/initrd-$(uname -r).img.bak Now create the initrd for the current kernel:\n1mkinitrd -f -v /boot/initrd-$(uname -r).img $(uname -r) If you need to build it for a specific kernel version (replace the version appropriately):\n1mkinitrd -f -v /boot/initrd-2.6.18-371.el5.img 2.6.18-371.el5 If you are migrating a physical machine to a virtual one using the Xen hypervisor, replace the last command above with:\n1mkinitrd --with-xenblk initrd-2.6.18-371.el5xen.img 2.6.18-371.el5xen Many other options may be exercised, such as adding non-loaded modules manually. See man mkinitrd for details. It may be necessary to modify /boot/grub/grub.conf and/or /etc/fstab depending on the details of your installation. This depends on your use of LABEL and/or UUID versus physical devices in the files, and is too complex an issue to get into in any detail in a TipsAndTricks article.\nReboot\n1cd / 2sync 3telinit 6 This page was created by PhilSchaffner. Other Wiki contributors are invited to make corrections, additions, or modifications.\nThe page was inspired by this forum thread. Please see the thread for additional discussion.\n","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/regenerate-a-new-initramfs-or-initrd-in-rhel-fedora-centos/","section":"docs","tags":["rhel","boot","initramfs","initrd","dracut","mkinitrd"],"title":""},{"body":"Reset lost root password https://wiki.archlinux.org/index.php/Reset_lost_root_password\nThis guide will show you how to reset a forgotten root password. Several methods are listed to help you accomplish this.\nWarning: An attacker could use the methods mentioned below to break into your system. No matter how secure the operating system is or how good passwords are, having physical access amounts to loading an alternate OS and exposing your data, unless you use disk encryption.\nWith a LiveCD a couple methods are available: change root and use the passwd command, or erase the password field entry directly editing the password file. Any Linux capable LiveCD can be used, albeit to change root it must match your installed architecture type. Here we only describe how to reset your password with chroot, since manual editing the password file is significantly more risky.\nUse the passwd --root MOUNT_POINT USER_NAME command to set the new password (you won't be prompted for an old one). Unmount the root partition. Reboot, and enter your new password. If you can't remember it, go to step 1. Using GRUB to invoke bash Select the appropriate boot entry in the GRUB menu and press e to edit the line. Select the kernel line and press e again to edit it. Append init=/bin/bash at the end of line. Press Ctrl-X to boot (this change is only temporary and will not be saved to your menu.lst). After booting you will be at the bash prompt. Your root file system is mounted as readonly now, so remount it as read/write mount -n -o remount,rw /. Use the passwd command to create a new root password. Reboot by typing reboot -f and do not lose your password again! Note: Some keyboards may not be loaded properly by the init system with this method and you will not be able to type anything at the bash prompt. If this is the case, you will have to use another method.\nSee also ","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/reset-lost-root-password/","section":"docs","tags":null,"title":""},{"body":"Tip: VM won’t boot, troubleshoot with guestfish | Richard WM Jones https://rwmj.wordpress.com/2010/02/09/tip-vm-wont-boot-troubleshoot-with-guestfish/\nUnbootable virtual machine? Here are three useful guestfish commands to help. (You can also consider using virt-rescue).\n1. Edit /boot/grub/grub.conf 1$ guestfish -i Rawhide 2 3Welcome to guestfish, the libguestfs filesystem interactive shell for 4editing virtual machine filesystems. 5 6Type: \u0026#39;help\u0026#39; for help with commands 7 \u0026#39;quit\u0026#39; to quit the shell 8 9\u0026gt;\u0026lt;fs\u0026gt; ls /boot/ 10System.map-2.6.32.1-9.fc13.x86_64 11System.map-2.6.32.3-21.fc13.x86_64 12System.map-2.6.33-0.40.rc7.git0.fc13.x86_64 13config-2.6.32.1-9.fc13.x86_64 14config-2.6.32.3-21.fc13.x86_64 15config-2.6.33-0.40.rc7.git0.fc13.x86_64 16[...] Use the “edit”, “emacs” or “vi” commands to edit grub.conf:\n1\u0026gt;\u0026lt;fs\u0026gt; vi /boot/grub/grub.conf From here you can change the boot kernel, change it to boot in single user mode, enable the grub menu, remove the “rhgb quiet” option so you can see boot messages, and much more.\n2. Look at the /init script When the kernel panics because it cannot mount root, it’s often because the initrd or initramfs is broken in some way. Two commands help here:\n1\u0026gt;\u0026lt;fs\u0026gt; initrd-list /boot/initramfs-2.6.33-0.40.rc7.git0.fc13.x86_64.img | less 2\u0026gt;\u0026lt;fs\u0026gt; initrd-cat /boot/initramfs-2.6.33-0.40.rc7.git0.fc13.x86_64.img init | less The first command lists all the files in the initrd, which lets you see if the right drivers got included for the (virtual) hardware. The second command lists out the init script — which is the shell script that runs first before the OS proper starts to boot.\n","link":"https://arvimal.github.io/docs/linux-booting/04-troubleshooting/tip-vm-wont-boot-troubleshoot-with-guestfish/","section":"docs","tags":null,"title":""},{"body":"The Linux Boot process 1. Power up the machine\nThe Boot process starts when a user powers up the machine.\n2. Power supply starts up, and regulates itself into the operating voltage.\nThis may take less than a millisecond.\n3. The Power supply system sends the PowerGood signal to the Motherboard.\nThe ATX specification defines the Power-Good signal as a +5-volt (V) signal generated in the power supply when it has passed its internal self-tests and the output voltages have stabilized.\nThe Power Good signal (power-good) prevents a computer from attempting to operate on improper voltages and damage itself by alerting it to an improper power supply.\n4. The Motherboard starts the Processor, once it recieves the Power Good signal.\n5. The Processor resets its internal registers, and fill it with pre-defined information.\n80386 series and later series set the following registers and corresponding data. 1 IP (16 Bit register) - 0xfff0 2 CS selector (16 Bit register) - 0xf000 3 CS base (16 Bit register) - 0xffff0000 6. The Processor starts in Real Mode.\nReal mode is characterized by a 20-bit segmented memory address space (giving exactly 1 MiB of addressable memory). This gives it unlimited direct software access to all addressable memory, the I/O addresses, and hardware. Real mode provides no support for memory protection, multitasking, or code privilege levels. Thus, all x86 CPUs start in Real mode with no memory protection, fixed 64 KiB segments, and only 20-bit (1024 KiB = 1 MiB) addressing. 7. The x86 CPU adds both theCS SelectorandCS Baseregister contents and expects to find the first instruction after reset, there.\nAll the registers, while in 8086, were 16-bit registers. This meant that only 64KiB addresses could be addressed in a single go. The CS (Code Segment) registers had two types (Selector and Base) each 16 bits long. These together (16 bits + 16 bits) were able to address 32 bit address locations. Hence, the 8086 and any x86 CPUs were able to address approximately 4GB of memory. Before starting up, the x86 CPU had cleared its registers and set it to the following values 1 IP (16 Bit register) - 0xfff0 2 CS selector (16 Bit register) - 0xf000 3 CS base (16 Bit register) - 0xffff0000 Adding CS Selector and CS Base values gives 0xfffffff0, which is 4 GB - 16 Bytes.\n1In [4]: hex(0xffff0000 + 0xfff0) 2Out[4]: \u0026#39;0xfffffff0\u0026#39; This address is called the Reset vector. The reset vector is the default location a central processing unit will go to find the first instruction it will execute after a reset. The reset vector is a pointer or address, where the CPU should always begin as soon as it is able to execute instructions.\nThe address contains a jump instruction, which points to the BIOS entry point in a Read-Only Memory chip (ROM) on the Motherboard. The BIOS is initialized and it starts up.\n8. BIOS starts\nOnce the BIOS starts, it does the Power-On Self Test and verifies all hardware. Information on the bootable disk or boot order is maintained in the BIOS. If the boot device is a disk, the BIOS tries to find a boot sector. An HDD sector is 512 Bytes. On HDDs partitioned with MBR partitioning tables, the first 446 Bytes of the first sector contains the BootStrap code. On systems using GRUB, the first stage of GRUB is located here, and is the Bootstrap code. NOTE: BIOS/UEFI cannot directly go ahead and read a disk, unless it has some way of addressing them. Almost all HDD manufacturers provide disk hardware that enable BIOS to utilize them, and access the HDD sectors through LBA (Logical Block Addressing). This is comparitively slow, but helps the BIOS to read the disks and pass control over to a Boot Loader.\n9. BIOS hands over control to the Boot Sector code (aka Master Boot Code) (GRUB Stage1)\nBIOS loads the first sector (Sector #0 of 512B) of the bootable disk into RAM. It reads the Bootstrap code (boot.img, in case of GRUB) residing within the first 446 Bytes. The control is passed on to the Bootstrap code (boot.img) (GRUB Stage1), and executes in memory. 10. GRUB starts\nOnce BIOS reads the first sector of the bootable disk via LBA addressing method, the Boot Strap code is called and executed (GRUB Stage1).\nStage 1 : (boot.img in MBR BootStrap code area, ie.. Sector #0)\nboot.img is stored in the master boot record (MBR) or optionally in any of the volume boot records (VBRs), and addresses the next stage by an LBA48 address (thus, the 1024-cylinder limitation of GRUB legacy is avoided). The Stage1 is configured (automatically) to load the first sector of core.img (core.img = Stage 1.5) Stage 1.5: (core.img - Sector #1 to #62) (Can contain drivers to access partitions with Filesystems, for Grub)\ncore.img is by default written to the sectors between the MBR and the first partition, when these sectors are free and available. For legacy reasons, the first partition of a hard drive does not begin at sector #1 (counting begins with 0) but starts at sector #63. This leaves 62 sectors of empty space not part of any partition or file system, and therefore not prone to any problems related with it. Once executed, core.img will load its configuration file and any other modules needed, particularly file system drivers; at installation time, it is generated from diskboot.img and configured to load the stage 2 by its file path. Stage 2: (In /boot/grub/)\nGRUB uses the filesystem drivers to access the filesystem partitions, and reads grub.conf. Files belonging to Stage 2 are all in /boot/grub, which is a subdirectory of the /boot directory This includes the configuration file grub.cfg, the kernels (vmlinuz), and the initrd files etc.. The GRUB menu as per grub.conf is shown and user selects a kernel to boot from. 11. GRUB loads the selected/default kernel loads, and initrd.\nGRUB reads the entry for the kernel selected (by the user or default kernel), and loads the kernel mentioned with directive linux16 to memory. The kernel takes into consideration the kernel parameters set for vmlinuz, and acts accordingly. NOTE: Some info on grub.conf and its parameters.\nThe location where GRUB searches for the kernel and initrd, is set with the parameter set root='hd0, msdos1'. This is the GRUB root, or the location where GRUB intends to find the kernel and initrd. The search parameter in grub.conf sets the way the GRUB root should be checked, and the disk UUID it should check. This filesystem is where GRUB expects to find the kernel and initrd. The search keyword follows with the vmlinuz path, and initrd path. A vmlinuz and kernel parameters example: 1`/vmlinuz-3.10.0-693.el7.x86_64 root=/dev/mapper/rhel_dell--r430--19-root ro crashkernel=auto rd.lvm.lv=rhel_dell-r430-19/root rd.lvm.lv=rhel_dell-r430-19/swap rhgb quiet LANG=en_US.UTF-8` 2`initrd16 /initramfs-3.10.0-693.el7.x86_64.img` Note that the kernel parameters mention ro (read-only). This is normal, and it instructs the kernel to read the root filesystem as read-only so that the filesystem checker can run its checks safely. After the filesystem check, the root filesystem will be mounted as read-write. If the kernel comes upon any parameters that it doesn't understand, it saves it and passes it to init (or systemd), in order to process later. If the vmlinuz path starts with a slash ('/') as in /vmlinuz-3.10.0-693.el7.x86_64, it means that the /boot/ partition is different than the root partition ('/'). If /boot/ was on the same partition as root ('/'), the entry would have been /boot/vmlinuz-3.10.0.... Grub (not the kernel) loads both the Kernel and the initrd file, as listed in grub.conf. Initrd contains the necessary drivers for the kernel, to access the connected devices as well as form a virtual filesystem in memory. With a virtual filesystem running in memory, the kernel initializes /sbin/init (which was part of the initrd file). 12. init or systemd starts\nThe kernel looks for an init binary in the following locations: /sbin/init /etc/init /bin/init /bin/sh NOTE: If the directive init=\u0026lt;path\u0026gt; is passed to grub via grub.conf (or editing at boot time),Grub loads that specific binary as the first process. Else, it looks for an init binary at the locations above.\n/sbin/init starts On systemd machines, /sbin/init is usually a symlink to /usr/lib/systemd/systemd. init reads /etc/inittab for run levels, and go to the specific runlevel locations at /etc/init.d/ to start the scripts marked to startup in that level. On Systemd machines, Systemd looks for the targets it has to reach (/usr/lib/systemd/system/default.target), and starts the units for it. By default, Systemd is configured to reach the multi-user target, and starts the services for it, and presents the login prompt. 13. mgetty, systemd-getty-generator, login, and PAM\nOn SystemV machines with older init, init loads mgetty or agetty.\nagetty takes control of the login binary It presents a login prompt to the user, in the virtual console. The user login credentials are passed to PAM settings in /etc/pam.d/ PAM checks /etc/passwd, and /etc/shadow for user info. If the user info is correct, the shell set in /etc/passwd is spawned. If not, login terminates and control is passed back to agetty. agetty takes control over login and presents the user with a prompt. On Systemd machines, systemd loads systemd-getty-generator.\nsystemd-getty-generator takes control over the login binary. The rest are similar to the sequence above. Notes 1. History of Real Mode\nThe 80286 series of processors introduced the Protected Mode of operation. Real Mode was the operational mode available before Protected Mode emerged in 80826. Protected Mode enabled features such as virtual memory, paging etc.., and these were not available in Real Mode mode of operation. Backward compatibility is a design decision in x86 series, hence it was a requirement to get any software written for processor series before 80286 to be able to run on any x86 series. The existing system software which were written for Real Mode would have to be re-written to use the Protected Mode. Hence, to maintain backward compatibility with all previous series as well as for using the existing system software, all x86 processors from 80286 till the latest x86 64-bit processors (those using Protected mode), start in Real Mode. The Processor switches from Real Mode to Protected Mode after the system software sets up a few descriptor tables and enables the Protection Enable (PE) bit in the control register 0 (CR0). 2. Why was the change to Protected mode required?\nThe Intel 8086, the predecessor to the 80286, was originally designed with a 20-bit address bus for its memory. This allowed the processor to access 220 bytes of memory, equivalent to 1 megabyte. At the time, 1 MB of memory was considered a relatively large amount of memory, so the designers of the IBM Personal Computer reserved the first 640 kilobytes for use by applications and the operating system, and the remaining 384 kilobytes for the BIOS and memory for add-on devices. As the cost of memory decreased and memory use increased, the 1 MB limitation became a significant problem. Intel intended to solve this limitation along with others with the release of the 286, through the Protected Mode. 3. How does Real mode address memory?\nReal Mode was the only mode available in the series prior 80286, ie.. 8086. This series had 20-bit address buses capable of addressing 1MiB of Memory, but had only 16-bit CPU registers that could load upto 64KiB of memory at a time. This meant that, even though the bus had the width to accomodate a larger bit size and access the memory, the Processor registers were not big enough to load the data in a single go. Hence, 8086 processors used a method known as Memory Segmentation. In 8086, Memory segmenatation worked by creating 64KiB chunks of the 1MiB data space, and loading it as required. 4. 80826 series provides memory protection compared to 8086, what is it?\nMemory segmentation is the process of dividing the system memory into sections. 8086 series used this technique to address a memory of 1MiB when its registers were only capable of storing 64KiB. In a system that uses memory segmentation, a reference to the memory location would include a value that points to a segment and an offset. This enables the processor to read the entire segment. The Memory Management Unit is responsible for mapping the segments to the actual locations in RAM, as well as checking the access permissions for that specific memory location. The Memory Segmentation used by 8086 did not provide any protection. ie. it didn't have a mechanism to prevent access to specific memory segments. Any software running on these processors can access any memory segments as it chose, even if those were not in use by the said system software. The lack of Memory protection in 8086 prevented features such as Virtual Memory from being realized. 80826 came with the Protected Mode of operation which brought in memory protection and features such as virtual memory, paging etc. As said earlier, due to backward compatibility, 80286 still started up in Real mode even though it came with Protected Mode. 5. Master Boot Record\nA master boot record (MBR) is a special type of boot sector at the very beginning of a partitioned storage device. The MBR holds the information on how the partitions are organized on that medium. The organization of the partition table in the MBR limits the maximum addressable storage space of a disk to 2 TiB (232 × 512 bytes) The first 446 Bytes of the sector of an MBR partitioned disk, contains the Bootstrap code. The next four 16 Bytes contains the four partition entries. Hence the limit of four primary partitions. The final two bytes contain the Boot signature, which denotes the disk is bootable and acts as an indicator that the sector is ending here. Thus, Total size =446 + (4 x16) + 2 = 512 Bytes\nNOTE: GPT (Guid Partition Table) is a replacement to MBR. Some of the differences between MBR and GPT are:\nMBR uses 32-bit addresses, hence is limited to read upto 2TiB of disk space (2**32 - 1)\nGPT uses 64-bit addresses and can address larger disks.\nMBR uses the Cylinder-Head-Sector (CHS) mode for disk access, which is not always correct due to outer cylinders being large than inner ones and thus the number of sectors per cylinder being different.\nGPT uses Logical-Block-Address (LBA) mode which is more accurate than GPT.\nGPT still maintains the MBR structure in Sector #0 to maintain backward compatibility. ie.. in LBA #0.\nGPT header is in LBA #1, the Partition table is at LBA #2, and the filesystem starts from LBA #34.\n6. Why does GRUB have multiple stages?\nGRUB has multiple stages, Stage 1 being in the Bootstrap section of the first sector of MBR formatted bootable disk. The Bootstrap code has only a space of around 446 Bytes. This is enough for simple bootloaders, but not so for bootloaders that support Menu-drive selection, supports multiple filesystems etc. Hence, the first stage of Grub exists in the Bootstrap code area, and the remaining at multiple locations such as the sectors between Sector #0 and Filesystem partition, as well as the Active partition. Although every MBR formatted HDD contains an MBR, the master boot code is used only if the disk contains the active, primary partition. 7. Difference between GRUB1 (Legacy) and GRUB2\nGRUB1 works only on x86 and x86_64 architecture. GRUB2 works on multiple architectures including SPARC and PowerPC. GRUB1 supported only MBR and BIOS, while GRUB2 supports MBR, GPT, EFI, BIOS, OpenFirmware etc.. GRUB1 supported boot from normal filesystems, while GRUB2 supports reading LVM, RAID etc.. GRUB1 could only read a few filesystems such as EXT, XFS, JFS, FAT, ReiserFS etc.., while GRUB2 supports additional FS such as Apple FS, NTFS etc. 8. Difference between MBR and GPT partition methods\nMBR (also called msdos partitions) uses 32-bits to store Block (LBA) addresses. For HDDs with 512 byte sectors, the MBR partition table entries allow a single partition upto 2TB. GPT (Guid Partition Table) use logical block addressing (LBA) in place of the historical cylinder-head-sector (CHS) addressing. On a system using GPT, the MBR is still maintained for backward compatibility. The protective MBR is contained in LBA 0, the GPT header is in LBA 1, and the GPT header has a pointer to the partition table, or Partition Entry Array, typically LBA 2. The UEFI specification stipulates that a minimum of 16,384 bytes, regardless of sector size, be allocated for the Partition Entry Array. On a disk having 512-byte sectors, a partition entry array size of 16,384 bytes and the minimum size of 128 bytes for each partition entry, LBA 34 is the first usable sector on the disk. 9. Difference between BIOS and EFI firmware systems\n10. Troubleshooting GRUB\nPress e from GRUB menu, to enter the GRUB configuration and edit it.\nCheck the GRUB root where GRUB checks for the UUID, at the set root=hd\u0026lt;X\u0026gt;, \u0026lt;type\u0026gt; parameter. The type would be usually msdos for MBR partitions and gpt for GPT partitions.\nPress Ctrl + C to access the GRUB command prompt.\nls and ls -l (for more details) to list the partitions on the disks, on the machine. Update/Edit grub.cfg\nAny changes to grub.cfg won't be permanent. Hence, don't directly edit it. Add changes in /etc/default/grub Run grub2-mkconfig \u0026gt; /etc/grub2.cfg to update the changes to grub2.cfg. GRUB 2 works as:\n/etc/default/grub contains customizations /etc/grub.d/ scripts contain GRUB menu information and operating system boot scripts. When the command grub2-mkconfig \u0026gt; /etc/grub2.cfg is run, it reads the contents of the grub file and the grub.d scripts and creates the grub.cfg file. Appendix https://en.wikipedia.org/wiki/Power_good_signal https://en.wikipedia.org/wiki/Real_mode https://en.wikipedia.org/wiki/Protected_mode https://en.wikipedia.org/wiki/Memory_segmentation https://en.wikipedia.org/wiki/Master_boot_record https://technet.microsoft.com/en-us/library/cc976786.aspx ","link":"https://arvimal.github.io/docs/linux-booting/readme/","section":"docs","tags":null,"title":""},{"body":"Obsidian ","link":"https://arvimal.github.io/posts/2022/12/writing-my-blog-article-in-obsidian/","section":"posts","tags":["blog","arvimal.github.io"],"title":""},{"body":"","link":"https://arvimal.github.io/tags/__base__/","section":"tags","tags":null,"title":"__base__"},{"body":"","link":"https://arvimal.github.io/tags/__bases__/","section":"tags","tags":null,"title":"__bases__"},{"body":"","link":"https://arvimal.github.io/tags/arvimal.github.io/","section":"tags","tags":null,"title":"arvimal.github.io"},{"body":"","link":"https://arvimal.github.io/tags/bios/","section":"tags","tags":null,"title":"bios"},{"body":"","link":"https://arvimal.github.io/tags/blog/","section":"tags","tags":null,"title":"blog"},{"body":"","link":"https://arvimal.github.io/tags/boot/","section":"tags","tags":null,"title":"boot"},{"body":"","link":"https://arvimal.github.io/tags/bootloader/","section":"tags","tags":null,"title":"bootloader"},{"body":"","link":"https://arvimal.github.io/docs/","section":"docs","tags":null,"title":"Docs"},{"body":"","link":"https://arvimal.github.io/tags/dracut/","section":"tags","tags":null,"title":"dracut"},{"body":"","link":"https://arvimal.github.io/tags/efi/","section":"tags","tags":null,"title":"efi"},{"body":"","link":"https://arvimal.github.io/tags/gpt/","section":"tags","tags":null,"title":"gpt"},{"body":"","link":"https://arvimal.github.io/tags/grub2/","section":"tags","tags":null,"title":"grub2"},{"body":"","link":"https://arvimal.github.io/tags/grub2-mkconfig/","section":"tags","tags":null,"title":"grub2-mkconfig"},{"body":"","link":"https://arvimal.github.io/tags/grubx64/","section":"tags","tags":null,"title":"grubx64"},{"body":"","link":"https://arvimal.github.io/tags/guid/","section":"tags","tags":null,"title":"guid"},{"body":"","link":"https://arvimal.github.io/tags/initramfs/","section":"tags","tags":null,"title":"initramfs"},{"body":"","link":"https://arvimal.github.io/tags/initrd/","section":"tags","tags":null,"title":"initrd"},{"body":"","link":"https://arvimal.github.io/tags/linux/","section":"tags","tags":null,"title":"linux"},{"body":"","link":"https://arvimal.github.io/tags/mbr/","section":"tags","tags":null,"title":"mbr"},{"body":"_M_ethod Resolution Order or 'MRO' in short, denotes the way a programming language resolves a method or attribute. This post looks into how Method Resolution Order works, using Python.\nPython supports classes inheriting from other classes. The class being inherited is called the Parent/Super class, while the class that inherits is called the Child/Sub class.\nWhile inheriting from another class, the interpreter needs a way to resolve the methods that are being called via an instance. Hence a method resolution order is needed.\nExample 0:\n[code language=\u0026quot;python\u0026quot;]\nclass A(object): def my_func(self): print(\u0026quot;Doing this in class A\u0026quot;)\nclass B(A): def my_func(self): print(\u0026quot;Doing this in class B\u0026quot;)\nmy_instance = B() my_instance.my_func() [/code]\nStructure: We've two classes, class A and class B. Instantiate class B as my_instance. Call the my_func() method through the my_instance instance. Where is the method fetched from? From class B or class A?\nHow does the code work? This should be pretty obvious, the answer would be class B. But why is it being called from class B and not from class A?\nAnswer : The Method Resolution Order [MRO].\nTo understand this in depth, let's check another example:\nExample 1:\n[code language=\u0026quot;python\u0026quot;] class A(object): def my_func(self): print(\u0026quot;Doing this in Class A\u0026quot;)\nclass B(A): pass\nclass C(object): def my_func(self): print(\u0026quot;Doing this in Class C\u0026quot;)\nclass D(B, C): pass\nmy_instance = D() my_instance.my_func() [/code]\nStructure: Four classes, class A, B, C, and D. Class D inherits from both B and C Class B inherits from A. Class A and C doesn't inherit from any super classes, but from the object base class due to being new-style classes. Class A and class C both have a method/function named my_func(). Class D is instantiated through my_instance If we were to call the method my_func() through the my_instance() instance, which class would it be called from? Would it be from class A or class C?\nHow does the code work? This won't be as obvious as Example 0.\nThe instance my_instance() is created from class D. Since class Dinherits from both class B and C, the python interpreter searches for the method my_func() in both of these classes. The intrepreter finds that class B inherits from class A, and class C doesn't have any super classes other than the default object class. Class A and class C both has the method named my_func(), and hence has to be called from one of these. Python follows a depth-first lookup order and hence ends up calling the method from class A. Following the depth-first Method Resolution Order, the lookup would be in the order :\nClass D -\u0026gt; Class B -\u0026gt; Class C\nLet's check another example, which can be a bit more complex.\nExample 2:\n[code language=\u0026quot;python\u0026quot;] class A(object): def my_func(self): print(\u0026quot;Doing this in A\u0026quot;)\nclass B(A): pass\nclass C(A): def my_func(self): print(\u0026quot;doing this in C\u0026quot;)\nclass D(B, C): pass\nmy_instance = D() my_instance.my_func() [/code]\nStructure: Four classes, class A, B, C, and D Class D inherits from both B and C Class B inherits from class A. Class C inherits from class A. Class A inherits from the default base class object. This sort of inheritance is called the Diamond Inheritance or the Deadly Diamond of death and looks like the following:\nImage courtsey : Wikipedia\nHow does the code work? Following the depth-first Method Resolution Order, the lookup would be in the order :\nClass D -\u0026gt; Class B -\u0026gt; Class A -\u0026gt; Class C -\u0026gt; Class A\nIn order to avoid ambiguity while doing a lookup for a method where multiple classes are inherited and involved, the MRO lookup has changed slightly from Python 2.3 onwards.\nIt still goes for the depth-first order, but if the occurrence of a class happens multiple times in the MRO path, it removes the initial occurrence and keeps the latter.\nHence, the look up order in Example 2 becomes:\nClass D -\u0026gt; Class B -\u0026gt; Class C -\u0026gt; Class A.\nNOTE: Python provides a method for a class to lookup the Method Resolution Order. Let's recheck Example 2 using that.\n[code language=\u0026quot;python\u0026quot;] class A(object): def my_func(self): print(\u0026quot;Calling this from A\u0026quot;)\nclass B(A): pass\nclass C(A): def my_func(self): print(\u0026quot;\\nCalling this from C\u0026quot;)\nclass D(B, C): pass\nmy_instance = D() my_instance.my_func()\nprint(\u0026quot;\\nPrint the Method Resolution Order\u0026quot;) print(D.mro()) print(D.__bases__) [/code] This should print:\n[code language=\u0026quot;python\u0026quot;] # python /tmp/Example-2.py\nCalling this from C\nPrint the Method Resolution Order class '__main__.D', class '__main__.B', class '__main__.C', class '__main__.A', type 'object'\n(, ) [/code]\nTakeaway Python follows a depth-first order for resolving methods and attributes. In case of multiple inheritances where the methods happen to occur more than once, python omits the first occurrence of a class in the Method Resolution Order. The \u0026lt;class\u0026gt;.mro()methods helps to understand the Medthod Resolution Order. The `__bases__` and `__base__` magic methods help to understand the Base/Parent classes of a Sub/Child class. References https://en.wikipedia.org/wiki/Multiple_inheritance ","link":"https://arvimal.github.io/posts/2016/05/mro-object-oriented-programming/","section":"posts","tags":["inheritance","method-resolution-order","mro","python","__bases__","__base__"],"title":"Method Resolution Order - Object Oriented Programming"},{"body":"","link":"https://arvimal.github.io/tags/method-resolution-order/","section":"tags","tags":null,"title":"method-resolution-order"},{"body":"","link":"https://arvimal.github.io/tags/mkinitrd/","section":"tags","tags":null,"title":"mkinitrd"},{"body":"","link":"https://arvimal.github.io/tags/mro/","section":"tags","tags":null,"title":"mro"},{"body":"","link":"https://arvimal.github.io/series/","section":"series","tags":null,"title":"Series"},{"body":"","link":"https://arvimal.github.io/tags/shim/","section":"tags","tags":null,"title":"shim"},{"body":"","link":"https://arvimal.github.io/tags/shimx64/","section":"tags","tags":null,"title":"shimx64"}]