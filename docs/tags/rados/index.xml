<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rados on The Child is Father of the Man</title>
    <link>/tags/rados/</link>
    <description>Recent content in rados on The Child is Father of the Man</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jun 2016 00:00:00 +0000</lastBuildDate><atom:link href="/tags/rados/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sharding the Ceph RADOS Gateway bucket index</title>
      <link>/posts/2016/06/2016-06-30-sharding-the-ceph-rados-gateway-bucket-index/</link>
      <pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>/posts/2016/06/2016-06-30-sharding-the-ceph-rados-gateway-bucket-index/</guid>
      <description>_S_harding is the process of breaking down data onto multiple locations so as to increase parallelism, as well as distribute load. This is a common feature used in databases. Read more on this at Wikipedia.
The concept of sharding is used in Ceph, for splitting the bucket index in a RADOS Gateway.
RGW or RADOS Gateway keeps an index for all the objects in its buckets for faster and easier lookup.</description>
    </item>
    
    <item>
      <title>Ceph Rados Block Device (RBD) and TRIM</title>
      <link>/posts/2015/10/2015-10-07-objects-remain-in-a-ceph-pool-used-for-rbd-even-if-the-files-are-deleted-from-the-mount-point/</link>
      <pubDate>Wed, 07 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>/posts/2015/10/2015-10-07-objects-remain-in-a-ceph-pool-used-for-rbd-even-if-the-files-are-deleted-from-the-mount-point/</guid>
      <description>I recently came across a scenario where the objects in a RADOS pool used for an RBD block device doesn’t get removed, even if the files created through the mount point were removed.
I had an RBD image from an RHCS1.3 cluster mapped to a RHEL7.1 client machine, with an XFS filesystem created on it, and mounted locally. Created a 5GB file, and I could see the objects being created in the rbd pool in the ceph cluster.</description>
    </item>
    
  </channel>
</rss>
